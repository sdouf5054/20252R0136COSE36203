{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Report Generator - Full Pipeline (Phase 2)\n",
    "\n",
    "**Version**: 2.0  \n",
    "**Date**: 2025-12-02  \n",
    "**Model**: Llama-3.1-8B (4-bit quantization)  \n",
    "**Environment**: Google Colab (T4 GPU recommended)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Overview\n",
    "\n",
    "Phase 1Ïùò Í∞úÏÑ† Î≤ÑÏ†ÑÏúºÎ°ú, Îã§ÏùåÍ≥º Í∞ôÏùÄ Ï£ºÏöî Í∞úÏÑ†ÏÇ¨Ìï≠ÏùÑ Ìè¨Ìï®Ìï©ÎãàÎã§:\n",
    "\n",
    "### Key Improvements\n",
    "- ‚úÖ **Multilingual Support**: Llama-3.1-8B (Korean ÌíàÏßà Ìñ•ÏÉÅ)\n",
    "- ‚úÖ **Modular Design**: Î™®Îç∏, ÌîÑÎ°¨ÌîÑÌä∏, Ï†ÑÏ≤òÎ¶¨ Î™®ÎìàÌôî\n",
    "- ‚úÖ **Extensible Architecture**: Team model ÌÜµÌï© Ï§ÄÎπÑ\n",
    "- ‚úÖ **Better Preprocessing**: URL Ï†úÍ±∞, Ïñ∏Ïñ¥ Í∞êÏßÄ\n",
    "- ‚úÖ **YouTube API Integration**: Ïã§ÏãúÍ∞Ñ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Ï§ÄÎπÑ\n",
    "\n",
    "### Expected Quality\n",
    "- Korean: 0-2/10 ‚Üí **6-8/10**\n",
    "- English: 4-8/10 ‚Üí **7-9/10**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers accelerate bitsandbytes torch\n",
    "!pip install -q langdetect isodate\n",
    "!pip install -q google-api-python-client  # For YouTube API (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import torch\n",
    "import isodate\n",
    "from langdetect import detect, LangDetectException\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 2. Configuration\n",
    "\n",
    "Î™®Îì† ÏÑ§Ï†ïÏùÑ Ïó¨Í∏∞ÏÑú Ï†úÏñ¥Ìï† Ïàò ÏûàÏäµÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PipelineConfig:\n",
    "    \"\"\"Ï†ÑÏ≤¥ ÌååÏù¥ÌîÑÎùºÏù∏ ÏÑ§Ï†ï\"\"\"\n",
    "    \n",
    "    # Model Configuration\n",
    "    model_name: str = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "    use_4bit: bool = True\n",
    "    max_new_tokens: int = 512\n",
    "    temperature: float = 0.7\n",
    "    top_p: float = 0.9\n",
    "    \n",
    "    # Data Configuration\n",
    "    use_youtube_api: bool = False\n",
    "    youtube_api_key: Optional[str] = None\n",
    "    data_path: str = \"full_dataset_20251013_215347.json\"\n",
    "    \n",
    "    # Processing Configuration\n",
    "    max_description_length: int = 2000\n",
    "    max_comments_to_process: int = 50\n",
    "    min_comment_length: int = 10\n",
    "    remove_urls: bool = True\n",
    "    detect_language: bool = True\n",
    "    \n",
    "    # Team Model Integration\n",
    "    use_category_model: bool = False\n",
    "    use_sentiment_model: bool = False\n",
    "    category_model_path: Optional[str] = None\n",
    "    sentiment_model_path: Optional[str] = None\n",
    "    \n",
    "    # Output Configuration\n",
    "    output_format: str = \"markdown\"\n",
    "    save_reports: bool = True\n",
    "    output_dir: str = \"reports\"\n",
    "\n",
    "# Create configuration\n",
    "config = PipelineConfig(\n",
    "    model_name=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    use_4bit=True,\n",
    "    use_youtube_api=False,\n",
    "    data_path=\"full_dataset_20251013_215347.json\"\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Pipeline Configuration\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {config.model_name}\")\n",
    "print(f\"4-bit: {config.use_4bit}\")\n",
    "print(f\"Temperature: {config.temperature}\")\n",
    "print(f\"YouTube API: {config.use_youtube_api}\")\n",
    "print(f\"Category Model: {config.use_category_model}\")\n",
    "print(f\"Sentiment Model: {config.use_sentiment_model}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© 3. Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptTemplates:\n",
    "    \"\"\"ÌîÑÎ°¨ÌîÑÌä∏ ÌÖúÌîåÎ¶ø Í¥ÄÎ¶¨\"\"\"\n",
    "    \n",
    "    VIDEO_SUMMARY_SYSTEM = \"\"\"You are an expert content analyst specializing in YouTube video analysis.\n",
    "Your task is to create concise, informative summaries based on video metadata.\n",
    "Focus on accuracy and avoid hallucinations.\"\"\"\n",
    "    \n",
    "    VIDEO_SUMMARY_USER = \"\"\"Analyze this YouTube video and create a summary.\n",
    "\n",
    "Video Information:\n",
    "- Title: {title}\n",
    "- Description: {description}\n",
    "- Category: {category}\n",
    "- Duration: {duration} seconds\n",
    "- Channel: {channel}\n",
    "\n",
    "Instructions:\n",
    "1. Write a 3-5 sentence summary in {language}\n",
    "2. Focus on what the video is about and key highlights\n",
    "3. Do NOT make up information\n",
    "4. Be factual and avoid speculation\n",
    "\n",
    "Summary:\"\"\"\n",
    "    \n",
    "    REACTION_SUMMARY_SYSTEM = \"\"\"You are an expert in social media sentiment analysis.\n",
    "Analyze YouTube comments and summarize audience reactions.\"\"\"\n",
    "    \n",
    "    REACTION_SUMMARY_USER = \"\"\"Analyze these YouTube comments and summarize the audience reaction.\n",
    "\n",
    "Video: {title}\n",
    "\n",
    "Top Comments:\n",
    "{comments}\n",
    "\n",
    "Instructions:\n",
    "1. Write a 3-5 sentence summary in {language}\n",
    "2. Identify overall sentiment (positive, negative, mixed)\n",
    "3. Highlight common themes\n",
    "4. Be objective and balanced\n",
    "\n",
    "Audience Reaction:\"\"\"\n",
    "    \n",
    "    CUSTOM_PROMPT = None\n",
    "    \n",
    "    @classmethod\n",
    "    def get_video_summary_prompt(cls, video_info: Dict, language: str = \"Korean\") -> List[Dict]:\n",
    "        if cls.CUSTOM_PROMPT:\n",
    "            return cls.CUSTOM_PROMPT\n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": cls.VIDEO_SUMMARY_SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": cls.VIDEO_SUMMARY_USER.format(\n",
    "                title=video_info.get('title', 'N/A'),\n",
    "                description=video_info.get('description', 'N/A')[:2000],\n",
    "                category=video_info.get('category_name', 'N/A'),\n",
    "                duration=video_info.get('duration_seconds', 'N/A'),\n",
    "                channel=video_info.get('channel_title', 'N/A'),\n",
    "                language=language\n",
    "            )}\n",
    "        ]\n",
    "    \n",
    "    @classmethod\n",
    "    def get_reaction_summary_prompt(cls, title: str, comments: str, language: str = \"Korean\") -> List[Dict]:\n",
    "        if cls.CUSTOM_PROMPT:\n",
    "            return cls.CUSTOM_PROMPT\n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": cls.REACTION_SUMMARY_SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": cls.REACTION_SUMMARY_USER.format(\n",
    "                title=title, comments=comments, language=language\n",
    "            )}\n",
    "        ]\n",
    "\n",
    "print(\"‚úÖ Prompt templates loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß 4. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    \"\"\"ÌÖçÏä§Ìä∏ Ï†ÑÏ≤òÎ¶¨\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "        self.url_pattern = re.compile(r'http[s]?://\\S+')\n",
    "    \n",
    "    def remove_urls(self, text: str) -> str:\n",
    "        return self.url_pattern.sub('', text)\n",
    "    \n",
    "    def detect_language(self, text: str) -> str:\n",
    "        try:\n",
    "            lang = detect(text)\n",
    "            lang_map = {'ko': 'Korean', 'en': 'English', 'ja': 'Japanese'}\n",
    "            return lang_map.get(lang, 'English')\n",
    "        except:\n",
    "            return 'English'\n",
    "    \n",
    "    def clean_description(self, description: str) -> str:\n",
    "        if not description:\n",
    "            return \"No description available.\"\n",
    "        if self.config.remove_urls:\n",
    "            description = self.remove_urls(description)\n",
    "        description = ' '.join(description.split())\n",
    "        if len(description) > self.config.max_description_length:\n",
    "            description = description[:self.config.max_description_length] + \"...\"\n",
    "        if len(description.strip()) < 20:\n",
    "            return \"Minimal description available.\"\n",
    "        return description\n",
    "    \n",
    "    def filter_comments(self, comments: List[Dict]) -> List[Dict]:\n",
    "        filtered = [c for c in comments if len(c.get('text', '')) >= self.config.min_comment_length]\n",
    "        filtered.sort(key=lambda x: x.get('like_count', 0), reverse=True)\n",
    "        return filtered[:self.config.max_comments_to_process]\n",
    "    \n",
    "    def format_comments_for_prompt(self, comments: List[Dict]) -> str:\n",
    "        if not comments:\n",
    "            return \"No comments available.\"\n",
    "        formatted = []\n",
    "        for i, comment in enumerate(comments, 1):\n",
    "            text = comment.get('text', '')\n",
    "            likes = comment.get('like_count', 0)\n",
    "            if self.config.remove_urls:\n",
    "                text = self.remove_urls(text)\n",
    "            formatted.append(f\"{i}. [{likes} likes] {text}\")\n",
    "        return \"\\n\".join(formatted)\n",
    "    \n",
    "    def parse_duration(self, duration_str: str) -> int:\n",
    "        try:\n",
    "            duration = isodate.parse_duration(duration_str)\n",
    "            return int(duration.total_seconds())\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "preprocessor = TextPreprocessor(config)\n",
    "print(\"‚úÖ Text preprocessor initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ 5. Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManager:\n",
    "    \"\"\"LLM Î™®Îç∏ Í¥ÄÎ¶¨\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.pipe = None\n",
    "    \n",
    "    def load_model(self):\n",
    "        print(f\"\\nüîÑ Loading: {self.config.model_name}\")\n",
    "        print(f\"‚öôÔ∏è 4-bit: {self.config.use_4bit}\")\n",
    "        \n",
    "        # Tokenizer\n",
    "        print(\"Loading tokenizer...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            self.config.model_name, trust_remote_code=True\n",
    "        )\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Quantization config\n",
    "        if self.config.use_4bit:\n",
    "            quantization_config = BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_compute_dtype=torch.float16,\n",
    "                bnb_4bit_quant_type=\"nf4\",\n",
    "                bnb_4bit_use_double_quant=True\n",
    "            )\n",
    "        else:\n",
    "            quantization_config = None\n",
    "        \n",
    "        # Model\n",
    "        print(\"Loading model...\")\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.config.model_name,\n",
    "            quantization_config=quantization_config,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=torch.float16 if not self.config.use_4bit else None\n",
    "        )\n",
    "        \n",
    "        # Pipeline\n",
    "        print(\"Creating pipeline...\")\n",
    "        self.pipe = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_new_tokens=self.config.max_new_tokens,\n",
    "            temperature=self.config.temperature,\n",
    "            top_p=self.config.top_p,\n",
    "            do_sample=True,\n",
    "            pad_token_id=self.tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Model loaded!\")\n",
    "    \n",
    "    def generate(self, messages: List[Dict]) -> str:\n",
    "        if self.pipe is None:\n",
    "            raise RuntimeError(\"Model not loaded\")\n",
    "        outputs = self.pipe(messages)\n",
    "        generated_text = outputs[0][\"generated_text\"]\n",
    "        if isinstance(generated_text, list):\n",
    "            return generated_text[-1][\"content\"]\n",
    "        return generated_text\n",
    "\n",
    "model_manager = ModelManager(config)\n",
    "model_manager.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîå 6. Team Model Integration (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeamModelIntegration:\n",
    "    \"\"\"ÌåÄ Î™®Îç∏ ÌÜµÌï© Ïù∏ÌÑ∞ÌéòÏù¥Ïä§\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "        self.category_model = None\n",
    "        self.sentiment_model = None\n",
    "    \n",
    "    def load_category_model(self):\n",
    "        if not self.config.use_category_model:\n",
    "            return\n",
    "        # TODO: ÌåÄÏõê Íµ¨ÌòÑ\n",
    "        print(\"‚ö†Ô∏è Category model not implemented yet\")\n",
    "    \n",
    "    def load_sentiment_model(self):\n",
    "        if not self.config.use_sentiment_model:\n",
    "            return\n",
    "        # TODO: ÌåÄÏõê Íµ¨ÌòÑ\n",
    "        print(\"‚ö†Ô∏è Sentiment model not implemented yet\")\n",
    "    \n",
    "    def predict_category(self, video_info: Dict) -> Optional[str]:\n",
    "        if not self.config.use_category_model or self.category_model is None:\n",
    "            return None\n",
    "        # TODO: Î™®Îç∏ inference\n",
    "        return None\n",
    "    \n",
    "    def analyze_sentiment(self, comments: List[Dict]) -> Optional[Dict]:\n",
    "        if not self.config.use_sentiment_model or self.sentiment_model is None:\n",
    "            return None\n",
    "        # TODO: Î™®Îç∏ inference\n",
    "        return None\n",
    "\n",
    "team_models = TeamModelIntegration(config)\n",
    "team_models.load_category_model()\n",
    "team_models.load_sentiment_model()\n",
    "print(\"‚úÖ Team model interface ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• 7. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def load_from_file(self, file_path: str) -> List[Dict]:\n",
    "        print(f\"\\nüìÇ Loading: {file_path}\")\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"‚úÖ Loaded {len(data)} videos\")\n",
    "        return data\n",
    "    \n",
    "    def get_data(self) -> List[Dict]:\n",
    "        if self.config.use_youtube_api:\n",
    "            raise NotImplementedError(\"YouTube API not implemented yet\")\n",
    "        return self.load_from_file(self.config.data_path)\n",
    "\n",
    "data_loader = DataLoader(config)\n",
    "print(\"‚úÖ Data loader ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé¨ 8. Report Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportGenerator:\n",
    "    def __init__(self, config, model_manager, preprocessor, team_models):\n",
    "        self.config = config\n",
    "        self.model_manager = model_manager\n",
    "        self.preprocessor = preprocessor\n",
    "        self.team_models = team_models\n",
    "    \n",
    "    def generate_video_summary(self, video_info: Dict) -> str:\n",
    "        video_info['description'] = self.preprocessor.clean_description(\n",
    "            video_info.get('description', '')\n",
    "        )\n",
    "        video_info['duration_seconds'] = self.preprocessor.parse_duration(\n",
    "            video_info.get('duration', 'PT0S')\n",
    "        )\n",
    "        \n",
    "        language = \"Korean\"\n",
    "        if self.config.detect_language:\n",
    "            title_lang = self.preprocessor.detect_language(video_info.get('title', ''))\n",
    "            desc_lang = self.preprocessor.detect_language(video_info.get('description', ''))\n",
    "            language = title_lang if title_lang != 'English' else desc_lang\n",
    "        \n",
    "        messages = PromptTemplates.get_video_summary_prompt(video_info, language)\n",
    "        \n",
    "        try:\n",
    "            summary = self.model_manager.generate(messages)\n",
    "            return summary.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error: {e}\")\n",
    "            return \"Summary generation failed.\"\n",
    "    \n",
    "    def generate_reaction_summary(self, title: str, comments: List[Dict]) -> str:\n",
    "        filtered_comments = self.preprocessor.filter_comments(comments)\n",
    "        \n",
    "        if not filtered_comments:\n",
    "            return \"No comments available.\"\n",
    "        \n",
    "        comments_text = self.preprocessor.format_comments_for_prompt(filtered_comments)\n",
    "        \n",
    "        language = \"Korean\"\n",
    "        if self.config.detect_language and filtered_comments:\n",
    "            sample_text = \" \".join([c.get('text', '') for c in filtered_comments[:5]])\n",
    "            language = self.preprocessor.detect_language(sample_text)\n",
    "        \n",
    "        messages = PromptTemplates.get_reaction_summary_prompt(title, comments_text, language)\n",
    "        \n",
    "        try:\n",
    "            summary = self.model_manager.generate(messages)\n",
    "            return summary.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error: {e}\")\n",
    "            return \"Reaction summary generation failed.\"\n",
    "    \n",
    "    def calculate_engagement_metrics(self, video_info: Dict) -> Dict:\n",
    "        views = video_info.get('view_count', 0)\n",
    "        likes = video_info.get('like_count', 0)\n",
    "        comments = video_info.get('comment_count', 0)\n",
    "        \n",
    "        engagement_rate = ((likes + comments) / views * 100) if views > 0 else 0\n",
    "        like_rate = (likes / views * 100) if views > 0 else 0\n",
    "        comment_rate = (comments / views * 100) if views > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'views': views,\n",
    "            'likes': likes,\n",
    "            'comments': comments,\n",
    "            'engagement_rate': round(engagement_rate, 2),\n",
    "            'like_rate': round(like_rate, 2),\n",
    "            'comment_rate': round(comment_rate, 2)\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Report generator class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_markdown_report(self, video_data: Dict, video_summary: str, \n",
    "                           reaction_summary: str, metrics: Dict,\n",
    "                           team_predictions: Dict = None) -> str:\n",
    "    video_info = video_data['video_info']\n",
    "    comments = video_data.get('comments', [])\n",
    "    \n",
    "    report = f\"\"\"# YouTube Video Report\n",
    "\n",
    "**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "**Model**: {self.config.model_name}\n",
    "\n",
    "---\n",
    "\n",
    "## üìπ Video Information\n",
    "\n",
    "- **Title**: {video_info.get('title', 'N/A')}\n",
    "- **Channel**: {video_info.get('channel_title', 'N/A')}\n",
    "- **Category**: {video_info.get('category_name', 'N/A')}\n",
    "- **Published**: {video_info.get('published_at', 'N/A')}\n",
    "- **Duration**: {self.preprocessor.parse_duration(video_info.get('duration', 'PT0S'))} seconds\n",
    "- **Video ID**: `{video_info.get('video_id', 'N/A')}`\n",
    "- **URL**: https://www.youtube.com/watch?v={video_info.get('video_id', '')}\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Engagement Metrics\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Views | {metrics['views']:,} |\n",
    "| Likes | {metrics['likes']:,} |\n",
    "| Comments | {metrics['comments']:,} |\n",
    "| Engagement Rate | {metrics['engagement_rate']}% |\n",
    "| Like Rate | {metrics['like_rate']}% |\n",
    "| Comment Rate | {metrics['comment_rate']}% |\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Video Summary\n",
    "\n",
    "{video_summary}\n",
    "\n",
    "---\n",
    "\n",
    "## üí¨ Audience Reaction Summary\n",
    "\n",
    "{reaction_summary}\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "    \n",
    "    if team_predictions:\n",
    "        report += \"\"\"## ü§ñ Team Model Predictions\\n\\n\"\"\"\n",
    "        if 'category' in team_predictions:\n",
    "            report += f\"- **Category**: {team_predictions['category']}\\n\"\n",
    "        if 'sentiment' in team_predictions:\n",
    "            s = team_predictions['sentiment']\n",
    "            report += f\"- **Sentiment**: Positive {s.get('positive',0):.0%}, \"\n",
    "            report += f\"Neutral {s.get('neutral',0):.0%}, Negative {s.get('negative',0):.0%}\\n\"\n",
    "        report += \"\\n---\\n\\n\"\n",
    "    \n",
    "    top_comments = self.preprocessor.filter_comments(comments)[:5]\n",
    "    if top_comments:\n",
    "        report += \"\"\"## üîç Top Comments\\n\\n\"\"\"\n",
    "        for i, c in enumerate(top_comments, 1):\n",
    "            text = c.get('text', '')[:200]\n",
    "            likes = c.get('like_count', 0)\n",
    "            author = c.get('author', 'Anonymous')\n",
    "            report += f\"{i}. **{author}** ({likes} likes): {text}...\\n\\n\"\n",
    "        report += \"---\\n\\n\"\n",
    "    \n",
    "    report += \"\"\"*Generated by YouTube Report Generator - Phase 2*\"\"\"\n",
    "    return report\n",
    "\n",
    "# Add method to ReportGenerator class\n",
    "ReportGenerator.format_markdown_report = format_markdown_report\n",
    "print(\"‚úÖ Report formatting method added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(self, video_data: Dict) -> str:\n",
    "    video_info = video_data['video_info']\n",
    "    comments = video_data.get('comments', [])\n",
    "    \n",
    "    print(f\"\\nüé¨ Processing: {video_info.get('title', 'Unknown')}\")\n",
    "    \n",
    "    print(\"  üìù Generating video summary...\")\n",
    "    video_summary = self.generate_video_summary(video_info)\n",
    "    \n",
    "    print(\"  üí¨ Generating reaction summary...\")\n",
    "    reaction_summary = self.generate_reaction_summary(\n",
    "        video_info.get('title', ''), comments\n",
    "    )\n",
    "    \n",
    "    print(\"  üìä Calculating metrics...\")\n",
    "    metrics = self.calculate_engagement_metrics(video_info)\n",
    "    \n",
    "    team_predictions = {}\n",
    "    if self.config.use_category_model:\n",
    "        pred = self.team_models.predict_category(video_info)\n",
    "        if pred:\n",
    "            team_predictions['category'] = pred\n",
    "    \n",
    "    if self.config.use_sentiment_model:\n",
    "        sent = self.team_models.analyze_sentiment(comments)\n",
    "        if sent:\n",
    "            team_predictions['sentiment'] = sent\n",
    "    \n",
    "    print(\"  üìÑ Formatting report...\")\n",
    "    report = self.format_markdown_report(\n",
    "        video_data, video_summary, reaction_summary, \n",
    "        metrics, team_predictions if team_predictions else None\n",
    "    )\n",
    "    \n",
    "    print(\"  ‚úÖ Done!\")\n",
    "    return report\n",
    "\n",
    "# Add method\n",
    "ReportGenerator.generate_report = generate_report\n",
    "\n",
    "# Initialize report generator\n",
    "report_generator = ReportGenerator(config, model_manager, preprocessor, team_models)\n",
    "print(\"‚úÖ Report generator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ 9. Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dataset = data_loader.get_data()\n",
    "\n",
    "# Select videos (start with 3 for testing)\n",
    "videos_to_process = dataset[:3]  # Change to dataset for all 20\n",
    "\n",
    "print(f\"\\nüéØ Processing {len(videos_to_process)} videos...\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate reports\n",
    "reports = []\n",
    "\n",
    "for i, video_data in enumerate(videos_to_process, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Video {i}/{len(videos_to_process)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        report = report_generator.generate_report(video_data)\n",
    "        reports.append({\n",
    "            'video_id': video_data['video_info']['video_id'],\n",
    "            'report': report\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úÖ Completed {len(reports)}/{len(videos_to_process)} videos\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ 10. Save Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if config.save_reports:\n",
    "    os.makedirs(config.output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nüíæ Saving to: {config.output_dir}/\")\n",
    "    \n",
    "    for report_data in reports:\n",
    "        video_id = report_data['video_id']\n",
    "        report = report_data['report']\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"{config.output_dir}/report_{video_id}_{timestamp}.md\"\n",
    "        \n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        print(f\"  ‚úÖ {filename}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ All reports saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 11. Display Sample Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reports:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Sample Report (First Video)\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    print(reports[0]['report'])\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No reports generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì 12. Usage Tips\n",
    "\n",
    "### Change Model\n",
    "```python\n",
    "config = PipelineConfig(\n",
    "    model_name=\"google/gemma-2-9b-it\"  # or other models\n",
    ")\n",
    "```\n",
    "\n",
    "### Customize Prompts\n",
    "```python\n",
    "PromptTemplates.VIDEO_SUMMARY_USER = \"\"\"Your custom prompt...\"\"\"\n",
    "```\n",
    "\n",
    "### Add Team Models\n",
    "```python\n",
    "config = PipelineConfig(\n",
    "    use_category_model=True,\n",
    "    category_model_path=\"path/to/model\"\n",
    ")\n",
    "```\n",
    "\n",
    "### Process All Videos\n",
    "```python\n",
    "videos_to_process = dataset  # All 20 videos\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Expected Performance**:\n",
    "- Korean quality: **6-8/10** (vs 0-2/10 Phase 1)\n",
    "- English quality: **7-9/10** (vs 4-8/10 Phase 1)\n",
    "- Time: ~2-3 min/video on T4 GPU\n",
    "\n",
    "**Next Steps**:\n",
    "1. Test with 3 sample videos\n",
    "2. Compare quality with Phase 1\n",
    "3. Try different models\n",
    "4. Tune prompts\n",
    "5. Integrate team models\n",
    "6. Process full dataset\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ **Phase 2 Full Pipeline Ready!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}