{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Overview\n",
    "\n",
    "Phase 1ì˜ ê°œì„  ë²„ì „ìœ¼ë¡œ, ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” ê°œì„ ì‚¬í•­ì„ í¬í•¨í•©ë‹ˆë‹¤:\n",
    "\n",
    "### Key Improvements\n",
    "- âœ… **Multilingual Support**: Llama-3.1-8B native multilingual understanding\n",
    "- âœ… **Fixed English Output**: All reports in English regardless of input language\n",
    "- âœ… **Code-switching Handling**: Understands mixed-language content naturally\n",
    "- âœ… **Modular Design**: ëª¨ë¸, í”„ë¡¬í”„íŠ¸, ì „ì²˜ë¦¬ ëª¨ë“ˆí™”\n",
    "- âœ… **Extensible Architecture**: Team model í†µí•© ì¤€ë¹„\n",
    "- âœ… **Better Preprocessing**: URL ì œê±°, ì–¸ì–´ ê°ì§€\n",
    "\n",
    "### Multilingual Processing\n",
    "- **Input**: Korean (í•œê¸€), English, Japanese (æ—¥æœ¬èª), Mixed languages\n",
    "- **Processing**: LLM native understanding (no translation layer)\n",
    "- **Output**: English (fixed)\n",
    "\n",
    "### Expected Quality\n",
    "- Korean input â†’ English output: **7-9/10**\n",
    "- English input â†’ English output: **8-9/10**\n",
    "- Mixed language input â†’ English output: **7-8/10**\n",
    "- Japanese input â†’ English output: **7-8/10**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers accelerate bitsandbytes torch\n",
    "!pip install -q langdetect isodate\n",
    "!pip install -q google-api-python-client  # For YouTube API (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import torch\n",
    "import isodate\n",
    "from langdetect import detect, LangDetectException\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ 2. Configuration\n",
    "\n",
    "ëª¨ë“  ì„¤ì •ì„ ì—¬ê¸°ì„œ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PipelineConfig:\n",
    "    \"\"\"ì „ì²´ íŒŒì´í”„ë¼ì¸ ì„¤ì •\"\"\"\n",
    "    \n",
    "    # Model Configuration\n",
    "    model_name: str = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "    use_4bit: bool = True\n",
    "    max_new_tokens: int = 512\n",
    "    temperature: float = 0.7\n",
    "    top_p: float = 0.9\n",
    "    \n",
    "    # Data Configuration\n",
    "    use_youtube_api: bool = False\n",
    "    youtube_api_key: Optional[str] = None\n",
    "    data_path: str = \"full_dataset_20251013_215347.json\"\n",
    "    \n",
    "    # Processing Configuration\n",
    "    max_description_length: int = 2000\n",
    "    max_comments_to_process: int = 50\n",
    "    min_comment_length: int = 10\n",
    "    remove_urls: bool = True\n",
    "    detect_language: bool = True  # Still detect for logging\n",
    "    \n",
    "    # Multilingual Configuration (NEW)\n",
    "    output_language: str = \"English\"  # Fixed output language\n",
    "    multilingual_understanding: bool = True  # LLM native multilingual\n",
    "    \n",
    "    # Team Model Integration\n",
    "    use_category_model: bool = False\n",
    "    use_sentiment_model: bool = False\n",
    "    category_model_path: Optional[str] = None\n",
    "    sentiment_model_path: Optional[str] = None\n",
    "    \n",
    "    # Output Configuration\n",
    "    output_format: str = \"markdown\"\n",
    "    save_reports: bool = True\n",
    "    output_dir: str = \"reports\"\n",
    "\n",
    "# Create configuration\n",
    "config = PipelineConfig(\n",
    "    model_name=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    use_4bit=True,\n",
    "    use_youtube_api=False,\n",
    "    data_path=\"full_dataset_20251013_215347.json\",\n",
    "    output_language=\"English\",  # NEW: Fixed to English\n",
    "    multilingual_understanding=True  # NEW: Enable multilingual\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Pipeline Configuration\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {config.model_name}\")\n",
    "print(f\"4-bit: {config.use_4bit}\")\n",
    "print(f\"Temperature: {config.temperature}\")\n",
    "print(f\"Output Language: {config.output_language}\")\n",
    "print(f\"Multilingual Understanding: {config.multilingual_understanding}\")\n",
    "print(f\"YouTube API: {config.use_youtube_api}\")\n",
    "print(f\"Category Model: {config.use_category_model}\")\n",
    "print(f\"Sentiment Model: {config.use_sentiment_model}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§© 3. Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptTemplates:\n",
    "    \"\"\"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê´€ë¦¬ (Multilingual Native)\"\"\"\n",
    "    \n",
    "    # ===== Video Summary Prompts =====\n",
    "    VIDEO_SUMMARY_SYSTEM = \"\"\"You are an expert multilingual content analyst specializing in YouTube video analysis.\n",
    "Your task is to understand content in ANY language (Korean, English, Japanese, or mixed) and create summaries in English.\n",
    "You have native-level understanding of multiple languages and can capture nuances across different cultures.\n",
    "Focus on accuracy and avoid hallucinations.\"\"\"\n",
    "    \n",
    "    VIDEO_SUMMARY_USER = \"\"\"Analyze this YouTube video and create a summary.\n",
    "\n",
    "Video Information:\n",
    "- Title: {title}\n",
    "- Description: {description}\n",
    "- Category: {category}\n",
    "- Duration: {duration} seconds\n",
    "- Channel: {channel}\n",
    "\n",
    "Context:\n",
    "The title and description may be in Korean (í•œê¸€), English, Japanese (æ—¥æœ¬èª), or mixed languages.\n",
    "Please understand the content in its original language(s) and provide your analysis.\n",
    "\n",
    "Instructions:\n",
    "1. Read and comprehend the content regardless of the language(s) used\n",
    "2. Understand cultural context and nuances in the original language\n",
    "3. Write a 3-5 sentence summary in ENGLISH\n",
    "4. Capture the key points, main theme, and purpose of the video\n",
    "5. Be accurate - do NOT make up information or misinterpret due to language barriers\n",
    "6. If description is minimal, acknowledge this limitation\n",
    "\n",
    "Summary (in English):\"\"\"\n",
    "    \n",
    "    # ===== Reaction Summary Prompts =====\n",
    "    REACTION_SUMMARY_SYSTEM = \"\"\"You are an expert in multilingual social media sentiment analysis.\n",
    "You can understand and analyze comments in Korean (í•œê¸€), English, Japanese (æ—¥æœ¬èª), and mixed languages.\n",
    "Your task is to capture audience reactions across all language communities and summarize in English.\"\"\"\n",
    "    \n",
    "    REACTION_SUMMARY_USER = \"\"\"Analyze these YouTube comments and summarize the audience reaction.\n",
    "\n",
    "Video: {title}\n",
    "\n",
    "Audience Comments:\n",
    "{comments}\n",
    "\n",
    "Context:\n",
    "These comments are from a multilingual audience and may include:\n",
    "- Korean (í•œê¸€) comments\n",
    "- English comments\n",
    "- Japanese (æ—¥æœ¬èª) comments\n",
    "- Mixed-language comments (e.g., \"ì´ ë…¸ë˜ ì§„ì§œ beautifulí•˜ë‹¤\" - Korean + English in one comment)\n",
    "- Code-switching between languages\n",
    "\n",
    "Your Task:\n",
    "Please analyze ALL comments by:\n",
    "1. Reading and understanding each comment in its original language(s)\n",
    "2. For mixed-language comments, understanding the complete meaning and emotional tone\n",
    "3. Identifying sentiment patterns (positive/negative/neutral) across all language groups\n",
    "4. Finding common themes and topics that appear across different languages\n",
    "5. Noting any cultural references or language-specific expressions\n",
    "\n",
    "Instructions:\n",
    "1. Comprehend ALL comments regardless of language\n",
    "2. Identify overall sentiment (positive, negative, or mixed)\n",
    "3. Highlight common themes that appear across language communities\n",
    "4. Mention notable reactions or insightful comments\n",
    "5. Write a 3-5 sentence summary in ENGLISH\n",
    "6. Be objective and balanced in capturing diverse reactions\n",
    "7. If different language communities show different reactions, mention this\n",
    "\n",
    "Audience Reaction Summary (in English):\"\"\"\n",
    "    \n",
    "    CUSTOM_PROMPT = None\n",
    "    \n",
    "    @classmethod\n",
    "    def get_video_summary_prompt(cls, video_info: Dict) -> List[Dict]:\n",
    "        \"\"\"Generate video summary prompt (language-agnostic)\"\"\"\n",
    "        if cls.CUSTOM_PROMPT:\n",
    "            return cls.CUSTOM_PROMPT\n",
    "        \n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": cls.VIDEO_SUMMARY_SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": cls.VIDEO_SUMMARY_USER.format(\n",
    "                title=video_info.get('title', 'N/A'),\n",
    "                description=video_info.get('description', 'N/A')[:2000],\n",
    "                category=video_info.get('category_name', 'N/A'),\n",
    "                duration=video_info.get('duration_seconds', 'N/A'),\n",
    "                channel=video_info.get('channel_title', 'N/A')\n",
    "            )}\n",
    "        ]\n",
    "    \n",
    "    @classmethod\n",
    "    def get_reaction_summary_prompt(cls, title: str, comments: str) -> List[Dict]:\n",
    "        \"\"\"Generate reaction summary prompt (language-agnostic)\"\"\"\n",
    "        if cls.CUSTOM_PROMPT:\n",
    "            return cls.CUSTOM_PROMPT\n",
    "        \n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": cls.REACTION_SUMMARY_SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": cls.REACTION_SUMMARY_USER.format(\n",
    "                title=title,\n",
    "                comments=comments\n",
    "            )}\n",
    "        ]\n",
    "\n",
    "print(\"âœ… Multilingual prompt templates loaded\")\n",
    "print(\"ğŸ“ Output language: English (fixed)\")\n",
    "print(\"ğŸŒ Input languages: Korean, English, Japanese, Mixed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸŒ Multilingual Processing Strategy\n",
    "\n",
    "**Approach**: LLM Native Multilingual Understanding\n",
    "\n",
    "**How it works:**\n",
    "1. **Input**: Content in ANY language (Korean, English, Japanese, Mixed)\n",
    "2. **Processing**: Llama-3.1-8B understands content in original language(s)\n",
    "3. **Output**: Summary always in English\n",
    "\n",
    "**Examples:**\n",
    "```\n",
    "Input:  \"NMIXX(ì—”ë¯¹ìŠ¤) 'Blue Valentine' M/V\"\n",
    "Output: \"This is NMIXX's music video for 'Blue Valentine'...\"\n",
    "\n",
    "Input:  \"ì´ ë…¸ë˜ ì§„ì§œ ì¢‹ë‹¤ I love it so much\"\n",
    "Output: \"Positive reaction praising the song...\"\n",
    "\n",
    "Input:  \"ã“ã®æ›²æœ€é«˜ï¼choreography ã‚‚ great\"\n",
    "Output: \"Enthusiastic praise for the song and choreography...\"\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- âœ… No translation layer needed\n",
    "- âœ… Preserves cultural context and nuances\n",
    "- âœ… Handles code-switching naturally\n",
    "- âœ… Fast and efficient (single LLM call)\n",
    "- âœ… Consistent English output for all reports\n",
    "\n",
    "**Language Detection:**\n",
    "- Still performed for logging/debugging\n",
    "- Helps monitor language distribution\n",
    "- Not used for prompt selection (English output always)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ 4. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    \"\"\"í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "        self.url_pattern = re.compile(r'http[s]?://\\S+')\n",
    "    \n",
    "    def remove_urls(self, text: str) -> str:\n",
    "        return self.url_pattern.sub('', text)\n",
    "    \n",
    "    def detect_language(self, text: str) -> str:\n",
    "        try:\n",
    "            lang = detect(text)\n",
    "            lang_map = {'ko': 'Korean', 'en': 'English', 'ja': 'Japanese'}\n",
    "            return lang_map.get(lang, 'English')\n",
    "        except:\n",
    "            return 'English'\n",
    "    \n",
    "    def clean_description(self, description: str) -> str:\n",
    "        if not description:\n",
    "            return \"No description available.\"\n",
    "        if self.config.remove_urls:\n",
    "            description = self.remove_urls(description)\n",
    "        description = ' '.join(description.split())\n",
    "        if len(description) > self.config.max_description_length:\n",
    "            description = description[:self.config.max_description_length] + \"...\"\n",
    "        if len(description.strip()) < 20:\n",
    "            return \"Minimal description available.\"\n",
    "        return description\n",
    "    \n",
    "    def filter_comments(self, comments: List[Dict]) -> List[Dict]:\n",
    "        filtered = [c for c in comments if len(c.get('text', '')) >= self.config.min_comment_length]\n",
    "        filtered.sort(key=lambda x: x.get('like_count', 0), reverse=True)\n",
    "        return filtered[:self.config.max_comments_to_process]\n",
    "    \n",
    "    def format_comments_for_prompt(self, comments: List[Dict]) -> str:\n",
    "        if not comments:\n",
    "            return \"No comments available.\"\n",
    "        formatted = []\n",
    "        for i, comment in enumerate(comments, 1):\n",
    "            text = comment.get('text', '')\n",
    "            likes = comment.get('like_count', 0)\n",
    "            if self.config.remove_urls:\n",
    "                text = self.remove_urls(text)\n",
    "            formatted.append(f\"{i}. [{likes} likes] {text}\")\n",
    "        return \"\\n\".join(formatted)\n",
    "    \n",
    "    def parse_duration(self, duration_str: str) -> int:\n",
    "        try:\n",
    "            duration = isodate.parse_duration(duration_str)\n",
    "            return int(duration.total_seconds())\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "preprocessor = TextPreprocessor(config)\n",
    "print(\"âœ… Text preprocessor initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– 5. Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManager:\n",
    "    \"\"\"LLM ëª¨ë¸ ê´€ë¦¬\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.pipe = None\n",
    "    \n",
    "    def load_model(self):\n",
    "        print(f\"\\nğŸ”„ Loading: {self.config.model_name}\")\n",
    "        print(f\"âš™ï¸ 4-bit: {self.config.use_4bit}\")\n",
    "        \n",
    "        # Tokenizer\n",
    "        print(\"Loading tokenizer...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            self.config.model_name, trust_remote_code=True\n",
    "        )\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Quantization config\n",
    "        if self.config.use_4bit:\n",
    "            quantization_config = BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_compute_dtype=torch.float16,\n",
    "                bnb_4bit_quant_type=\"nf4\",\n",
    "                bnb_4bit_use_double_quant=True\n",
    "            )\n",
    "        else:\n",
    "            quantization_config = None\n",
    "        \n",
    "        # Model\n",
    "        print(\"Loading model...\")\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.config.model_name,\n",
    "            quantization_config=quantization_config,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=torch.float16 if not self.config.use_4bit else None\n",
    "        )\n",
    "        \n",
    "        # Pipeline\n",
    "        print(\"Creating pipeline...\")\n",
    "        self.pipe = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_new_tokens=self.config.max_new_tokens,\n",
    "            temperature=self.config.temperature,\n",
    "            top_p=self.config.top_p,\n",
    "            do_sample=True,\n",
    "            pad_token_id=self.tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… Model loaded!\")\n",
    "    \n",
    "    def generate(self, messages: List[Dict]) -> str:\n",
    "        if self.pipe is None:\n",
    "            raise RuntimeError(\"Model not loaded\")\n",
    "        outputs = self.pipe(messages)\n",
    "        generated_text = outputs[0][\"generated_text\"]\n",
    "        if isinstance(generated_text, list):\n",
    "            return generated_text[-1][\"content\"]\n",
    "        return generated_text\n",
    "\n",
    "model_manager = ModelManager(config)\n",
    "model_manager.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”Œ 6. Team Model Integration (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeamModelIntegration:\n",
    "    \"\"\"íŒ€ ëª¨ë¸ í†µí•© ì¸í„°í˜ì´ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "        self.category_model = None\n",
    "        self.sentiment_model = None\n",
    "    \n",
    "    def load_category_model(self):\n",
    "        if not self.config.use_category_model:\n",
    "            return\n",
    "        # TODO: íŒ€ì› êµ¬í˜„\n",
    "        print(\"âš ï¸ Category model not implemented yet\")\n",
    "    \n",
    "    def load_sentiment_model(self):\n",
    "        if not self.config.use_sentiment_model:\n",
    "            return\n",
    "        # TODO: íŒ€ì› êµ¬í˜„\n",
    "        print(\"âš ï¸ Sentiment model not implemented yet\")\n",
    "    \n",
    "    def predict_category(self, video_info: Dict) -> Optional[str]:\n",
    "        if not self.config.use_category_model or self.category_model is None:\n",
    "            return None\n",
    "        # TODO: ëª¨ë¸ inference\n",
    "        return None\n",
    "    \n",
    "    def analyze_sentiment(self, comments: List[Dict]) -> Optional[Dict]:\n",
    "        if not self.config.use_sentiment_model or self.sentiment_model is None:\n",
    "            return None\n",
    "        # TODO: ëª¨ë¸ inference\n",
    "        return None\n",
    "\n",
    "team_models = TeamModelIntegration(config)\n",
    "team_models.load_category_model()\n",
    "team_models.load_sentiment_model()\n",
    "print(\"âœ… Team model interface ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ 7. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def load_from_file(self, file_path: str) -> List[Dict]:\n",
    "        print(f\"\\nğŸ“‚ Loading: {file_path}\")\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"âœ… Loaded {len(data)} videos\")\n",
    "        return data\n",
    "    \n",
    "    def get_data(self) -> List[Dict]:\n",
    "        if self.config.use_youtube_api:\n",
    "            raise NotImplementedError(\"YouTube API not implemented yet\")\n",
    "        return self.load_from_file(self.config.data_path)\n",
    "\n",
    "data_loader = DataLoader(config)\n",
    "print(\"âœ… Data loader ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¬ 8. Report Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportGenerator:\n",
    "    def __init__(self, config, model_manager, preprocessor, team_models):\n",
    "        self.config = config\n",
    "        self.model_manager = model_manager\n",
    "        self.preprocessor = preprocessor\n",
    "        self.team_models = team_models\n",
    "    \n",
    "    def generate_video_summary(self, video_info: Dict) -> str:\n",
    "        \"\"\"Generate video summary (multilingual input â†’ English output)\"\"\"\n",
    "        # Preprocess\n",
    "        video_info['description'] = self.preprocessor.clean_description(\n",
    "            video_info.get('description', '')\n",
    "        )\n",
    "        video_info['duration_seconds'] = self.preprocessor.parse_duration(\n",
    "            video_info.get('duration', 'PT0S')\n",
    "        )\n",
    "        \n",
    "        # Detect language for logging purposes\n",
    "        if self.config.detect_language:\n",
    "            detected_lang = self.preprocessor.detect_language(\n",
    "                video_info.get('title', '') + ' ' + video_info.get('description', '')[:500]\n",
    "            )\n",
    "            print(f\"    [Detected input language: {detected_lang}]\")\n",
    "        \n",
    "        # Generate prompt (no language parameter - LLM handles multilingual)\n",
    "        messages = PromptTemplates.get_video_summary_prompt(video_info)\n",
    "        \n",
    "        # Generate summary\n",
    "        try:\n",
    "            summary = self.model_manager.generate(messages)\n",
    "            print(f\"    [Output language: {self.config.output_language}]\")\n",
    "            return summary.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error: {e}\")\n",
    "            return \"Summary generation failed.\"\n",
    "    \n",
    "    def generate_reaction_summary(self, title: str, comments: List[Dict]) -> str:\n",
    "        \"\"\"Generate reaction summary (multilingual input â†’ English output)\"\"\"\n",
    "        # Filter and format comments\n",
    "        filtered_comments = self.preprocessor.filter_comments(comments)\n",
    "        \n",
    "        if not filtered_comments:\n",
    "            return \"No comments available.\"\n",
    "        \n",
    "        comments_text = self.preprocessor.format_comments_for_prompt(filtered_comments)\n",
    "        \n",
    "        # Detect language distribution for logging\n",
    "        if self.config.detect_language:\n",
    "            sample_texts = [c.get('text', '')[:100] for c in filtered_comments[:10]]\n",
    "            langs = [self.preprocessor.detect_language(t) for t in sample_texts if t]\n",
    "            lang_dist = {}\n",
    "            for lang in langs:\n",
    "                lang_dist[lang] = lang_dist.get(lang, 0) + 1\n",
    "            print(f\"    [Comment languages: {lang_dist}]\")\n",
    "        \n",
    "        # Generate prompt (no language parameter)\n",
    "        messages = PromptTemplates.get_reaction_summary_prompt(title, comments_text)\n",
    "        \n",
    "        # Generate summary\n",
    "        try:\n",
    "            summary = self.model_manager.generate(messages)\n",
    "            print(f\"    [Output language: {self.config.output_language}]\")\n",
    "            return summary.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error: {e}\")\n",
    "            return \"Reaction summary generation failed.\"\n",
    "    \n",
    "    def calculate_engagement_metrics(self, video_info: Dict) -> Dict:\n",
    "        views = video_info.get('view_count', 0)\n",
    "        likes = video_info.get('like_count', 0)\n",
    "        comments = video_info.get('comment_count', 0)\n",
    "        \n",
    "        engagement_rate = ((likes + comments) / views * 100) if views > 0 else 0\n",
    "        like_rate = (likes / views * 100) if views > 0 else 0\n",
    "        comment_rate = (comments / views * 100) if views > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'views': views,\n",
    "            'likes': likes,\n",
    "            'comments': comments,\n",
    "            'engagement_rate': round(engagement_rate, 2),\n",
    "            'like_rate': round(like_rate, 2),\n",
    "            'comment_rate': round(comment_rate, 2)\n",
    "        }\n",
    "\n",
    "print(\"âœ… Report generator class defined (multilingual)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_markdown_report(self, video_data: Dict, video_summary: str, \n",
    "                           reaction_summary: str, metrics: Dict,\n",
    "                           team_predictions: Dict = None) -> str:\n",
    "    video_info = video_data['video_info']\n",
    "    comments = video_data.get('comments', [])\n",
    "    \n",
    "    report = f\"\"\"# YouTube Video Report\n",
    "\n",
    "**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "**Model**: {self.config.model_name}\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“¹ Video Information\n",
    "\n",
    "- **Title**: {video_info.get('title', 'N/A')}\n",
    "- **Channel**: {video_info.get('channel_title', 'N/A')}\n",
    "- **Category**: {video_info.get('category_name', 'N/A')}\n",
    "- **Published**: {video_info.get('published_at', 'N/A')}\n",
    "- **Duration**: {self.preprocessor.parse_duration(video_info.get('duration', 'PT0S'))} seconds\n",
    "- **Video ID**: `{video_info.get('video_id', 'N/A')}`\n",
    "- **URL**: https://www.youtube.com/watch?v={video_info.get('video_id', '')}\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š Engagement Metrics\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Views | {metrics['views']:,} |\n",
    "| Likes | {metrics['likes']:,} |\n",
    "| Comments | {metrics['comments']:,} |\n",
    "| Engagement Rate | {metrics['engagement_rate']}% |\n",
    "| Like Rate | {metrics['like_rate']}% |\n",
    "| Comment Rate | {metrics['comment_rate']}% |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Video Summary\n",
    "\n",
    "{video_summary}\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¬ Audience Reaction Summary\n",
    "\n",
    "{reaction_summary}\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "    \n",
    "    if team_predictions:\n",
    "        report += \"\"\"## ğŸ¤– Team Model Predictions\\n\\n\"\"\"\n",
    "        if 'category' in team_predictions:\n",
    "            report += f\"- **Category**: {team_predictions['category']}\\n\"\n",
    "        if 'sentiment' in team_predictions:\n",
    "            s = team_predictions['sentiment']\n",
    "            report += f\"- **Sentiment**: Positive {s.get('positive',0):.0%}, \"\n",
    "            report += f\"Neutral {s.get('neutral',0):.0%}, Negative {s.get('negative',0):.0%}\\n\"\n",
    "        report += \"\\n---\\n\\n\"\n",
    "    \n",
    "    top_comments = self.preprocessor.filter_comments(comments)[:5]\n",
    "    if top_comments:\n",
    "        report += \"\"\"## ğŸ” Top Comments\\n\\n\"\"\"\n",
    "        for i, c in enumerate(top_comments, 1):\n",
    "            text = c.get('text', '')[:200]\n",
    "            likes = c.get('like_count', 0)\n",
    "            author = c.get('author', 'Anonymous')\n",
    "            report += f\"{i}. **{author}** ({likes} likes): {text}...\\n\\n\"\n",
    "        report += \"---\\n\\n\"\n",
    "    \n",
    "    report += \"\"\"*Generated by YouTube Report Generator - Phase 2*\"\"\"\n",
    "    return report\n",
    "\n",
    "# Add method to ReportGenerator class\n",
    "ReportGenerator.format_markdown_report = format_markdown_report\n",
    "print(\"âœ… Report formatting method added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(self, video_data: Dict) -> str:\n",
    "    video_info = video_data['video_info']\n",
    "    comments = video_data.get('comments', [])\n",
    "    \n",
    "    print(f\"\\nğŸ¬ Processing: {video_info.get('title', 'Unknown')}\")\n",
    "    \n",
    "    print(\"  ğŸ“ Generating video summary...\")\n",
    "    video_summary = self.generate_video_summary(video_info)\n",
    "    \n",
    "    print(\"  ğŸ’¬ Generating reaction summary...\")\n",
    "    reaction_summary = self.generate_reaction_summary(\n",
    "        video_info.get('title', ''), comments\n",
    "    )\n",
    "    \n",
    "    print(\"  ğŸ“Š Calculating metrics...\")\n",
    "    metrics = self.calculate_engagement_metrics(video_info)\n",
    "    \n",
    "    team_predictions = {}\n",
    "    if self.config.use_category_model:\n",
    "        pred = self.team_models.predict_category(video_info)\n",
    "        if pred:\n",
    "            team_predictions['category'] = pred\n",
    "    \n",
    "    if self.config.use_sentiment_model:\n",
    "        sent = self.team_models.analyze_sentiment(comments)\n",
    "        if sent:\n",
    "            team_predictions['sentiment'] = sent\n",
    "    \n",
    "    print(\"  ğŸ“„ Formatting report...\")\n",
    "    report = self.format_markdown_report(\n",
    "        video_data, video_summary, reaction_summary, \n",
    "        metrics, team_predictions if team_predictions else None\n",
    "    )\n",
    "    \n",
    "    print(\"  âœ… Done!\")\n",
    "    return report\n",
    "\n",
    "# Add method\n",
    "ReportGenerator.generate_report = generate_report\n",
    "\n",
    "# Initialize report generator\n",
    "report_generator = ReportGenerator(config, model_manager, preprocessor, team_models)\n",
    "print(\"âœ… Report generator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ 9. Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dataset = data_loader.get_data()\n",
    "\n",
    "# Select videos (start with 3 for testing)\n",
    "videos_to_process = dataset[:3]  # Change to dataset for all 20\n",
    "\n",
    "print(f\"\\nğŸ¯ Processing {len(videos_to_process)} videos...\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate reports\n",
    "reports = []\n",
    "\n",
    "for i, video_data in enumerate(videos_to_process, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Video {i}/{len(videos_to_process)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        report = report_generator.generate_report(video_data)\n",
    "        reports.append({\n",
    "            'video_id': video_data['video_info']['video_id'],\n",
    "            'report': report\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"âœ… Completed {len(reports)}/{len(videos_to_process)} videos\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ 10. Save Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if config.save_reports:\n",
    "    os.makedirs(config.output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ Saving to: {config.output_dir}/\")\n",
    "    \n",
    "    for report_data in reports:\n",
    "        video_id = report_data['video_id']\n",
    "        report = report_data['report']\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"{config.output_dir}/report_{video_id}_{timestamp}.md\"\n",
    "        \n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        print(f\"  âœ… {filename}\")\n",
    "    \n",
    "    print(f\"\\nâœ… All reports saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š 11. Display Sample Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reports:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Sample Report (First Video)\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    print(reports[0]['report'])\n",
    "else:\n",
    "    print(\"âš ï¸ No reports generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ 12. Usage Tips\n",
    "\n",
    "### ğŸŒ Multilingual Processing\n",
    "\n",
    "**The pipeline automatically handles:**\n",
    "```python\n",
    "# Korean video â†’ English report\n",
    "Input:  Title: \"NMIXX(ì—”ë¯¹ìŠ¤) 'Blue Valentine' M/V\"\n",
    "        Comments: \"ì´ ë…¸ë˜ ì§„ì§œ ì¢‹ë‹¤\", \"ì™„ì „ ëŒ€ë°•\"\n",
    "Output: English summary capturing all Korean content\n",
    "\n",
    "# Mixed language â†’ English report  \n",
    "Input:  Comments: \"ì´ ë…¸ë˜ beautifulí•˜ë‹¤\", \"choreography ì§„ì§œ amazing\"\n",
    "Output: English summary understanding code-switching\n",
    "\n",
    "# Japanese â†’ English report\n",
    "Input:  Comments: \"ã“ã®æ›²æœ€é«˜ï¼\", \"lyrics ã‚‚ç´ æ™´ã‚‰ã—ã„\"\n",
    "Output: English summary from Japanese reactions\n",
    "```\n",
    "\n",
    "**Configuration:**\n",
    "```python\n",
    "config = PipelineConfig(\n",
    "    output_language=\"English\",           # Fixed output\n",
    "    multilingual_understanding=True,     # Enable LLM native multilingual\n",
    "    detect_language=True                 # For logging only\n",
    ")\n",
    "```\n",
    "\n",
    "### ğŸ”§ Change Model\n",
    "```python\n",
    "config = PipelineConfig(\n",
    "    model_name=\"google/gemma-2-9b-it\"  # or other models\n",
    ")\n",
    "```\n",
    "\n",
    "### ğŸ“ Customize Prompts\n",
    "```python\n",
    "# Modify multilingual instructions\n",
    "PromptTemplates.VIDEO_SUMMARY_USER = \"\"\"Your custom prompt...\"\"\"\n",
    "\n",
    "# Add more languages\n",
    "PromptTemplates.VIDEO_SUMMARY_SYSTEM = \"\"\"\n",
    "You understand Korean, English, Japanese, Chinese, Spanish...\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### ğŸ¤– Add Team Models\n",
    "```python\n",
    "config = PipelineConfig(\n",
    "    use_category_model=True,\n",
    "    category_model_path=\"path/to/model\"\n",
    ")\n",
    "```\n",
    "\n",
    "### ğŸ“Š Process All Videos\n",
    "```python\n",
    "videos_to_process = dataset  # All 20 videos\n",
    "```\n",
    "\n",
    "### ğŸ› Debugging Multilingual Issues\n",
    "\n",
    "**Check language detection logs:**\n",
    "```\n",
    "ğŸ¬ Processing: NMIXX(ì—”ë¯¹ìŠ¤) \"Blue Valentine\" M/V\n",
    "  ğŸ“ Generating video summary...\n",
    "    [Detected input language: Korean]    â† Input language\n",
    "    [Output language: English]           â† Output fixed\n",
    "  ğŸ’¬ Generating reaction summary...\n",
    "    [Comment languages: {'English': 7, 'Korean': 3}]  â† Language mix\n",
    "    [Output language: English]\n",
    "```\n",
    "\n",
    "**If output quality is poor:**\n",
    "1. Check if input language is too rare (e.g., not Korean/English/Japanese)\n",
    "2. Try adjusting temperature (lower = more deterministic)\n",
    "3. Add language-specific examples to prompt\n",
    "4. Consider Option 3 (pre-translation) for very rare languages\n",
    "\n",
    "---\n",
    "\n",
    "**Expected Performance**:\n",
    "- Korean â†’ English quality: **7-9/10** (vs 0-2/10 Phase 1)\n",
    "- English â†’ English quality: **8-9/10** (vs 4-8/10 Phase 1)\n",
    "- Mixed language quality: **7-8/10** (NEW)\n",
    "- Time: ~2-3 min/video on T4 GPU\n",
    "\n",
    "**Next Steps**:\n",
    "1. Test with 3 sample videos (different languages)\n",
    "2. Verify all outputs are in English\n",
    "3. Check if multilingual content is understood correctly\n",
    "4. Compare with Phase 1 quality\n",
    "5. Try different models if needed\n",
    "6. Process full dataset\n",
    "\n",
    "---\n",
    "\n",
    "âœ… **Phase 2 Full Pipeline with Multilingual Support Ready!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}