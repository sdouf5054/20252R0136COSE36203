{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "overview"
      },
      "source": [
        "# YouTube Report Generator - Part 1: Setup & Preprocessing\n",
        "\n",
        "This notebook contains environment setup, configuration, and preprocessing utilities.\n",
        "\n",
        "**Pipeline Structure:**\n",
        "- **Part 1** (this file): Setup, configuration, utilities, data loading\n",
        "- **Part 2**: Category and Sentiment model initialization\n",
        "- **Part 3**: Full pipeline execution and report generation\n",
        "\n",
        "Run all cells in order before proceeding to Part 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mount_drive",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "5e6ed51b-7617-46c9-98f5-11fc3bb65f17"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "install_packages",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f203fd2-8878-4552-92b3-78a65c5efcec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers accelerate bitsandbytes torch\n",
        "!pip install -q langdetect isodate\n",
        "!pip install -q google-api-python-client\n",
        "!pip install -q imbalanced-learn datasets seaborn scikit-learn scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "imports",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "094c2e98-73e4-4003-f7ea-4f54df06d3c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "CUDA device: NVIDIA L4\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import isodate\n",
        "from langdetect import detect, LangDetectException\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    pipeline\n",
        ")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "config_section"
      },
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pipeline_config",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c191af43-ef6f-4bf1-f0ce-1a8a2e39b974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Pipeline Configuration\n",
            "============================================================\n",
            "Model: meta-llama/Llama-3.1-8B-Instruct\n",
            "4-bit quantization: True\n",
            "Output Language: English\n",
            "Test Videos: 3\n",
            "Max Comments: 100\n",
            "Token Efficiency: True (Mode: adaptive)\n",
            "Quality Gate: True\n",
            "Category Model: True\n",
            "Sentiment Model: True\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class PipelineConfig:\n",
        "    \"\"\"Full pipeline configuration\"\"\"\n",
        "\n",
        "    # Model settings\n",
        "    model_name: str = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "    use_4bit: bool = True\n",
        "    max_new_tokens: int = 512\n",
        "    temperature: float = 0.7\n",
        "    top_p: float = 0.9\n",
        "\n",
        "    # Data settings\n",
        "    use_youtube_api: bool = False\n",
        "    youtube_api_key: Optional[str] = None\n",
        "    data_path: str = \"/content/drive/MyDrive/25_sch/ML/youtube_test_10132154/full_dataset_20251013_215347.json\"\n",
        "\n",
        "    # Processing settings\n",
        "    max_description_length: int = 2000\n",
        "    max_comments_to_process: int = 100\n",
        "    min_comment_length: int = 10\n",
        "    remove_urls: bool = True\n",
        "    detect_language: bool = True\n",
        "\n",
        "    # Output settings\n",
        "    output_language: str = \"English\"\n",
        "    multilingual_understanding: bool = True\n",
        "\n",
        "    # Test settings\n",
        "    num_videos_for_test: int = 3\n",
        "    enable_detailed_logging: bool = True\n",
        "    log_token_counts: bool = True\n",
        "\n",
        "    # Token efficiency settings\n",
        "    enable_dynamic_tokens: bool = True\n",
        "    token_efficiency_mode: str = \"adaptive\"  # 'adaptive', 'conservative', 'aggressive'\n",
        "\n",
        "    # Quality gate settings\n",
        "    enable_quality_gate: bool = True\n",
        "    min_summary_length: int = 100\n",
        "    min_keyword_diversity: int = 10\n",
        "    max_regeneration_attempts: int = 2\n",
        "    quality_gate_temperature: float = 0.5\n",
        "\n",
        "    # Category model settings\n",
        "    use_category_model: bool = True\n",
        "    category_model_path: Optional[str] = \"/content/drive/MyDrive/25_sch/ML/models\"\n",
        "    enable_llm_category_correction: bool = True\n",
        "\n",
        "    # Sentiment model settings\n",
        "    use_sentiment_model: bool = True\n",
        "    sentiment_root_dir: str = \"./models/sentiment\"\n",
        "    sentiment_model_path: str = \"./models/sentiment/bert_sentiment\"\n",
        "    sentiment_zip_path: str = \"/content/drive/MyDrive/25_sch/ML/sentiment/bert_sentiment.zip\"\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.use_youtube_api and not self.youtube_api_key:\n",
        "            raise ValueError(\"YouTube API key is required when use_youtube_api=True\")\n",
        "\n",
        "\n",
        "# Create global config instance\n",
        "config = PipelineConfig()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Pipeline Configuration\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Model: {config.model_name}\")\n",
        "print(f\"4-bit quantization: {config.use_4bit}\")\n",
        "print(f\"Output Language: {config.output_language}\")\n",
        "print(f\"Test Videos: {config.num_videos_for_test}\")\n",
        "print(f\"Max Comments: {config.max_comments_to_process}\")\n",
        "print(f\"Token Efficiency: {config.enable_dynamic_tokens} (Mode: {config.token_efficiency_mode})\")\n",
        "print(f\"Quality Gate: {config.enable_quality_gate}\")\n",
        "print(f\"Category Model: {config.use_category_model}\")\n",
        "print(f\"Sentiment Model: {config.use_sentiment_model}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prompts_section"
      },
      "source": [
        "## 3. Prompt Templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "prompt_templates",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac53efe-d410-4ecd-8484-02ce72b7811a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt templates loaded\n"
          ]
        }
      ],
      "source": [
        "class PromptTemplates:\n",
        "    \"\"\"Prompt templates for video analysis\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_video_summary_prompt(title: str, description: str, category_id: str,\n",
        "                                  duration: str, output_lang: str = \"English\") -> str:\n",
        "        \"\"\"Video summary prompt with two-part structure\"\"\"\n",
        "        return f\"\"\"You are analyzing a YouTube video. Based on the information provided, create a comprehensive summary in {output_lang}.\n",
        "\n",
        "Video Information:\n",
        "- Title: {title}\n",
        "- Description: {description}\n",
        "- Category ID: {category_id}\n",
        "- Duration: {duration}\n",
        "\n",
        "Instructions:\n",
        "1. First, provide a KEY POINT (1-2 sentences) that captures the video's essence\n",
        "2. Then, provide a DETAILED SUMMARY (3-5 sentences) with more context\n",
        "3. Write ONLY in {output_lang}, regardless of the input language\n",
        "4. Focus on what viewers will learn or experience\n",
        "5. Be concise and informative\n",
        "\n",
        "Format your response EXACTLY as:\n",
        "KEY POINT:\n",
        "[Your 1-2 sentence key point here]\n",
        "\n",
        "DETAILED SUMMARY:\n",
        "[Your 3-5 sentence detailed summary here]\n",
        "\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_reaction_summary_prompt(comments: List[str], output_lang: str = \"English\") -> str:\n",
        "        \"\"\"Reaction summary prompt with sentiment analysis\"\"\"\n",
        "        comments_text = \"\\n\".join([f\"- {c}\" for c in comments[:100]])\n",
        "        return f\"\"\"You are analyzing audience reactions to a YouTube video. Based on the comments provided, create a comprehensive reaction summary in {output_lang}.\n",
        "\n",
        "Comments:\n",
        "{comments_text}\n",
        "\n",
        "Instructions:\n",
        "1. First, provide a KEY POINT (1-2 sentences) about the overall reaction\n",
        "2. Then, provide a DETAILED SUMMARY (3-5 sentences) with:\n",
        "   - Majority opinion (what most viewers think)\n",
        "   - Notable minority views (outliers, different perspectives)\n",
        "   - Language patterns (if mixed Korean/English/Japanese, note code-switching)\n",
        "3. After the summary, provide a SENTIMENT BREAKDOWN estimate:\n",
        "   Positive: X%  Negative: Y%  Neutral: Z%\n",
        "4. Write ONLY in {output_lang}, regardless of comment languages\n",
        "5. Ignore spam, absurd, or irrelevant comments (<5% outliers)\n",
        "\n",
        "Format your response EXACTLY as:\n",
        "KEY POINT:\n",
        "[Your 1-2 sentence key point here]\n",
        "\n",
        "DETAILED SUMMARY:\n",
        "[Your 3-5 sentence detailed analysis here]\n",
        "\n",
        "SENTIMENT BREAKDOWN:\n",
        "Positive: X%  Negative: Y%  Neutral: Z%\n",
        "\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_category_correction_prompt(title: str, description: str,\n",
        "                                       predicted_category: int) -> str:\n",
        "        \"\"\"Category validation prompt\"\"\"\n",
        "        return f\"\"\"You are reviewing a video category classification.\n",
        "\n",
        "Video Information:\n",
        "- Title: {title}\n",
        "- Description: {description[:500]}\n",
        "- Model Predicted Category: {predicted_category}\n",
        "\n",
        "Valid Categories:\n",
        "1: Film & Animation, 2: Autos & Vehicles, 10: Music, 15: Pets & Animals,\n",
        "17: Sports, 19: Travel & Events, 20: Gaming, 22: People & Blogs,\n",
        "23: Comedy, 24: Entertainment, 25: News & Politics, 26: HowTo & Style,\n",
        "27: Education, 28: Science & Tech\n",
        "\n",
        "Task: Review if the predicted category is appropriate. Respond with ONLY:\n",
        "- \"CORRECT\" if the prediction is appropriate\n",
        "- \"CORRECT: [category_id]\" if you suggest a different category (use the number)\n",
        "\n",
        "Example responses:\n",
        "- \"CORRECT\" (if prediction is good)\n",
        "- \"CORRECT: 10\" (if Music is more appropriate)\n",
        "\"\"\"\n",
        "\n",
        "print(\"Prompt templates loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preprocessing_section"
      },
      "source": [
        "## 4. Text Preprocessing Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "text_preprocessor",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d86c2d3c-e9d8-4411-f002-0c4b9b769e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text preprocessing utilities loaded\n"
          ]
        }
      ],
      "source": [
        "class TextPreprocessor:\n",
        "    \"\"\"Text preprocessing utilities\"\"\"\n",
        "\n",
        "    # Language name mapping\n",
        "    LANG_NAMES = {\n",
        "        'ko': 'Korean', 'en': 'English', 'ja': 'Japanese',\n",
        "        'zh-cn': 'Chinese (Simplified)', 'zh-tw': 'Chinese (Traditional)',\n",
        "        'de': 'German', 'fr': 'French', 'es': 'Spanish',\n",
        "        'it': 'Italian', 'pt': 'Portuguese', 'ru': 'Russian',\n",
        "        'ar': 'Arabic', 'hi': 'Hindi', 'th': 'Thai', 'vi': 'Vietnamese',\n",
        "        'nl': 'Dutch', 'pl': 'Polish', 'tr': 'Turkish',\n",
        "        'sv': 'Swedish', 'da': 'Danish', 'no': 'Norwegian', 'fi': 'Finnish',\n",
        "        'cs': 'Czech', 'hu': 'Hungarian', 'ro': 'Romanian', 'uk': 'Ukrainian',\n",
        "        'el': 'Greek', 'he': 'Hebrew', 'af': 'Afrikaans', 'ca': 'Catalan',\n",
        "        'hr': 'Croatian', 'sr': 'Serbian', 'sk': 'Slovak', 'sl': 'Slovenian',\n",
        "        'et': 'Estonian', 'lv': 'Latvian', 'lt': 'Lithuanian', 'bg': 'Bulgarian',\n",
        "        'fa': 'Persian', 'ur': 'Urdu', 'bn': 'Bengali', 'ta': 'Tamil',\n",
        "        'te': 'Telugu', 'mr': 'Marathi', 'kn': 'Kannada',\n",
        "        'ml': 'Malayalam', 'gu': 'Gujarati'\n",
        "    }\n",
        "\n",
        "    @staticmethod\n",
        "    def remove_urls(text: str) -> str:\n",
        "        \"\"\"Remove URLs from text\"\"\"\n",
        "        url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
        "        return re.sub(url_pattern, '', text)\n",
        "\n",
        "    @staticmethod\n",
        "    def clean_text(text: str, remove_urls: bool = True) -> str:\n",
        "        \"\"\"Clean text by removing URLs and extra whitespace\"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "        if remove_urls:\n",
        "            text = TextPreprocessor.remove_urls(text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        return text.strip()\n",
        "\n",
        "    @staticmethod\n",
        "    def detect_language(text: str) -> str:\n",
        "        \"\"\"Detect text language and return full name\"\"\"\n",
        "        try:\n",
        "            if not text or len(text.strip()) < 10:\n",
        "                return \"Unknown\"\n",
        "            lang = detect(text)\n",
        "            return TextPreprocessor.LANG_NAMES.get(lang, lang.title())\n",
        "        except LangDetectException:\n",
        "            return \"Unknown\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_language_distribution(texts: List[str]) -> Dict[str, int]:\n",
        "        \"\"\"Calculate language distribution for a list of texts\"\"\"\n",
        "        lang_dist = {}\n",
        "        for text in texts:\n",
        "            lang = TextPreprocessor.detect_language(text)\n",
        "            lang_dist[lang] = lang_dist.get(lang, 0) + 1\n",
        "        return lang_dist\n",
        "\n",
        "print(\"Text preprocessing utilities loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_manager_section"
      },
      "source": [
        "## 5. Model Manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "model_manager",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f574aa1-9185-4bcd-8898-d4753a9b8a1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ModelManager loaded\n"
          ]
        }
      ],
      "source": [
        "class ModelManager:\n",
        "    \"\"\"LLM model manager with token efficiency tracking\"\"\"\n",
        "\n",
        "    def __init__(self, config: PipelineConfig):\n",
        "        self.config = config\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.pipe = None\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.token_stats = {\n",
        "            \"total_input_tokens\": 0,\n",
        "            \"total_output_tokens\": 0,\n",
        "            \"total_calls\": 0,\n",
        "            \"tokens_saved\": 0\n",
        "        }\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load model with optional 4-bit quantization\"\"\"\n",
        "        print(f\"Loading {self.config.model_name}...\")\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            self.config.model_name,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        if self.config.use_4bit:\n",
        "            bnb_config = BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_quant_type=\"nf4\",\n",
        "                bnb_4bit_compute_dtype=torch.float16,\n",
        "                bnb_4bit_use_double_quant=True\n",
        "            )\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.config.model_name,\n",
        "                quantization_config=bnb_config,\n",
        "                device_map=\"auto\",\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "        else:\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.config.model_name,\n",
        "                torch_dtype=torch.float16,\n",
        "                device_map=\"auto\",\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "        self.pipe = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=self.model,\n",
        "            tokenizer=self.tokenizer,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "\n",
        "        print(f\"Model loaded on {self.device}\")\n",
        "        print(f\"Memory allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
        "\n",
        "    def dynamic_max_tokens(self, input_length: int) -> int:\n",
        "        \"\"\"Calculate dynamic token limit based on input length\"\"\"\n",
        "        if not self.config.enable_dynamic_tokens:\n",
        "            return self.config.max_new_tokens\n",
        "\n",
        "        mode = self.config.token_efficiency_mode\n",
        "        if mode == \"conservative\":\n",
        "            if input_length < 500:\n",
        "                return 320\n",
        "            elif input_length < 1500:\n",
        "                return 448\n",
        "            return 512\n",
        "        elif mode == \"aggressive\":\n",
        "            if input_length < 500:\n",
        "                return 192\n",
        "            elif input_length < 1500:\n",
        "                return 320\n",
        "            return 448\n",
        "        else:  # adaptive (default)\n",
        "            if input_length < 500:\n",
        "                return 256\n",
        "            elif input_length < 1500:\n",
        "                return 384\n",
        "            return 512\n",
        "\n",
        "    def generate(self, prompt: str, temperature: Optional[float] = None,\n",
        "                 force_max_tokens: Optional[int] = None) -> str:\n",
        "        \"\"\"Generate text with dynamic token allocation\"\"\"\n",
        "        if self.pipe is None:\n",
        "            raise RuntimeError(\"Model not loaded. Call load_model() first.\")\n",
        "\n",
        "        input_tokens = len(self.tokenizer.encode(prompt))\n",
        "        max_tokens = force_max_tokens if force_max_tokens else self.dynamic_max_tokens(input_tokens)\n",
        "        tokens_saved = self.config.max_new_tokens - max_tokens\n",
        "\n",
        "        if self.config.enable_dynamic_tokens and tokens_saved > 0:\n",
        "            self.token_stats[\"tokens_saved\"] += tokens_saved\n",
        "\n",
        "        if self.config.log_token_counts:\n",
        "            print(f\"      [Input: {input_tokens} tokens, Max output: {max_tokens}]\")\n",
        "\n",
        "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "        prompt_text = self.tokenizer.apply_chat_template(\n",
        "            messages, tokenize=False, add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "        temp = temperature if temperature is not None else self.config.temperature\n",
        "        outputs = self.pipe(\n",
        "            prompt_text,\n",
        "            max_new_tokens=max_tokens,\n",
        "            temperature=temp,\n",
        "            top_p=self.config.top_p,\n",
        "            do_sample=True,\n",
        "            pad_token_id=self.tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "        response = outputs[0][\"generated_text\"][len(prompt_text):].strip()\n",
        "        output_tokens = len(self.tokenizer.encode(response))\n",
        "\n",
        "        if self.config.log_token_counts:\n",
        "            print(f\"      [Output: {output_tokens} tokens]\")\n",
        "\n",
        "        self.token_stats[\"total_input_tokens\"] += input_tokens\n",
        "        self.token_stats[\"total_output_tokens\"] += output_tokens\n",
        "        self.token_stats[\"total_calls\"] += 1\n",
        "\n",
        "        return response\n",
        "\n",
        "    def get_token_efficiency_report(self) -> str:\n",
        "        \"\"\"Generate token efficiency report\"\"\"\n",
        "        stats = self.token_stats\n",
        "        total_tokens = stats[\"total_input_tokens\"] + stats[\"total_output_tokens\"]\n",
        "        avg_per_call = total_tokens / stats[\"total_calls\"] if stats[\"total_calls\"] > 0 else 0\n",
        "        efficiency = (stats['tokens_saved'] / total_tokens * 100) if total_tokens > 0 else 0\n",
        "\n",
        "        return f\"\"\"\n",
        "╔══════════════════════════════════════════════════════════╗\n",
        "║              TOKEN EFFICIENCY REPORT                     ║\n",
        "╠══════════════════════════════════════════════════════════╣\n",
        "║ Total Calls:           {stats['total_calls']:>6}                         ║\n",
        "║ Total Input Tokens:    {stats['total_input_tokens']:>6}                         ║\n",
        "║ Total Output Tokens:   {stats['total_output_tokens']:>6}                         ║\n",
        "║ Tokens Saved:          {stats['tokens_saved']:>6}                         ║\n",
        "║ Avg Tokens/Call:       {avg_per_call:>6.1f}                         ║\n",
        "║ Efficiency Gain:       {efficiency:>5.1f}%                         ║\n",
        "╚══════════════════════════════════════════════════════════╝\n",
        "\"\"\"\n",
        "\n",
        "print(\"ModelManager loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "global_model_section"
      },
      "source": [
        "## 6. Global Model Management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "global_model_manager",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1293e66a-1261-40a1-e65e-ecc115da1b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global model management loaded\n",
            "  - get_or_create_model_manager(config): Get or create model\n",
            "  - cleanup_model(): Release model memory\n",
            "  - get_current_model_info(): Get model status\n"
          ]
        }
      ],
      "source": [
        "# Global model manager storage\n",
        "_global_model_manager = None\n",
        "_global_model_config = None\n",
        "\n",
        "\n",
        "def get_or_create_model_manager(config: PipelineConfig,\n",
        "                                 force_reload: bool = False) -> ModelManager:\n",
        "    \"\"\"\n",
        "    Get existing or create new model manager.\n",
        "\n",
        "    Args:\n",
        "        config: Pipeline configuration\n",
        "        force_reload: If True, reload model even if already loaded\n",
        "\n",
        "    Returns:\n",
        "        ModelManager instance\n",
        "    \"\"\"\n",
        "    global _global_model_manager, _global_model_config\n",
        "\n",
        "    if force_reload and _global_model_manager is not None:\n",
        "        print(\"Force reload requested...\")\n",
        "        cleanup_model()\n",
        "\n",
        "    if _global_model_manager is None:\n",
        "        print(f\"Loading model: {config.model_name}\")\n",
        "        _global_model_manager = ModelManager(config)\n",
        "        _global_model_manager.load_model()\n",
        "        _global_model_config = config\n",
        "        return _global_model_manager\n",
        "\n",
        "    if _global_model_config.model_name == config.model_name:\n",
        "        print(f\"Reusing existing model: {config.model_name}\")\n",
        "        return _global_model_manager\n",
        "\n",
        "    print(f\"Switching model: {_global_model_config.model_name} -> {config.model_name}\")\n",
        "    cleanup_model()\n",
        "    _global_model_manager = ModelManager(config)\n",
        "    _global_model_manager.load_model()\n",
        "    _global_model_config = config\n",
        "\n",
        "    return _global_model_manager\n",
        "\n",
        "\n",
        "def cleanup_model():\n",
        "    \"\"\"Release model from memory\"\"\"\n",
        "    global _global_model_manager, _global_model_config\n",
        "\n",
        "    if _global_model_manager is None:\n",
        "        print(\"No model to cleanup\")\n",
        "        return\n",
        "\n",
        "    model_name = _global_model_config.model_name if _global_model_config else \"Unknown\"\n",
        "    print(f\"Cleaning up model: {model_name}\")\n",
        "\n",
        "    del _global_model_manager\n",
        "    _global_model_manager = None\n",
        "    _global_model_config = None\n",
        "\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"GPU memory freed\")\n",
        "\n",
        "\n",
        "def get_current_model_info() -> Dict[str, any]:\n",
        "    \"\"\"Get current model information\"\"\"\n",
        "    if _global_model_manager is None:\n",
        "        return {\"loaded\": False, \"model_name\": None, \"gpu_memory_allocated\": 0}\n",
        "\n",
        "    return {\n",
        "        \"loaded\": True,\n",
        "        \"model_name\": _global_model_config.model_name,\n",
        "        \"gpu_memory_allocated\": torch.cuda.memory_allocated(0) / 1e9 if torch.cuda.is_available() else 0\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"Global model management loaded\")\n",
        "print(\"  - get_or_create_model_manager(config): Get or create model\")\n",
        "print(\"  - cleanup_model(): Release model memory\")\n",
        "print(\"  - get_current_model_info(): Get model status\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quality_gate_section"
      },
      "source": [
        "## 7. Quality Gate System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "quality_gate",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13dc608-70f2-40c6-b4a7-7f817a12b9db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QualityGate loaded\n"
          ]
        }
      ],
      "source": [
        "class QualityGate:\n",
        "    \"\"\"Quality validation system for generated summaries\"\"\"\n",
        "\n",
        "    def __init__(self, config: PipelineConfig):\n",
        "        self.config = config\n",
        "        self.validation_stats = {\n",
        "            \"total_validations\": 0,\n",
        "            \"passed_first_time\": 0,\n",
        "            \"regenerated\": 0,\n",
        "            \"failed_final\": 0\n",
        "        }\n",
        "\n",
        "    def validate_summary(self, summary: str, summary_type: str = \"video\") -> Tuple[bool, List[str]]:\n",
        "        \"\"\"\n",
        "        Validate summary quality.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (is_valid, failure_reasons)\n",
        "        \"\"\"\n",
        "        if not self.config.enable_quality_gate:\n",
        "            return True, []\n",
        "\n",
        "        self.validation_stats[\"total_validations\"] += 1\n",
        "        failure_reasons = []\n",
        "\n",
        "        # Check 1: Minimum length\n",
        "        if len(summary) < self.config.min_summary_length:\n",
        "            failure_reasons.append(f\"Too short ({len(summary)} < {self.config.min_summary_length} chars)\")\n",
        "\n",
        "        # Check 2: Keyword diversity\n",
        "        words = summary.lower().split()\n",
        "        unique_words = set(words)\n",
        "        if len(unique_words) < self.config.min_keyword_diversity:\n",
        "            failure_reasons.append(f\"Low diversity ({len(unique_words)} < {self.config.min_keyword_diversity} unique words)\")\n",
        "\n",
        "        # Check 3: Content relevance\n",
        "        if summary_type == \"video\":\n",
        "            relevance_keywords = [\"video\", \"content\", \"shows\", \"features\", \"presents\", \"discusses\"]\n",
        "        else:\n",
        "            relevance_keywords = [\"comment\", \"viewer\", \"audience\", \"reaction\", \"opinion\", \"sentiment\"]\n",
        "\n",
        "        if not any(keyword in summary.lower() for keyword in relevance_keywords):\n",
        "            failure_reasons.append(f\"Missing relevance keywords for {summary_type}\")\n",
        "\n",
        "        # Check 4: Required structure\n",
        "        if \"KEY POINT\" not in summary:\n",
        "            failure_reasons.append(\"Missing 'KEY POINT' section\")\n",
        "\n",
        "        # Check 5: Exact error message detection\n",
        "        actual_failure_messages = [\n",
        "            \"Video summary generation failed.\",\n",
        "            \"Reaction summary generation failed.\",\n",
        "        ]\n",
        "        if summary.strip() in actual_failure_messages:\n",
        "            failure_reasons.append(\"Generation returned error message\")\n",
        "\n",
        "        is_valid = len(failure_reasons) == 0\n",
        "        if is_valid:\n",
        "            self.validation_stats[\"passed_first_time\"] += 1\n",
        "\n",
        "        return is_valid, failure_reasons\n",
        "\n",
        "    def get_quality_report(self) -> str:\n",
        "        \"\"\"Generate quality validation report\"\"\"\n",
        "        stats = self.validation_stats\n",
        "        total = stats[\"total_validations\"]\n",
        "\n",
        "        if total == 0:\n",
        "            return \"\\n[Quality Gate: No validations performed]\\n\"\n",
        "\n",
        "        pass_rate = (stats[\"passed_first_time\"] / total * 100) if total > 0 else 0\n",
        "        regen_rate = (stats[\"regenerated\"] / total * 100) if total > 0 else 0\n",
        "\n",
        "        return f\"\"\"\n",
        "╔══════════════════════════════════════════════════════════╗\n",
        "║              QUALITY GATE REPORT                         ║\n",
        "╠══════════════════════════════════════════════════════════╣\n",
        "║ Total Validations:     {total:>6}                         ║\n",
        "║ Passed First Time:     {stats['passed_first_time']:>6} ({pass_rate:>5.1f}%)              ║\n",
        "║ Regenerated:           {stats['regenerated']:>6} ({regen_rate:>5.1f}%)              ║\n",
        "║ Failed Final:          {stats['failed_final']:>6}                         ║\n",
        "╚══════════════════════════════════════════════════════════╝\n",
        "\"\"\"\n",
        "\n",
        "print(\"QualityGate loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_loading_section"
      },
      "source": [
        "## 8. Data Loading Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "data_loading",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54ed3deb-9ab7-435b-fa1c-4e39740a48d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loading utilities loaded\n"
          ]
        }
      ],
      "source": [
        "def load_test_data(data_path: str, num_videos: int = 3) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Load test data from JSON file.\n",
        "\n",
        "    Args:\n",
        "        data_path: Path to JSON data file\n",
        "        num_videos: Number of videos to load\n",
        "\n",
        "    Returns:\n",
        "        List of video data dictionaries\n",
        "    \"\"\"\n",
        "    print(f\"Loading data from: {data_path}\")\n",
        "\n",
        "    with open(data_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Handle different data structures\n",
        "    if isinstance(data, list):\n",
        "        videos = data\n",
        "    elif isinstance(data, dict) and 'videos' in data:\n",
        "        videos = data['videos']\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected data structure: {type(data)}\")\n",
        "\n",
        "    print(f\"  Found {len(videos)} videos in dataset\")\n",
        "    test_videos = videos[:num_videos]\n",
        "    print(f\"  Using {len(test_videos)} videos for testing\")\n",
        "\n",
        "    return test_videos\n",
        "\n",
        "\n",
        "print(\"Data loading utilities loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sentiment_helper_section"
      },
      "source": [
        "## 9. Sentiment Model Helper\n",
        "\n",
        "Helper function to prepare sentiment model from zip file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sentiment_helper",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad4bde07-5f5e-4b05-d31e-9df7b2fe2a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment model helper loaded\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "def ensure_sentiment_model_from_zip(zip_path: str, root_dir: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract sentiment model from zip if needed.\n",
        "\n",
        "    Args:\n",
        "        zip_path: Path to zip file containing bert_sentiment folder\n",
        "        root_dir: Root directory to extract to\n",
        "\n",
        "    Returns:\n",
        "        Path to extracted model directory\n",
        "    \"\"\"\n",
        "    target_dir = os.path.join(root_dir, \"bert_sentiment\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Preparing sentiment model from zip\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if os.path.isdir(target_dir):\n",
        "        print(f\"Model directory already exists: {target_dir}\")\n",
        "        print(f\"  Files: {os.listdir(target_dir)}\")\n",
        "        return target_dir\n",
        "\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(f\"Zip not found: {zip_path}\")\n",
        "        return target_dir\n",
        "\n",
        "    os.makedirs(root_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"Extracting {zip_path}...\")\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "        print(f\"  Size: {os.path.getsize(zip_path) / (1024**2):.1f} MB\")\n",
        "        print(f\"  Files in zip: {len(zf.infolist())}\")\n",
        "        zf.extractall(root_dir)\n",
        "\n",
        "    if os.path.isdir(target_dir):\n",
        "        files = os.listdir(target_dir)\n",
        "        print(f\"Extracted to: {target_dir}\")\n",
        "        print(f\"  Files ({len(files)}): {files}\")\n",
        "        missing = [f for f in [\"config.json\", \"tokenizer_config.json\"] if f not in files]\n",
        "        if missing:\n",
        "            print(f\"  Warning: Missing required files: {missing}\")\n",
        "    else:\n",
        "        print(f\"Warning: {target_dir} not found after unzip\")\n",
        "\n",
        "    return target_dir\n",
        "\n",
        "\n",
        "print(\"Sentiment model helper loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "verification_section"
      },
      "source": [
        "## 10. Part 1 Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "verification",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b64974-f83e-4862-a7cd-a5a4559ebe7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Part 1 Setup Complete\n",
            "============================================================\n",
            "\n",
            "Available components:\n",
            "  - PipelineConfig: Configuration dataclass\n",
            "  - config: Global configuration instance\n",
            "  - PromptTemplates: Prompt generation utilities\n",
            "  - TextPreprocessor: Text cleaning and language detection\n",
            "  - ModelManager: LLM model wrapper\n",
            "  - QualityGate: Output quality validation\n",
            "  - load_test_data(): Load video data from JSON\n",
            "  - ensure_sentiment_model_from_zip(): Prepare sentiment model\n",
            "  - get_or_create_model_manager(): Global model management\n",
            "  - cleanup_model(): Release model memory\n",
            "\n",
            "Next steps:\n",
            "  1. Run Part 2 to load Category and Sentiment models\n",
            "  2. Run Part 3 to execute the full pipeline\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Part 1 Setup Complete\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\")\n",
        "print(\"Available components:\")\n",
        "print(\"  - PipelineConfig: Configuration dataclass\")\n",
        "print(\"  - config: Global configuration instance\")\n",
        "print(\"  - PromptTemplates: Prompt generation utilities\")\n",
        "print(\"  - TextPreprocessor: Text cleaning and language detection\")\n",
        "print(\"  - ModelManager: LLM model wrapper\")\n",
        "print(\"  - QualityGate: Output quality validation\")\n",
        "print(\"  - load_test_data(): Load video data from JSON\")\n",
        "print(\"  - ensure_sentiment_model_from_zip(): Prepare sentiment model\")\n",
        "print(\"  - get_or_create_model_manager(): Global model management\")\n",
        "print(\"  - cleanup_model(): Release model memory\")\n",
        "print(\"\")\n",
        "print(\"Next steps:\")\n",
        "print(\"  1. Run Part 2 to load Category and Sentiment models\")\n",
        "print(\"  2. Run Part 3 to execute the full pipeline\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27sT93FRNGiz"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "# From: part2_models.ipynb\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar8-tAEzNGi0"
      },
      "source": [
        "# YouTube Report Generator - Part 2: Models (Category & Sentiment)\n",
        "\n",
        "This notebook contains Category and Sentiment model definitions and initialization.\n",
        "\n",
        "**Pipeline Structure:**\n",
        "- **Part 1**: Setup, configuration, utilities, data loading\n",
        "- **Part 2** (this file): Category and Sentiment model initialization\n",
        "- **Part 3**: Full pipeline execution and report generation\n",
        "\n",
        "**Prerequisites:** Run all cells in Part 1 before running this notebook.\n",
        "\n",
        "**Note:** This notebook uses `config` (PipelineConfig instance) from Part 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "category_section"
      },
      "source": [
        "## 1. Category Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "category_imports"
      },
      "outputs": [],
      "source": [
        "# NOTE: These imports are also in Part 1, but included here for standalone execution\n",
        "import os\n",
        "import pickle\n",
        "import joblib\n",
        "import torch\n",
        "import numpy as np\n",
        "from typing import List, Dict, Optional\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "category_model_manager",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17d0bf5d-3967-4193-a8fb-928c8e2a3e51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CategoryModelManager class defined\n"
          ]
        }
      ],
      "source": [
        "class CategoryModelManager:\n",
        "    \"\"\"Category prediction model manager (BERT + TF-IDF)\"\"\"\n",
        "\n",
        "    CATEGORY_MAPPING = {\n",
        "        10: 'Music', 17: 'Sports', 19: 'Travel', 20: 'Gaming',\n",
        "        22: 'People & Blogs', 23: 'Comedy', 24: 'Entertainment',\n",
        "        25: 'News & Politics', 26: 'HowTo & Style',\n",
        "        27: 'Education', 28: 'Science & Tech'\n",
        "    }\n",
        "\n",
        "    def __init__(self, model_dir: str = \"./models\"):\n",
        "        self.model_dir = model_dir\n",
        "        self.bert_model = None\n",
        "        self.bert_tokenizer = None\n",
        "        self.tfidf_model = None\n",
        "        self.tfidf_vectorizer = None\n",
        "        self.label_encoder = None\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"CategoryModelManager initialized (Device: {self.device})\")\n",
        "\n",
        "    def load_models(self) -> bool:\n",
        "        \"\"\"Load saved models\"\"\"\n",
        "        if not os.path.exists(self.model_dir):\n",
        "            print(f\"Model directory not found: {self.model_dir}\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            # Load BERT model\n",
        "            bert_path = os.path.join(self.model_dir, \"bert_model\")\n",
        "            if os.path.exists(bert_path):\n",
        "                self.bert_tokenizer = AutoTokenizer.from_pretrained(bert_path)\n",
        "                self.bert_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                    bert_path, device_map=\"auto\"\n",
        "                ).to(self.device)\n",
        "                self.bert_model.eval()\n",
        "                print(f\"BERT model loaded: {bert_path}\")\n",
        "            else:\n",
        "                print(f\"BERT model not found: {bert_path}\")\n",
        "\n",
        "            # Load TF-IDF model\n",
        "            tfidf_vec_path = os.path.join(self.model_dir, \"tfidf_vectorizer.pkl\")\n",
        "            tfidf_model_path = os.path.join(self.model_dir, \"tfidf_model.pkl\")\n",
        "            le_path = os.path.join(self.model_dir, \"label_encoder.pkl\")\n",
        "\n",
        "            if all(os.path.exists(p) for p in [tfidf_vec_path, tfidf_model_path, le_path]):\n",
        "                self.tfidf_vectorizer = joblib.load(tfidf_vec_path)\n",
        "                self.tfidf_model = joblib.load(tfidf_model_path)\n",
        "                self.label_encoder = joblib.load(le_path)\n",
        "                print(\"TF-IDF model loaded\")\n",
        "            else:\n",
        "                print(\"TF-IDF model files not found\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Model loading failed: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def save_models(self, bert_model, bert_tokenizer, tfidf_model,\n",
        "                    tfidf_vectorizer, label_encoder):\n",
        "        \"\"\"Save trained models\"\"\"\n",
        "        os.makedirs(self.model_dir, exist_ok=True)\n",
        "\n",
        "        # Save BERT model\n",
        "        bert_path = os.path.join(self.model_dir, \"bert_model\")\n",
        "        bert_model.save_pretrained(bert_path)\n",
        "        bert_tokenizer.save_pretrained(bert_path)\n",
        "        print(f\"BERT model saved: {bert_path}\")\n",
        "\n",
        "        # Save TF-IDF model\n",
        "        joblib.dump(tfidf_vectorizer, os.path.join(self.model_dir, \"tfidf_vectorizer.pkl\"))\n",
        "        joblib.dump(tfidf_model, os.path.join(self.model_dir, \"tfidf_model.pkl\"))\n",
        "        joblib.dump(label_encoder, os.path.join(self.model_dir, \"label_encoder.pkl\"))\n",
        "        print(f\"TF-IDF model saved: {self.model_dir}\")\n",
        "\n",
        "        # Update internal references\n",
        "        self.bert_model = bert_model\n",
        "        self.bert_tokenizer = bert_tokenizer\n",
        "        self.tfidf_model = tfidf_model\n",
        "        self.tfidf_vectorizer = tfidf_vectorizer\n",
        "        self.label_encoder = label_encoder\n",
        "\n",
        "    def predict(self, text: str, use_bert: bool = True) -> str:\n",
        "        \"\"\"Predict category for given text\"\"\"\n",
        "        if not text or len(text.strip()) < 5:\n",
        "            return \"Unknown\"\n",
        "\n",
        "        # Try BERT first\n",
        "        if use_bert and self.bert_model is not None:\n",
        "            try:\n",
        "                inputs = self.bert_tokenizer(\n",
        "                    text,\n",
        "                    return_tensors=\"pt\",\n",
        "                    truncation=True,\n",
        "                    padding=True,\n",
        "                    max_length=256\n",
        "                ).to(self.device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    outputs = self.bert_model(**inputs)\n",
        "                    pred_idx = torch.argmax(outputs.logits, dim=1).cpu().numpy()[0]\n",
        "\n",
        "                return self.label_encoder.inverse_transform([pred_idx])[0]\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"BERT prediction failed, trying TF-IDF: {str(e)}\")\n",
        "\n",
        "        # Fallback to TF-IDF\n",
        "        if self.tfidf_model is not None:\n",
        "            try:\n",
        "                text_vec = self.tfidf_vectorizer.transform([text])\n",
        "                pred_idx = self.tfidf_model.predict(text_vec)[0]\n",
        "                return self.label_encoder.inverse_transform([pred_idx])[0]\n",
        "            except Exception as e:\n",
        "                print(f\"TF-IDF prediction failed: {str(e)}\")\n",
        "\n",
        "        return \"Unknown\"\n",
        "\n",
        "    def get_status(self) -> Dict:\n",
        "        \"\"\"Get current model status\"\"\"\n",
        "        return {\n",
        "            \"bert_loaded\": self.bert_model is not None,\n",
        "            \"tfidf_loaded\": self.tfidf_model is not None,\n",
        "            \"label_encoder_loaded\": self.label_encoder is not None,\n",
        "            \"device\": self.device\n",
        "        }\n",
        "\n",
        "\n",
        "print(\"CategoryModelManager class defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "category_init_section"
      },
      "source": [
        "### 1.1 Category Model Initialization\n",
        "\n",
        "**Mode options:**\n",
        "- `load`: Load pre-trained model (default, fast)\n",
        "- `train_script`: Run external training script (final_code.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "category_init",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f2ad02-9ace-4879-9f82-8ec8c6b9ac98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Category Model Initialization\n",
            "============================================================\n",
            "CategoryModelManager initialized (Device: cuda)\n",
            "\n",
            "Selected mode: load\n",
            "============================================================\n",
            "\n",
            "Loading saved models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer you are loading from '/content/drive/MyDrive/25_sch/ML/models/bert_model' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model loaded: /content/drive/MyDrive/25_sch/ML/models/bert_model\n",
            "TF-IDF model loaded\n",
            "\n",
            "Model load complete!\n",
            "  BERT: OK\n",
            "  TF-IDF: OK\n",
            "  Device: cuda\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Category Model Initialization\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create CategoryModelManager instance\n",
        "category_model_manager = CategoryModelManager(model_dir=\"/content/drive/MyDrive/25_sch/ML/models\")\n",
        "\n",
        "# Mode selection: \"load\" or \"train_script\"\n",
        "CATEGORY_MODE = \"load\"\n",
        "\n",
        "print(f\"\\nSelected mode: {CATEGORY_MODE}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if CATEGORY_MODE == \"load\":\n",
        "    print(\"\\nLoading saved models...\")\n",
        "    success = category_model_manager.load_models()\n",
        "\n",
        "    if success:\n",
        "        print(\"\\nModel load complete!\")\n",
        "        status = category_model_manager.get_status()\n",
        "        print(f\"  BERT: {'OK' if status['bert_loaded'] else 'Not loaded'}\")\n",
        "        print(f\"  TF-IDF: {'OK' if status['tfidf_loaded'] else 'Not loaded'}\")\n",
        "        print(f\"  Device: {status['device']}\")\n",
        "    else:\n",
        "        print(\"\\nModel load failed!\")\n",
        "        print(\"  Solution: Set CATEGORY_MODE='train_script' to train the model\")\n",
        "\n",
        "elif CATEGORY_MODE == \"train_script\":\n",
        "    print(\"\\nRunning final_code.py... (~30 min)\")\n",
        "    %run final_code.py\n",
        "\n",
        "    print(\"\\nSaving trained models...\")\n",
        "    try:\n",
        "        MODEL_DIR = \"./models\"\n",
        "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "        bert_save_path = os.path.join(MODEL_DIR, \"bert_model\")\n",
        "        model_bert.save_pretrained(bert_save_path)\n",
        "        tokenizer.save_pretrained(bert_save_path)\n",
        "        print(f\"BERT model saved: {bert_save_path}\")\n",
        "\n",
        "        joblib.dump(tfidf, os.path.join(MODEL_DIR, \"tfidf_vectorizer.pkl\"))\n",
        "        joblib.dump(model_lr, os.path.join(MODEL_DIR, \"tfidf_model.pkl\"))\n",
        "        joblib.dump(le, os.path.join(MODEL_DIR, \"label_encoder.pkl\"))\n",
        "        print(f\"TF-IDF model saved: {MODEL_DIR}\")\n",
        "\n",
        "        print(\"\\nLoading saved models...\")\n",
        "        category_model_manager.load_models()\n",
        "        print(\"Save and load complete!\")\n",
        "\n",
        "    except NameError as e:\n",
        "        print(f\"Model variables not found: {e}\")\n",
        "        print(\"  Check if final_code.py executed correctly.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Save failed: {e}\")\n",
        "\n",
        "else:\n",
        "    print(f\"Unknown mode: {CATEGORY_MODE}\")\n",
        "    print(\"  Use 'load' or 'train_script'\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sentiment_section"
      },
      "source": [
        "## 2. Sentiment Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sentiment_model_manager",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a9a156a-d864-44a5-c9b5-71113208275a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentModelManager class defined\n"
          ]
        }
      ],
      "source": [
        "class SentimentModelManager:\n",
        "    \"\"\"Sentiment prediction model manager (neg/neu/pos)\"\"\"\n",
        "\n",
        "    def __init__(self, model_dir: str):\n",
        "        self.model_dir = model_dir\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.bert_model = None  # Alias for compatibility\n",
        "        self.classic_clf = None  # For compatibility check\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.labels = [\"neg\", \"neu\", \"pos\"]\n",
        "        self.label2id = {\"neg\": 0, \"neu\": 1, \"pos\": 2}\n",
        "        self.id2label = {0: \"neg\", 1: \"neu\", 2: \"pos\"}\n",
        "        print(f\"SentimentModelManager initialized (Device: {self.device})\")\n",
        "\n",
        "    def load_models(self) -> bool:\n",
        "        \"\"\"Load BERT sentiment model\"\"\"\n",
        "        if not os.path.isdir(self.model_dir):\n",
        "            print(f\"Sentiment model directory not found: {self.model_dir}\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            print(f\"  Loading from: {self.model_dir}\")\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_dir)\n",
        "            self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                self.model_dir\n",
        "            ).to(self.device)\n",
        "            self.model.eval()\n",
        "            self.bert_model = self.model  # Alias for compatibility\n",
        "            print(\"  Sentiment model loaded successfully!\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Failed to load sentiment model: {e}\")\n",
        "            return False\n",
        "\n",
        "    def predict(self, texts, use_bert: bool = True, use_classic: bool = True,\n",
        "                ensemble: str = \"bert_priority\", batch_size: int = 32) -> Dict:\n",
        "        \"\"\"\n",
        "        Predict sentiment for texts.\n",
        "\n",
        "        Args:\n",
        "            texts: Single text or list of texts\n",
        "            use_bert: Use BERT model (ignored, always uses BERT)\n",
        "            use_classic: Use classic model (ignored, for compatibility)\n",
        "            ensemble: Ensemble method (ignored, for compatibility)\n",
        "            batch_size: Batch size for inference\n",
        "\n",
        "        Returns:\n",
        "            Dict with 'predictions' (list of labels) and 'probabilities' (numpy array)\n",
        "        \"\"\"\n",
        "        if isinstance(texts, str):\n",
        "            texts = [texts]\n",
        "\n",
        "        if self.model is None:\n",
        "            raise RuntimeError(\"Sentiment model not loaded. Call load_models() first.\")\n",
        "\n",
        "        try:\n",
        "            all_probs = []\n",
        "            all_preds = []\n",
        "\n",
        "            for i in range(0, len(texts), batch_size):\n",
        "                batch_texts = texts[i:i+batch_size]\n",
        "                inputs = self.tokenizer(\n",
        "                    batch_texts,\n",
        "                    return_tensors=\"pt\",\n",
        "                    padding=True,\n",
        "                    truncation=True,\n",
        "                    max_length=128,\n",
        "                ).to(self.device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    outputs = self.model(**inputs)\n",
        "                    probs = torch.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
        "                    preds = np.argmax(probs, axis=1)\n",
        "\n",
        "                all_probs.extend(probs)\n",
        "                all_preds.extend(preds)\n",
        "\n",
        "            proba = np.array(all_probs)\n",
        "            pred_labels = [self.labels[p] for p in all_preds]\n",
        "\n",
        "            return {\n",
        "                \"predictions\": pred_labels,\n",
        "                \"probabilities\": proba\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Prediction error: {e}\")\n",
        "            return {\n",
        "                \"predictions\": [\"neu\"] * len(texts),\n",
        "                \"probabilities\": np.ones((len(texts), 3)) / 3\n",
        "            }\n",
        "\n",
        "    def get_status(self) -> Dict:\n",
        "        \"\"\"Get model status\"\"\"\n",
        "        return {\n",
        "            \"loaded\": self.model is not None,\n",
        "            \"device\": self.device,\n",
        "            \"model_dir\": self.model_dir,\n",
        "        }\n",
        "\n",
        "\n",
        "print(\"SentimentModelManager class defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sentiment_init_section"
      },
      "source": [
        "### 2.1 Sentiment Model Initialization\n",
        "\n",
        "**Mode options:**\n",
        "- `load`: Load pre-trained model from zip (default)\n",
        "- `train_script`: Run Bert_model.py training script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bCio-RrHNGi1"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "def ensure_sentiment_model_from_zip(zip_path: str, root_dir: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract sentiment model from zip if needed.\n",
        "\n",
        "    Args:\n",
        "        zip_path: Path to zip file containing bert_sentiment folder\n",
        "        root_dir: Root directory to extract to\n",
        "\n",
        "    Returns:\n",
        "        Path to extracted model directory\n",
        "    \"\"\"\n",
        "    target_dir = os.path.join(root_dir, \"bert_sentiment\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Preparing sentiment model from zip\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if os.path.isdir(target_dir):\n",
        "        print(f\"Model directory already exists: {target_dir}\")\n",
        "        print(f\"  Files: {os.listdir(target_dir)}\")\n",
        "        return target_dir\n",
        "\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(f\"Zip not found: {zip_path}\")\n",
        "        return target_dir\n",
        "\n",
        "    os.makedirs(root_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"Extracting {zip_path}...\")\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "        print(f\"  Size: {os.path.getsize(zip_path) / (1024**2):.1f} MB\")\n",
        "        print(f\"  Files in zip: {len(zf.infolist())}\")\n",
        "        zf.extractall(root_dir)\n",
        "\n",
        "    if os.path.isdir(target_dir):\n",
        "        files = os.listdir(target_dir)\n",
        "        print(f\"Extracted to: {target_dir}\")\n",
        "        print(f\"  Files ({len(files)}): {files}\")\n",
        "        missing = [f for f in [\"config.json\", \"tokenizer_config.json\"] if f not in files]\n",
        "        if missing:\n",
        "            print(f\"  Warning: Missing required files: {missing}\")\n",
        "    else:\n",
        "        print(f\"Warning: {target_dir} not found after unzip\")\n",
        "\n",
        "    return target_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sentiment_load",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5689f25-5772-4ae6-a448-c986dacec50e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Sentiment Model Initialization\n",
            "============================================================\n",
            "\n",
            "Selected mode: load\n",
            "------------------------------------------------------------\n",
            "============================================================\n",
            "Preparing sentiment model from zip\n",
            "============================================================\n",
            "Extracting /content/drive/MyDrive/25_sch/ML/sentiment/bert_sentiment.zip...\n",
            "  Size: 805.6 MB\n",
            "  Files in zip: 7\n",
            "Extracted to: ./models/sentiment/bert_sentiment\n",
            "  Files (7): ['training_args.bin', 'tokenizer.json', 'special_tokens_map.json', 'model.safetensors', 'tokenizer_config.json', 'config.json', 'sentencepiece.bpe.model']\n",
            "SentimentModelManager initialized (Device: cuda)\n",
            "\n",
            "Loading pre-trained sentiment model...\n",
            "------------------------------------------------------------\n",
            "  Loading from: ./models/sentiment/bert_sentiment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer you are loading from './models/sentiment/bert_sentiment' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Sentiment model loaded successfully!\n",
            "\n",
            "============================================================\n",
            "Sentiment Model Loaded Successfully!\n",
            "============================================================\n",
            "  Device: cuda\n",
            "  Model Dir: ./models/sentiment/bert_sentiment\n",
            "\n",
            "Quick Test:\n",
            "  😊 '정말 최고예요! 👍' -> pos (pos=1.00, neu=0.00, neg=0.00)\n",
            "  😠 '별로네.. 시간낭비' -> neg (pos=0.01, neu=0.01, neg=0.98)\n",
            "  😐 '그냥 보통이에요' -> neu (pos=0.01, neu=0.98, neg=0.01)\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Sentiment Model Initialization Complete!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Sentiment Model Initialization\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Mode selection: \"load\" or \"train_script\"\n",
        "SENTIMENT_MODE = \"load\"\n",
        "\n",
        "print(f\"\\nSelected mode: {SENTIMENT_MODE}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Step 1: Prepare model from zip (common for load mode)\n",
        "sentiment_model_dir = ensure_sentiment_model_from_zip(\n",
        "    config.sentiment_zip_path,\n",
        "    config.sentiment_root_dir,\n",
        ")\n",
        "\n",
        "# Step 2: Create SentimentModelManager\n",
        "sentiment_model_manager = SentimentModelManager(\n",
        "    model_dir=config.sentiment_model_path\n",
        ")\n",
        "\n",
        "# Step 3: Mode-specific processing\n",
        "if SENTIMENT_MODE == \"load\":\n",
        "    print(\"\\nLoading pre-trained sentiment model...\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    success = sentiment_model_manager.load_models()\n",
        "    status = sentiment_model_manager.get_status()\n",
        "\n",
        "    if success and status[\"loaded\"]:\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"Sentiment Model Loaded Successfully!\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"  Device: {status['device']}\")\n",
        "        print(f\"  Model Dir: {status['model_dir']}\")\n",
        "\n",
        "        # Quick test\n",
        "        print(\"\\nQuick Test:\")\n",
        "        test_texts = [\"정말 최고예요! 👍\", \"별로네.. 시간낭비\", \"그냥 보통이에요\"]\n",
        "        results = sentiment_model_manager.predict(test_texts)\n",
        "\n",
        "        for text, pred, probs in zip(test_texts, results['predictions'], results['probabilities']):\n",
        "            emoji = {\"pos\": \"😊\", \"neu\": \"😐\", \"neg\": \"😠\"}[pred]\n",
        "            p_neg, p_neu, p_pos = probs\n",
        "            print(f\"  {emoji} '{text}' -> {pred} (pos={p_pos:.2f}, neu={p_neu:.2f}, neg={p_neg:.2f})\")\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "    else:\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"Failed to load Sentiment model\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"Troubleshooting:\")\n",
        "        print(\"  1. Check zip path: config.sentiment_zip_path\")\n",
        "        print(\"  2. Check extraction: config.sentiment_model_path\")\n",
        "        print(\"  3. Required files: config.json, model.safetensors, tokenizer\")\n",
        "        print(\"  4. Or set SENTIMENT_MODE='train_script' to train the model\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "elif SENTIMENT_MODE == \"train_script\":\n",
        "    print(\"\\ntrain_script mode: running Bert_model.py\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    if not os.path.exists(\"Bert_model.py\"):\n",
        "        print(\"\\nBert_model.py not found\")\n",
        "        print(\"  Download from: https://github.com/myWworld/20252R0136COSE36203\")\n",
        "    else:\n",
        "        print(\"Bert_model.py found\")\n",
        "        print(\"\\nRunning Bert_model.py...\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        %run Bert_model.py\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"Bert_model.py execution complete!\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Move trained model if needed\n",
        "        if os.path.isdir(\"./bert_sentiment\"):\n",
        "            target_dir = config.sentiment_model_path\n",
        "            if \"./bert_sentiment\" != target_dir:\n",
        "                import shutil\n",
        "                os.makedirs(os.path.dirname(target_dir), exist_ok=True)\n",
        "                if not os.path.isdir(target_dir):\n",
        "                    shutil.move(\"./bert_sentiment\", target_dir)\n",
        "                    print(f\"Moved: ./bert_sentiment -> {target_dir}\")\n",
        "                else:\n",
        "                    print(f\"{target_dir} already exists, skipping move\")\n",
        "\n",
        "        print(\"\\nLoading trained sentiment model...\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        success = sentiment_model_manager.load_models()\n",
        "\n",
        "        if success:\n",
        "            print(\"Sentiment model ready after train_script!\")\n",
        "\n",
        "            print(\"\\nQuick Test:\")\n",
        "            test_texts = [\"정말 최고예요! 👍\", \"별로네.. 시간낭비\", \"그냥 보통이에요\"]\n",
        "            results = sentiment_model_manager.predict(test_texts)\n",
        "\n",
        "            for text, pred in zip(test_texts, results['predictions']):\n",
        "                emoji = {\"pos\": \"😊\", \"neu\": \"😐\", \"neg\": \"😠\"}[pred]\n",
        "                print(f\"  {emoji} '{text}' -> {pred}\")\n",
        "        else:\n",
        "            print(\"Sentiment model load failed after training.\")\n",
        "            print(\"  Check Bert_model.py execution logs\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\nUnknown mode: {SENTIMENT_MODE}\")\n",
        "    print(\"  Use 'load' or 'train_script'\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Sentiment Model Initialization Complete!\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cleanup_section"
      },
      "source": [
        "## 3. Optional: Clear Sentiment Model Directory\n",
        "\n",
        "Run this cell only if you need to re-extract the sentiment model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cleanup"
      },
      "outputs": [],
      "source": [
        "# Uncomment and run only if needed\n",
        "# import shutil\n",
        "# folder_to_delete = \"/content/models/sentiment\"\n",
        "# if os.path.exists(folder_to_delete):\n",
        "#     shutil.rmtree(folder_to_delete)\n",
        "#     print(f\"Deleted: {folder_to_delete}\")\n",
        "# else:\n",
        "#     print(f\"Folder not found: {folder_to_delete}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH3lMH2TNGi3"
      },
      "source": [
        "## 4. Part 2 Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJFFjfYoNGi3",
        "outputId": "bcd12b5a-90d9-42dd-a43a-d4e7e9738a52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Part 2 Model Setup Complete\n",
            "============================================================\n",
            "\n",
            "Loaded models:\n",
            "  Category Model:\n",
            "    BERT: OK\n",
            "    TF-IDF: OK\n",
            "  Sentiment Model:\n",
            "    Loaded: OK\n",
            "    Device: cuda\n",
            "\n",
            "Global variables available:\n",
            "  - category_model_manager: CategoryModelManager instance\n",
            "  - sentiment_model_manager: SentimentModelManager instance\n",
            "\n",
            "Next steps:\n",
            "  Run Part 3 to execute the full pipeline\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Part 2 Model Setup Complete\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\")\n",
        "print(\"Loaded models:\")\n",
        "\n",
        "# Category model status\n",
        "if 'category_model_manager' in globals():\n",
        "    cat_status = category_model_manager.get_status()\n",
        "    print(f\"  Category Model:\")\n",
        "    print(f\"    BERT: {'OK' if cat_status['bert_loaded'] else 'Not loaded'}\")\n",
        "    print(f\"    TF-IDF: {'OK' if cat_status['tfidf_loaded'] else 'Not loaded'}\")\n",
        "else:\n",
        "    print(\"  Category Model: Not initialized\")\n",
        "\n",
        "# Sentiment model status\n",
        "if 'sentiment_model_manager' in globals():\n",
        "    sent_status = sentiment_model_manager.get_status()\n",
        "    print(f\"  Sentiment Model:\")\n",
        "    print(f\"    Loaded: {'OK' if sent_status['loaded'] else 'Not loaded'}\")\n",
        "    print(f\"    Device: {sent_status['device']}\")\n",
        "else:\n",
        "    print(\"  Sentiment Model: Not initialized\")\n",
        "\n",
        "print(\"\")\n",
        "print(\"Global variables available:\")\n",
        "print(\"  - category_model_manager: CategoryModelManager instance\")\n",
        "print(\"  - sentiment_model_manager: SentimentModelManager instance\")\n",
        "print(\"\")\n",
        "print(\"Next steps:\")\n",
        "print(\"  Run Part 3 to execute the full pipeline\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqHZ_u72NGi8"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "# From: part3_pipeline_report.ipynb\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zFSJ1F4NGi8"
      },
      "source": [
        "# YouTube Report Generator - Part 3: Full Pipeline & Report\n",
        "\n",
        "This notebook contains the ReportGenerator class and pipeline execution.\n",
        "\n",
        "**Pipeline Structure:**\n",
        "- **Part 1**: Setup, configuration, utilities, data loading\n",
        "- **Part 2**: Category and Sentiment model initialization\n",
        "- **Part 3** (this file): Full pipeline execution and report generation\n",
        "\n",
        "**Prerequisites:** Run all cells in Part 1 and Part 2 before running this notebook.\n",
        "\n",
        "**Required global variables from previous parts:**\n",
        "- `config` (PipelineConfig)\n",
        "- `category_model_manager` (CategoryModelManager)\n",
        "- `sentiment_model_manager` (SentimentModelManager)\n",
        "- Utility classes: `TextPreprocessor`, `PromptTemplates`, `ModelManager`, `QualityGate`\n",
        "- Functions: `get_or_create_model_manager`, `load_test_data`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "report_generator_section"
      },
      "source": [
        "## 1. Report Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "report_generator_imports"
      },
      "outputs": [],
      "source": [
        "# NOTE: These imports are for standalone execution reference\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "report_generator",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c69d4f-9bb8-425e-a519-11a516608c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReportGenerator loaded\n"
          ]
        }
      ],
      "source": [
        "class ReportGenerator:\n",
        "    \"\"\"Report generator with quality gate integration\"\"\"\n",
        "\n",
        "    CATEGORY_MAPPING = {\n",
        "        '10': 'Music', '17': 'Sports', '19': 'Travel', '20': 'Gaming',\n",
        "        '22': 'People & Blogs', '23': 'Comedy', '24': 'Entertainment',\n",
        "        '25': 'News & Politics', '26': 'HowTo & Style',\n",
        "        '27': 'Education', '28': 'Science & Tech',\n",
        "        10: 'Music', 17: 'Sports', 19: 'Travel', 20: 'Gaming',\n",
        "        22: 'People & Blogs', 23: 'Comedy', 24: 'Entertainment',\n",
        "        25: 'News & Politics', 26: 'HowTo & Style',\n",
        "        27: 'Education', 28: 'Science & Tech'\n",
        "    }\n",
        "\n",
        "    def __init__(self, config: 'PipelineConfig', model_manager: 'ModelManager'):\n",
        "        self.config = config\n",
        "        self.model = model_manager\n",
        "        self.quality_gate = QualityGate(config)\n",
        "\n",
        "    def predict_category(self, video_data: Dict) -> Dict[str, any]:\n",
        "        \"\"\"\n",
        "        Predict category using ML model and LLM validation.\n",
        "\n",
        "        Returns:\n",
        "            Dict with original_id, original_name, model_prediction, llm_validated, used_llm\n",
        "        \"\"\"\n",
        "        video_info = video_data.get('video_info', {})\n",
        "        original_id = video_info.get('category_id', 'Unknown')\n",
        "\n",
        "        result = {\n",
        "            'original_id': original_id,\n",
        "            'original_name': self.CATEGORY_MAPPING.get(original_id, 'Unknown'),\n",
        "            'model_prediction': None,\n",
        "            'llm_validated': None,\n",
        "            'used_llm': False\n",
        "        }\n",
        "\n",
        "        # Step 1: ML Model prediction\n",
        "        predicted_category_id = original_id\n",
        "        if self.config.use_category_model and 'category_model_manager' in globals():\n",
        "            try:\n",
        "                title = video_info.get('title', '')\n",
        "                description = video_info.get('description', '')\n",
        "                text = f\"{title} {description}\"\n",
        "\n",
        "                predicted_name = category_model_manager.predict(text, use_bert=True)\n",
        "                result['model_prediction'] = predicted_name\n",
        "                print(f\"  ML Model Prediction: {predicted_name}\")\n",
        "\n",
        "                # Reverse mapping: name -> id\n",
        "                name_to_id = {v: k for k, v in self.CATEGORY_MAPPING.items() if isinstance(k, int)}\n",
        "                predicted_category_id = name_to_id.get(predicted_name, original_id)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ML Model prediction failed: {str(e)}\")\n",
        "                result['model_prediction'] = \"Model Error\"\n",
        "        else:\n",
        "            print(\"  Category Model disabled or not loaded\")\n",
        "            result['model_prediction'] = \"Not Used\"\n",
        "\n",
        "        # Step 2: LLM validation\n",
        "        if self.config.enable_llm_category_correction:\n",
        "            try:\n",
        "                if isinstance(predicted_category_id, str):\n",
        "                    predicted_category_id = int(predicted_category_id)\n",
        "\n",
        "                validated_id = self.validate_category(video_data, predicted_category_id)\n",
        "                result['llm_validated'] = self.CATEGORY_MAPPING.get(validated_id, f\"ID:{validated_id}\")\n",
        "                result['used_llm'] = True\n",
        "                print(f\"  LLM Validated: {result['llm_validated']}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  LLM validation failed: {str(e)}\")\n",
        "                result['llm_validated'] = result['model_prediction'] or result['original_name']\n",
        "                result['used_llm'] = False\n",
        "        else:\n",
        "            result['llm_validated'] = result['model_prediction'] or result['original_name']\n",
        "            result['used_llm'] = False\n",
        "            print(\"  LLM Category Correction disabled\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    def validate_category(self, video_data: Dict, predicted_category: int) -> int:\n",
        "        \"\"\"Validate category using LLM\"\"\"\n",
        "        if not self.config.enable_llm_category_correction:\n",
        "            return predicted_category\n",
        "\n",
        "        print(\"  Validating category with LLM...\")\n",
        "\n",
        "        video_info = video_data.get('video_info', {})\n",
        "        title = video_info.get('title', '')\n",
        "        description = video_info.get('description', '')\n",
        "\n",
        "        prompt = PromptTemplates.get_category_correction_prompt(\n",
        "            title, description, predicted_category\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            response = self.model.generate(prompt, temperature=0.3)\n",
        "            response = response.strip().upper()\n",
        "\n",
        "            if \"CORRECT:\" in response:\n",
        "                corrected = int(response.split(\":\")[1].strip())\n",
        "                if corrected != predicted_category:\n",
        "                    print(f\"    Category corrected: {predicted_category} -> {corrected}\")\n",
        "                    return corrected\n",
        "                else:\n",
        "                    print(f\"    Category {predicted_category} validated\")\n",
        "                    return predicted_category\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Validation failed, using original: {str(e)}\")\n",
        "\n",
        "        return predicted_category\n",
        "\n",
        "    def generate_video_summary(self, video_data: Dict) -> Tuple[str, str]:\n",
        "        \"\"\"Generate video summary with quality validation\"\"\"\n",
        "        print(\"  Generating video summary...\")\n",
        "\n",
        "        video_info = video_data.get('video_info', {})\n",
        "        title = video_info.get('title', 'N/A')\n",
        "        description = video_info.get('description', 'N/A')\n",
        "        category_id = video_info.get('category_id', 'Unknown')\n",
        "        duration = video_info.get('duration', 'Unknown')\n",
        "\n",
        "        # Preprocess description\n",
        "        if self.config.remove_urls:\n",
        "            description = TextPreprocessor.remove_urls(description)\n",
        "        if len(description) > self.config.max_description_length:\n",
        "            description = description[:self.config.max_description_length] + \"...\"\n",
        "\n",
        "        # Detect language\n",
        "        detected_lang = \"unknown\"\n",
        "        if self.config.detect_language:\n",
        "            detected_lang = TextPreprocessor.detect_language(f\"{title} {description}\")\n",
        "            print(f\"    [Input language: {detected_lang}]\")\n",
        "\n",
        "        prompt = PromptTemplates.get_video_summary_prompt(\n",
        "            title, description, str(category_id), str(duration),\n",
        "            self.config.output_language\n",
        "        )\n",
        "\n",
        "        # Quality gate with regeneration\n",
        "        summary = None\n",
        "        attempts = 0\n",
        "        max_attempts = self.config.max_regeneration_attempts + 1\n",
        "\n",
        "        while attempts < max_attempts:\n",
        "            try:\n",
        "                temp = self.config.quality_gate_temperature if attempts > 0 else self.config.temperature\n",
        "                summary = self.model.generate(prompt, temperature=temp)\n",
        "\n",
        "                is_valid, failure_reasons = self.quality_gate.validate_summary(summary, \"video\")\n",
        "\n",
        "                if is_valid:\n",
        "                    if attempts > 0:\n",
        "                        print(f\"    Quality passed after {attempts} regeneration(s)\")\n",
        "                        self.quality_gate.validation_stats[\"regenerated\"] += 1\n",
        "                    break\n",
        "                else:\n",
        "                    attempts += 1\n",
        "                    if attempts < max_attempts:\n",
        "                        print(f\"    Quality check failed (attempt {attempts}): {', '.join(failure_reasons)}\")\n",
        "                        print(f\"    Regenerating...\")\n",
        "                    else:\n",
        "                        print(f\"    Quality check failed after {attempts} attempts\")\n",
        "                        self.quality_gate.validation_stats[\"failed_final\"] += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    Error: {str(e)}\")\n",
        "                summary = \"Video summary generation failed.\"\n",
        "                break\n",
        "\n",
        "        output_lang = TextPreprocessor.detect_language(summary)\n",
        "        print(f\"    [Output language: {output_lang}]\")\n",
        "\n",
        "        return summary, detected_lang\n",
        "\n",
        "    def generate_reaction_summary(self, comments: List[str]) -> Tuple[str, Dict[str, int]]:\n",
        "        \"\"\"Generate reaction summary with quality validation\"\"\"\n",
        "        print(\"  Generating reaction summary...\")\n",
        "\n",
        "        if not comments:\n",
        "            return \"No comments available for analysis.\", {}\n",
        "\n",
        "        # Preprocess and filter comments\n",
        "        processed_comments = []\n",
        "        for comment in comments[:self.config.max_comments_to_process]:\n",
        "            cleaned = TextPreprocessor.clean_text(comment, remove_urls=self.config.remove_urls)\n",
        "            if len(cleaned) >= self.config.min_comment_length:\n",
        "                processed_comments.append(cleaned)\n",
        "\n",
        "        if not processed_comments:\n",
        "            return \"No valid comments after filtering.\", {}\n",
        "\n",
        "        # Language distribution\n",
        "        lang_dist = TextPreprocessor.get_language_distribution(processed_comments)\n",
        "        print(f\"    [Comment languages: {lang_dist}]\")\n",
        "\n",
        "        prompt = PromptTemplates.get_reaction_summary_prompt(\n",
        "            processed_comments,\n",
        "            self.config.output_language\n",
        "        )\n",
        "\n",
        "        # Quality gate with regeneration\n",
        "        summary = None\n",
        "        attempts = 0\n",
        "        max_attempts = self.config.max_regeneration_attempts + 1\n",
        "\n",
        "        while attempts < max_attempts:\n",
        "            try:\n",
        "                temp = self.config.quality_gate_temperature if attempts > 0 else self.config.temperature\n",
        "                summary = self.model.generate(prompt, temperature=temp)\n",
        "\n",
        "                is_valid, failure_reasons = self.quality_gate.validate_summary(summary, \"reaction\")\n",
        "\n",
        "                if is_valid:\n",
        "                    if attempts > 0:\n",
        "                        print(f\"    Quality passed after {attempts} regeneration(s)\")\n",
        "                        self.quality_gate.validation_stats[\"regenerated\"] += 1\n",
        "                    break\n",
        "                else:\n",
        "                    attempts += 1\n",
        "                    if attempts < max_attempts:\n",
        "                        print(f\"    Quality check failed (attempt {attempts}): {', '.join(failure_reasons)}\")\n",
        "                        print(f\"    Regenerating...\")\n",
        "                    else:\n",
        "                        print(f\"    Quality check failed after {attempts} attempts\")\n",
        "                        self.quality_gate.validation_stats[\"failed_final\"] += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    Error: {str(e)}\")\n",
        "                summary = \"Reaction summary generation failed.\"\n",
        "                break\n",
        "\n",
        "        output_lang = TextPreprocessor.detect_language(summary)\n",
        "        print(f\"    [Output language: {output_lang}]\")\n",
        "\n",
        "        return summary, lang_dist\n",
        "\n",
        "    def calculate_metrics(self, video_data: Dict) -> Dict[str, float]:\n",
        "        \"\"\"Calculate engagement metrics\"\"\"\n",
        "        print(\"  Calculating metrics...\")\n",
        "\n",
        "        views = video_data.get('view_count', 0)\n",
        "        likes = video_data.get('like_count', 0)\n",
        "        comments = video_data.get('comment_count', 0)\n",
        "\n",
        "        return {\n",
        "            'engagement_rate': ((likes + comments) / views * 100) if views > 0 else 0,\n",
        "            'like_rate': (likes / views * 100) if views > 0 else 0,\n",
        "            'comment_rate': (comments / views * 100) if views > 0 else 0\n",
        "        }\n",
        "\n",
        "    def format_report(self, video_data: Dict, video_summary: str,\n",
        "                      reaction_summary: str, metrics: Dict,\n",
        "                      video_lang: str, comment_langs: Dict,\n",
        "                      sentiment_summary: Optional[Dict] = None) -> str:\n",
        "        \"\"\"Format the final markdown report\"\"\"\n",
        "        print(\"  Formatting report...\")\n",
        "\n",
        "        video_info = video_data.get('video_info', {})\n",
        "        category_info = self.predict_category(video_data)\n",
        "\n",
        "        # Top comments\n",
        "        top_comments = []\n",
        "        for i, comment in enumerate(video_data.get('comments', [])[:5], 1):\n",
        "            author = comment.get('author', 'Unknown')\n",
        "            text = comment.get('text', '')\n",
        "            likes = comment.get('like_count', 0)\n",
        "            top_comments.append(f\"{i}. **@{author}** ({likes} likes): {text[:100]}...\")\n",
        "\n",
        "        top_comments_section = \"\\n\\n\".join(top_comments) if top_comments else \"No comments available.\"\n",
        "\n",
        "        # Language formatting\n",
        "        if comment_langs:\n",
        "            sorted_langs = sorted(comment_langs.items(), key=lambda x: x[1], reverse=True)\n",
        "            comment_lang_str = \", \".join([f\"{lang} ({count})\" for lang, count in sorted_langs])\n",
        "        else:\n",
        "            comment_lang_str = \"No comments analyzed\"\n",
        "\n",
        "        video_lang_display = \"Unknown\" if video_lang.lower() == \"unknown\" else video_lang\n",
        "\n",
        "        # Comment analysis stats\n",
        "        total_comments = video_info.get('comment_count', 0)\n",
        "        analyzed_comments = len(video_data.get('comments', []))\n",
        "        analysis_rate = (analyzed_comments / total_comments * 100) if total_comments > 0 else 0\n",
        "\n",
        "        # Category display\n",
        "        if category_info['used_llm']:\n",
        "            category_display = f\"- **Category (ML Model)**: {category_info['model_prediction']} \\n- **Category (LLM Validated)**: {category_info['llm_validated']}\"\n",
        "        elif category_info['model_prediction'] and category_info['model_prediction'] != \"Not Used\":\n",
        "            category_display = f\"- **Category (ML Model)**: {category_info['model_prediction']}\"\n",
        "        else:\n",
        "            category_display = f\"- **Category**: {category_info['original_id']} ({category_info['original_name']})\"\n",
        "\n",
        "        report = f\"\"\"# YouTube Video Report\n",
        "\n",
        "**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "**Model**: {self.config.model_name}\n",
        "**Pipeline Version**: 2.3\n",
        "\n",
        "---\n",
        "\n",
        "## Video Information\n",
        "\n",
        "- **Title**: {video_info.get('title', 'N/A')}\n",
        "- **Channel**: {video_info.get('channel_title', 'N/A')}\n",
        "{category_display}\n",
        "- **Published**: {video_info.get('published_at', 'N/A')}\n",
        "- **Duration**: {video_info.get('duration', 'N/A')} seconds\n",
        "- **Video ID**: `{video_info.get('video_id', 'N/A')}`\n",
        "- **URL**: https://www.youtube.com/watch?v={video_info.get('video_id', 'N/A')}\n",
        "\n",
        "### Detected Languages\n",
        "\n",
        "- **Video content**: {video_lang_display}\n",
        "- **Comments**: {comment_lang_str}\n",
        "- **Report language**: {self.config.output_language}\n",
        "\n",
        "---\n",
        "\n",
        "## Engagement Metrics\n",
        "\n",
        "| Metric | Value |\n",
        "|--------|-------|\n",
        "| Views | {video_info.get('view_count', 0):,} |\n",
        "| Likes | {video_info.get('like_count', 0):,} |\n",
        "| Comments | {video_info.get('comment_count', 0):,} |\n",
        "| Engagement Rate | {metrics.get('engagement_rate', 0):.2f}% |\n",
        "| Like Rate | {metrics.get('like_rate', 0):.2f}% |\n",
        "| Comment Rate | {metrics.get('comment_rate', 0):.2f}% |\n",
        "\n",
        "---\n",
        "\n",
        "## Video Summary\n",
        "\n",
        "{video_summary}\n",
        "\n",
        "---\n",
        "\n",
        "## Audience Reaction Summary\n",
        "\n",
        "**Comments Analyzed**: {analyzed_comments} / {total_comments} ({analysis_rate:.1f}%)\n",
        "\n",
        "### ML Model Sentiment Analysis\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "        # Add ML sentiment if available\n",
        "        if sentiment_summary:\n",
        "            report += f\"\"\"**Distribution:**\n",
        "- Positive: {sentiment_summary['pos_count']} ({sentiment_summary['pos_ratio']:.1f}%)\n",
        "- Neutral: {sentiment_summary['neu_count']} ({sentiment_summary['neu_ratio']:.1f}%)\n",
        "- Negative: {sentiment_summary['neg_count']} ({sentiment_summary['neg_ratio']:.1f}%)\n",
        "\n",
        "**Model Confidence (Average):**\n",
        "- P(Positive): {sentiment_summary['avg_p_pos']:.1f}%\n",
        "- P(Neutral): {sentiment_summary['avg_p_neu']:.1f}%\n",
        "- P(Negative): {sentiment_summary['avg_p_neg']:.1f}%\n",
        "\n",
        "\"\"\"\n",
        "            # Interpretation\n",
        "            if sentiment_summary['pos_ratio'] > 60:\n",
        "                report += \"**Interpretation**: Highly positive audience reception!\\n\\n\"\n",
        "            elif sentiment_summary['neg_ratio'] > 40:\n",
        "                report += \"**Interpretation**: Audience shows significant negative sentiment.\\n\\n\"\n",
        "            else:\n",
        "                report += \"**Interpretation**: Mixed audience sentiment with balanced reactions.\\n\\n\"\n",
        "        else:\n",
        "            report += \"*(ML Model not available or disabled)*\\n\\n\"\n",
        "\n",
        "        report += \"---\\n\\n\"\n",
        "\n",
        "        # LLM analysis\n",
        "        report += f\"\"\"### LLM Qualitative Analysis\n",
        "\n",
        "{reaction_summary}\n",
        "\n",
        "---\n",
        "\n",
        "## Top Comments\n",
        "\n",
        "{top_comments_section}\n",
        "\n",
        "---\n",
        "\n",
        "## Technical Notes\n",
        "\n",
        "- This report was automatically generated using LLM-based multilingual analysis\n",
        "- Token Efficiency: Dynamic token allocation based on input length\n",
        "- Quality Gate: Automatic validation and regeneration for quality assurance\n",
        "- Input content processed in original language(s) without translation layer\n",
        "- Output language fixed to {self.config.output_language} for consistency\n",
        "\n",
        "---\n",
        "\n",
        "*Generated by YouTube Report Generator - Phase 2 Full Pipeline v2.3*\n",
        "\"\"\"\n",
        "\n",
        "        return report\n",
        "\n",
        "    def generate_full_report(self, video_data: Dict) -> str:\n",
        "        \"\"\"Generate complete report pipeline\"\"\"\n",
        "        video_info = video_data.get('video_info', {})\n",
        "        print(f\"\\nProcessing: {video_info.get('title', 'Unknown')[:50]}...\")\n",
        "\n",
        "        # 1. Video summary\n",
        "        video_summary, video_lang = self.generate_video_summary(video_data)\n",
        "\n",
        "        # 2. Sentiment analysis (ML Model)\n",
        "        sentiment_summary = None\n",
        "        if self.config.use_sentiment_model and 'sentiment_model_manager' in globals():\n",
        "            if sentiment_model_manager.bert_model or sentiment_model_manager.classic_clf:\n",
        "                print(\"\\n  Analyzing sentiment with ML model...\")\n",
        "\n",
        "                comments = video_data.get('comments', [])\n",
        "                if comments:\n",
        "                    max_comments = min(len(comments), self.config.max_comments_to_process)\n",
        "                    comment_texts = [c.get('text', '') for c in comments[:max_comments]]\n",
        "\n",
        "                    try:\n",
        "                        sentiment_results = sentiment_model_manager.predict(\n",
        "                            comment_texts,\n",
        "                            use_bert=True,\n",
        "                            use_classic=True,\n",
        "                            ensemble=\"bert_priority\"\n",
        "                        )\n",
        "\n",
        "                        preds = sentiment_results[\"predictions\"]\n",
        "                        probs = sentiment_results[\"probabilities\"]\n",
        "\n",
        "                        pred_counts = Counter(preds)\n",
        "                        total = len(preds)\n",
        "\n",
        "                        sentiment_summary = {\n",
        "                            \"pos_count\": pred_counts.get(\"pos\", 0),\n",
        "                            \"neu_count\": pred_counts.get(\"neu\", 0),\n",
        "                            \"neg_count\": pred_counts.get(\"neg\", 0),\n",
        "                            \"pos_ratio\": pred_counts.get(\"pos\", 0) / total * 100 if total > 0 else 0,\n",
        "                            \"neu_ratio\": pred_counts.get(\"neu\", 0) / total * 100 if total > 0 else 0,\n",
        "                            \"neg_ratio\": pred_counts.get(\"neg\", 0) / total * 100 if total > 0 else 0,\n",
        "                            \"avg_p_pos\": probs[:, 2].mean() * 100,\n",
        "                            \"avg_p_neu\": probs[:, 1].mean() * 100,\n",
        "                            \"avg_p_neg\": probs[:, 0].mean() * 100,\n",
        "                            \"total_analyzed\": total\n",
        "                        }\n",
        "\n",
        "                        print(f\"    ML Sentiment: Pos {sentiment_summary['pos_ratio']:.1f}% | \"\n",
        "                              f\"Neu {sentiment_summary['neu_ratio']:.1f}% | \"\n",
        "                              f\"Neg {sentiment_summary['neg_ratio']:.1f}%\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"    Sentiment analysis failed: {e}\")\n",
        "                        sentiment_summary = None\n",
        "\n",
        "        # 3. Reaction summary\n",
        "        comments = [c.get('text', '') for c in video_data.get('comments', [])]\n",
        "        reaction_summary, comment_langs = self.generate_reaction_summary(comments)\n",
        "\n",
        "        # 4. Calculate metrics\n",
        "        metrics = self.calculate_metrics(video_info)\n",
        "\n",
        "        # 5. Format report\n",
        "        report = self.format_report(\n",
        "            video_data,\n",
        "            video_summary,\n",
        "            reaction_summary,\n",
        "            metrics,\n",
        "            video_lang,\n",
        "            comment_langs,\n",
        "            sentiment_summary\n",
        "        )\n",
        "\n",
        "        print(\"  Done!\")\n",
        "        return report\n",
        "\n",
        "\n",
        "print(\"ReportGenerator loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pipeline_section"
      },
      "source": [
        "## 2. Pipeline Execution Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pipeline_functions",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "389ac04b-f668-4775-f0ac-40b82b85e658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline functions loaded\n"
          ]
        }
      ],
      "source": [
        "def run_pipeline(config: 'PipelineConfig', test_videos: List[Dict],\n",
        "                 model_manager: Optional['ModelManager'] = None,\n",
        "                 force_reload: bool = False) -> List[str]:\n",
        "    \"\"\"\n",
        "    Execute full pipeline on multiple videos.\n",
        "\n",
        "    Args:\n",
        "        config: Pipeline configuration\n",
        "        test_videos: List of video data dictionaries\n",
        "        model_manager: Existing model manager (None to auto-create)\n",
        "        force_reload: Force reload model if True\n",
        "\n",
        "    Returns:\n",
        "        List of generated reports\n",
        "    \"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"STARTING FULL PIPELINE\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Get or create model manager\n",
        "    if model_manager is None:\n",
        "        model_manager = get_or_create_model_manager(config, force_reload)\n",
        "    else:\n",
        "        print(\"Using provided model manager\")\n",
        "\n",
        "    # Initialize report generator\n",
        "    report_gen = ReportGenerator(config, model_manager)\n",
        "\n",
        "    # Process each video\n",
        "    reports = []\n",
        "    for i, video in enumerate(test_videos, 1):\n",
        "        print(f\"\\n{'=' * 80}\")\n",
        "        print(f\"Video {i}/{len(test_videos)}\")\n",
        "        print(f\"{'=' * 80}\")\n",
        "\n",
        "        report = report_gen.generate_full_report(video)\n",
        "        reports.append(report)\n",
        "\n",
        "    print(f\"\\n{'=' * 80}\")\n",
        "    print(\"PIPELINE COMPLETED\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Print efficiency reports\n",
        "    print(model_manager.get_token_efficiency_report())\n",
        "    print(report_gen.quality_gate.get_quality_report())\n",
        "\n",
        "    return reports\n",
        "\n",
        "\n",
        "print(\"Pipeline functions loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "execution_section"
      },
      "source": [
        "## 3. Execute Pipeline (JSON Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "execute_pipeline",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a5865f2c30954078bd5f15b8991cf28c",
            "1ce5177ff25742569d975cf55b6d5071",
            "24a475a8d9b24f5b82c362b1f30be614",
            "322fcb48e549422b8cb28be0be829cc1",
            "f6b7d789e5f34ab981d21076d361b7ed",
            "bed3025cc54d432b849622b044e6f610",
            "4705922ef99d43168c314e7b7971d455",
            "8aabdbab6c4c40bc8c18586d5af042a5",
            "c3beebc4de5f41bfbb6a3dc674c373a0",
            "469be542154f40afa4a97a979e6a43b2",
            "723345f5bd094741b1f5f08d4172d5a9",
            "b2ff6bbf97c447eeb47d0daafa48f310",
            "4fbd5db1119146d09d4c376ade67db93",
            "22a2036531024bb5ab237ea0f3028d98",
            "d0d58d874d064bc18a91f64fbe9dc0f3",
            "ef44f0ff40824373826997f853eddd0d",
            "acdf772a0a0f468cb698c9131a79303e",
            "1b35c8f5170c4988a065097f5d9d51aa",
            "96831706d99c4f5faf8c917790bac45e",
            "fa59a29b453a40fdbbda523266df609c",
            "81579cd60f934881bf4f6057cf5af1ef",
            "4770c9609f314868806c8d7d8ed2d403",
            "6b0e4b62ec6e4546861b768f4f45c0bd",
            "6ea9c48017c2424abf15ad9a1c5f717e",
            "5e271df14c0c4535ba00ad69343d58b0",
            "bc6137268db24fb694f78dbb5b76bd70",
            "939cb135db9e4b6597d79adc84aacd35",
            "4ec0aae9ff5044b78f9ed96d1e32cc4e",
            "f23b8c5b00b44c19afde0e62ff98dc84",
            "ca0315a0811141278fde25c28184de89",
            "e6f01261beec4919b503a11b71edfb4d",
            "4237a9dc610f4dbe845588834b97ed51",
            "47599aa53f1443bfa9fd5c8d53ccaae1",
            "1c9ef75a07c044178bf41dc86c4f5f51",
            "1efa60f5c5ce4384b48b3f0cdec07812",
            "8b0be080967847bd9db86d686b819820",
            "1a2d276c098c43aa83045580213c9480",
            "8bc97a2b5f8c471094596a1293ae5493",
            "82398331ef09463f99efb3668935c3f6",
            "5ad59aef7d044d3ea8f0929c74179cf3",
            "86ae301a27a34969bad1ee300e195f7e",
            "d2488c6d12094c078a6e427a604e435f",
            "1f8982a16a194a17b7192bdbf8cfecc6",
            "75c1db22131d47d1a3a52a4cc0d3adb0",
            "6be7b1198bcf4177a9bf3a626a8ac0b9",
            "34f2e3fb2710444ab433ee97a2786f76",
            "37fc2f35cb594220b56ab657cde67dad",
            "aa1ddd9f25fc45d1b71ad74e6b622808",
            "9264099b911f498d8db7cbc310c58000",
            "d7b99df4aac24e3dbf8395aed0ca8da7",
            "951dda4406884de98b2f8fcee0935b31",
            "9a5cfa2326324ee2a2e3458957d909ab",
            "5b0c0aa72ca74546bc106b987f391cb0",
            "4d694044effd44de960ccfcd9a291d15",
            "da48314e1c644fc9850c21b4b11578e3",
            "3656fc763cf24d039830e49487c55df8",
            "52abae1a1e204489a8438ea24274ae3c",
            "52de9d66e39b475fa163e61ea7cb4150",
            "0a69de2f4dd74076b6baa9fa56e78a1f",
            "c0831b7820344eff8165a7ca35f8f85c",
            "91d40f62e5bd417eb62f3798e6ad0d26",
            "e1bb5ec2d8454f9bbd2482acd136b953",
            "656fb74c226a4a968b2a46670b80b082",
            "1ea582815f4b430ab9350f95dcdded05",
            "5486d91c97424bd58f424b2dc1a5db9d",
            "53814e2fe7ad4a55a5ea5177870231f6",
            "e48c64ca72d54c36b793446859d34beb",
            "ddb6d7c0bea542a38725261b76e60a02",
            "a662c1282836449c854593afe53cacfb",
            "597ae11b55274613a6d8e00a8605c17a",
            "6d6e4cf882294ed3a5093e435eee9a99",
            "2492a190798246b5a47a1e392f4cfdce",
            "970c70d162184a93a499d5cc41ae3b0c",
            "8fe4dae176a74a4798a9f1608324343f",
            "0b760a3723ae4044899440cc56db1297",
            "f1d746b3f01a4636b7799b4900366aea",
            "0572eef7bc204d79bc76684e004a8446",
            "bd22bbbfd2c04950963c872d20ebce73",
            "f7a6750cb0da4558aa8a6d013bcb88c1",
            "dc49d2d0688148a2b9480ea319947f76",
            "e66ca8214c75478d8c1417c0d8ae0987",
            "40699855419643d899013ed8d2fe65de",
            "344eecd3046348bca04154612a295147",
            "2648c9082cfa4e57a597ef184774f423",
            "a5a1ac299f2d4156a5aec999220df5af",
            "84ffe3fdb0f34673b68b056b3f390014",
            "9ff4b467cba84e4ea05b881536f2162e",
            "a8d090a61f6445c8b7b546389d95036b",
            "09280d1ca3e34a429c4ffc7528b7b49c",
            "a442cfca7c0c4a4293c49f7d48777954",
            "b1d1748a6a61477998b0fce0266678dd",
            "393f57fa721b4646b7993ec84ed0e831",
            "9a5f1db731b942d58c9a9c646733e89d",
            "1e558611ff3747e69c7f0abf58463abe",
            "49b8cb1d92794f528f903d6521fbe760",
            "21f1d85913d0405cb75d35d851695f39",
            "56c7ba4140d74214ad8b012f9ff6d0c2",
            "4738d93b7f144375a8be8945552f6966",
            "680a3a6352c8456c9dcad790c899fe28",
            "622a6f8513b44535b32b61df51bf3d91",
            "fe96feedc2ab4b2598253353b0014b45",
            "529182bd5936473d936493f0af648c15",
            "5fd1fe2e7e46472d974d5961469b4d1a",
            "4a3272a7970646e58af4c7e5316d563d",
            "ef36998b10674150ae5bd4988b95c8af",
            "fbda7f9c2e824e949a85503ff2e1df37",
            "f84c27d379e5456e9962ae66f1d14fc7",
            "0486cbbf483d4f89bfce7ca8ec3834af",
            "4a8d088df29f4749807d45e9f317c356",
            "bb9396a99ee84ee686abf0a5ee79c7c7",
            "c68e7e8465a54f509960789b752ad634",
            "a9138cdc026743d685d03b42ce7f923d",
            "0ad4d020ee134f4fafa0cb606462cd87",
            "7f53ab6a05d04b05a4c1e059cebce311",
            "75819672e8dd4a0ea2cc0e4e464743ce",
            "8237dbd217e6453a8d2ab80e203269fc",
            "65156932531c452b9088f1b0728434ca",
            "8fb342591e684ef1bbc7f26230b153c7",
            "acea9fd4d22d4dd887938dee002868e3",
            "1a386656758a41e1947d1ce087b237de",
            "9b73564e9ae2447ebd88d0a95d8a917e",
            "6a99fee6311d41a383a518715022b68a",
            "ca70217c6bda42d5abba743321009260",
            "c9d1f7bb31a5452fb3aaa5c784e175ba",
            "ae034a9a579c4fe6b92c3cf27451185d",
            "8dadbb4255764d2ba7165ee8c1f7ae8c",
            "98f50ddb2d944afc9bc0691b9827caab",
            "339561e0218a44cf8fd5c1a544874b76",
            "7811aed94ba24ea2b8d02e36ccf5aab8",
            "f5c56d4f6bbd45479431ee322db80c43",
            "bb348ce75b924394919023772e474bfa",
            "286ffe532b084afa8db4383fbbf16704"
          ]
        },
        "outputId": "276b9982-ae73-4927-a87a-2b594f0ef89c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from: /content/drive/MyDrive/25_sch/ML/youtube_test_10132154/full_dataset_20251013_215347.json\n",
            "  Found 20 videos in dataset\n",
            "  Using 3 videos for testing\n",
            "================================================================================\n",
            "STARTING FULL PIPELINE\n",
            "================================================================================\n",
            "Loading model: meta-llama/Llama-3.1-8B-Instruct\n",
            "Loading meta-llama/Llama-3.1-8B-Instruct...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5865f2c30954078bd5f15b8991cf28c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2ff6bbf97c447eeb47d0daafa48f310"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b0e4b62ec6e4546861b768f4f45c0bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c9ef75a07c044178bf41dc86c4f5f51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6be7b1198bcf4177a9bf3a626a8ac0b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3656fc763cf24d039830e49487c55df8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e48c64ca72d54c36b793446859d34beb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd22bbbfd2c04950963c872d20ebce73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09280d1ca3e34a429c4ffc7528b7b49c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "622a6f8513b44535b32b61df51bf3d91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c68e7e8465a54f509960789b752ad634"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a99fee6311d41a383a518715022b68a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on cuda\n",
            "Memory allocated: 7.54 GB\n",
            "\n",
            "================================================================================\n",
            "Video 1/3\n",
            "================================================================================\n",
            "\n",
            "Processing: NMIXX(엔믹스) “Blue Valentine” M/V...\n",
            "  Generating video summary...\n",
            "    [Input language: English]\n",
            "      [Input: 305 tokens, Max output: 256]\n",
            "      [Output: 153 tokens]\n",
            "    [Output language: English]\n",
            "\n",
            "  Analyzing sentiment with ML model...\n",
            "    ML Sentiment: Pos 100.0% | Neu 0.0% | Neg 0.0%\n",
            "  Generating reaction summary...\n",
            "    [Comment languages: {'Korean': 9, 'English': 8, 'Japanese': 3}]\n",
            "      [Input: 1478 tokens, Max output: 384]\n",
            "      [Output: 194 tokens]\n",
            "    [Output language: English]\n",
            "  Calculating metrics...\n",
            "  Formatting report...\n",
            "  ML Model Prediction: Gaming\n",
            "  Validating category with LLM...\n",
            "      [Input: 371 tokens, Max output: 256]\n",
            "      [Output: 6 tokens]\n",
            "    Category corrected: 20 -> 10\n",
            "  LLM Validated: Music\n",
            "  Done!\n",
            "\n",
            "================================================================================\n",
            "Video 2/3\n",
            "================================================================================\n",
            "\n",
            "Processing: How well do I know ROBLOX | ALBERTGUESSR...\n",
            "  Generating video summary...\n",
            "    [Input language: English]\n",
            "      [Input: 260 tokens, Max output: 256]\n",
            "      [Output: 179 tokens]\n",
            "    [Output language: English]\n",
            "\n",
            "  Analyzing sentiment with ML model...\n",
            "    ML Sentiment: Pos 30.0% | Neu 60.0% | Neg 10.0%\n",
            "  Generating reaction summary...\n",
            "    [Comment languages: {'English': 16, 'German': 3, 'Id': 1}]\n",
            "      [Input: 590 tokens, Max output: 384]\n",
            "      [Output: 252 tokens]\n",
            "    [Output language: English]\n",
            "  Calculating metrics...\n",
            "  Formatting report...\n",
            "  ML Model Prediction: Entertainment\n",
            "  Validating category with LLM...\n",
            "      [Input: 358 tokens, Max output: 256]\n",
            "      [Output: 6 tokens]\n",
            "    Category corrected: 24 -> 20\n",
            "  LLM Validated: Gaming\n",
            "  Done!\n",
            "\n",
            "================================================================================\n",
            "Video 3/3\n",
            "================================================================================\n",
            "\n",
            "Processing: 劇場版『チェンソーマン レゼ篇』オープニングムービー 　主題歌：米津玄師「IRIS OUT」“Cha...\n",
            "  Generating video summary...\n",
            "    [Input language: Japanese]\n",
            "      [Input: 1443 tokens, Max output: 384]\n",
            "      [Output: 180 tokens]\n",
            "    [Output language: English]\n",
            "\n",
            "  Analyzing sentiment with ML model...\n",
            "    ML Sentiment: Pos 75.0% | Neu 20.0% | Neg 5.0%\n",
            "  Generating reaction summary...\n",
            "    [Comment languages: {'Japanese': 19, 'English': 1}]\n",
            "      [Input: 1071 tokens, Max output: 384]\n",
            "      [Output: 222 tokens]\n",
            "    [Output language: English]\n",
            "  Calculating metrics...\n",
            "  Formatting report...\n",
            "  ML Model Prediction: Entertainment\n",
            "  Validating category with LLM...\n",
            "      [Input: 495 tokens, Max output: 256]\n",
            "      [Output: 6 tokens]\n",
            "    Category 24 validated\n",
            "  LLM Validated: Entertainment\n",
            "  Done!\n",
            "\n",
            "================================================================================\n",
            "PIPELINE COMPLETED\n",
            "================================================================================\n",
            "\n",
            "╔══════════════════════════════════════════════════════════╗\n",
            "║              TOKEN EFFICIENCY REPORT                     ║\n",
            "╠══════════════════════════════════════════════════════════╣\n",
            "║ Total Calls:                9                         ║\n",
            "║ Total Input Tokens:      6371                         ║\n",
            "║ Total Output Tokens:     1198                         ║\n",
            "║ Tokens Saved:            1792                         ║\n",
            "║ Avg Tokens/Call:        841.0                         ║\n",
            "║ Efficiency Gain:        23.7%                         ║\n",
            "╚══════════════════════════════════════════════════════════╝\n",
            "\n",
            "\n",
            "╔══════════════════════════════════════════════════════════╗\n",
            "║              QUALITY GATE REPORT                         ║\n",
            "╠══════════════════════════════════════════════════════════╣\n",
            "║ Total Validations:          6                         ║\n",
            "║ Passed First Time:          6 (100.0%)              ║\n",
            "║ Regenerated:                0 (  0.0%)              ║\n",
            "║ Failed Final:               0                         ║\n",
            "╚══════════════════════════════════════════════════════════╝\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load test data and run pipeline\n",
        "test_videos = load_test_data(config.data_path, config.num_videos_for_test)\n",
        "reports = run_pipeline(config, test_videos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "display_report",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5dfedd5d-0801-4755-de24-6e4aa38efd0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SAMPLE REPORT (First Video)\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# YouTube Video Report\n\n**Generated**: 2025-12-13 01:02:57\n**Model**: meta-llama/Llama-3.1-8B-Instruct\n**Pipeline Version**: 2.3\n\n---\n\n## Video Information\n\n- **Title**: NMIXX(엔믹스) “Blue Valentine” M/V\n- **Channel**: JYP Entertainment\n- **Category (ML Model)**: Gaming \n- **Category (LLM Validated)**: Music\n- **Published**: 2025-10-13T09:00:02Z\n- **Duration**: PT3M15S seconds\n- **Video ID**: `EmeW6li6bbo`\n- **URL**: https://www.youtube.com/watch?v=EmeW6li6bbo\n\n### Detected Languages\n\n- **Video content**: English\n- **Comments**: Korean (9), English (8), Japanese (3)\n- **Report language**: English\n\n---\n\n## Engagement Metrics\n\n| Metric | Value |\n|--------|-------|\n| Views | 1,295,943 |\n| Likes | 66,047 |\n| Comments | 6,284 |\n| Engagement Rate | 5.58% |\n| Like Rate | 5.10% |\n| Comment Rate | 0.48% |\n\n---\n\n## Video Summary\n\nKEY POINT:\nThe music video \"Blue Valentine\" by NMIXX is a captivating visual representation of the K-pop group's energetic and emotive performance, featuring a blend of vibrant colors and synchronized choreography. The video showcases the group's unique style and musicality.\n\nDETAILED SUMMARY:\n\"Blue Valentine\" is a music video by the South Korean girl group NMIXX, released under JYP Entertainment. The video features the group's members performing an addictive and upbeat track, showcasing their synchronized dance moves and captivating stage presence. With a bright and vibrant color palette, the video adds to the overall energetic and youthful vibe of the song. Throughout the video, the members demonstrate their impressive dance skills and charismatic charm, highlighting the group's talent and appeal.\n\n---\n\n## Audience Reaction Summary\n\n**Comments Analyzed**: 20 / 6284 (0.3%)\n\n### ML Model Sentiment Analysis\n\n**Distribution:**\n- Positive: 20 (100.0%)\n- Neutral: 0 (0.0%)\n- Negative: 0 (0.0%)\n\n**Model Confidence (Average):**\n- P(Positive): 90.6%\n- P(Neutral): 7.5%\n- P(Negative): 1.9%\n\n**Interpretation**: Highly positive audience reception!\n\n---\n\n### LLM Qualitative Analysis\n\nKEY POINT:\nThe overall reaction to the NMIXX song and music video is overwhelmingly positive, with viewers praising the group's unique sound, emotional lyrics, and captivating visuals.\n\nDETAILED SUMMARY:\nThe majority of viewers (around 85%) are thrilled with the song and music video, praising NMIXX for their growth and unique style. Many commenters (around 60%) highlight the emotional lyrics, vocal delivery, and nostalgic vibe of the song, which they believe will resonate with listeners. Some viewers (around 10%) appreciate the music video's captivating visuals and choreography, while others (around 5%) mention the song's ability to evoke various emotions, from sadness to happiness. Notable minority views include a few commenters who express concerns about the song's potential to appeal to a broader audience, but these views are relatively rare.\n\nSENTIMENT BREAKDOWN:\nPositive: 85%  Negative: 5%  Neutral: 10%\n\n---\n\n## Top Comments\n\n1. **@@하-d7k** (58 likes): 이건 열심히 달려온 모든게 준비된 엔믹스들에게 온 너무 소중한 기회임 안 뜬다면… 케이팝 시장에 문제가 있는 건데 앞으로 홍보만 잘 돌리면 될 것 같은데 제발 힘을 내 제와피 !!...\n\n2. **@@mikzzza-k7o** (141 likes): i have this unexplainable feeling that this song will be a hit, the biggest so far in the entire nmi...\n\n3. **@@Belle_vie** (33 likes): 와 이번에는 수록곡뿐만 아니라 타이틀도 너무 잘 꼽았다 진짜… 트렌디하면서도 뭔가 애틋 아련하면서도 벅차고 느낌 너무 좋은데....\n\n4. **@@mAsHuMaRoPanda** (132 likes): Wait! People! Seriously! Please pay attention to lyrics! Their vocal delivery! Like this is the most...\n\n5. **@@rynnieeefairy** (320 likes): this song feels so upbeat and nostalgic!! and like many are saying, their sound/color is so unique, ...\n\n---\n\n## Technical Notes\n\n- This report was automatically generated using LLM-based multilingual analysis\n- Token Efficiency: Dynamic token allocation based on input length\n- Quality Gate: Automatic validation and regeneration for quality assurance\n- Input content processed in original language(s) without translation layer\n- Output language fixed to English for consistency\n\n---\n\n*Generated by YouTube Report Generator - Phase 2 Full Pipeline v2.3*\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Display first report\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"SAMPLE REPORT (First Video)\")\n",
        "print(\"=\" * 80)\n",
        "display(Markdown(reports[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "display_all_reports",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d75d5ef3-acc2-4656-91cd-ff2e353a2b75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "REPORT 1/3\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# YouTube Video Report\n\n**Generated**: 2025-12-13 01:02:57\n**Model**: meta-llama/Llama-3.1-8B-Instruct\n**Pipeline Version**: 2.3\n\n---\n\n## Video Information\n\n- **Title**: NMIXX(엔믹스) “Blue Valentine” M/V\n- **Channel**: JYP Entertainment\n- **Category (ML Model)**: Gaming \n- **Category (LLM Validated)**: Music\n- **Published**: 2025-10-13T09:00:02Z\n- **Duration**: PT3M15S seconds\n- **Video ID**: `EmeW6li6bbo`\n- **URL**: https://www.youtube.com/watch?v=EmeW6li6bbo\n\n### Detected Languages\n\n- **Video content**: English\n- **Comments**: Korean (9), English (8), Japanese (3)\n- **Report language**: English\n\n---\n\n## Engagement Metrics\n\n| Metric | Value |\n|--------|-------|\n| Views | 1,295,943 |\n| Likes | 66,047 |\n| Comments | 6,284 |\n| Engagement Rate | 5.58% |\n| Like Rate | 5.10% |\n| Comment Rate | 0.48% |\n\n---\n\n## Video Summary\n\nKEY POINT:\nThe music video \"Blue Valentine\" by NMIXX is a captivating visual representation of the K-pop group's energetic and emotive performance, featuring a blend of vibrant colors and synchronized choreography. The video showcases the group's unique style and musicality.\n\nDETAILED SUMMARY:\n\"Blue Valentine\" is a music video by the South Korean girl group NMIXX, released under JYP Entertainment. The video features the group's members performing an addictive and upbeat track, showcasing their synchronized dance moves and captivating stage presence. With a bright and vibrant color palette, the video adds to the overall energetic and youthful vibe of the song. Throughout the video, the members demonstrate their impressive dance skills and charismatic charm, highlighting the group's talent and appeal.\n\n---\n\n## Audience Reaction Summary\n\n**Comments Analyzed**: 20 / 6284 (0.3%)\n\n### ML Model Sentiment Analysis\n\n**Distribution:**\n- Positive: 20 (100.0%)\n- Neutral: 0 (0.0%)\n- Negative: 0 (0.0%)\n\n**Model Confidence (Average):**\n- P(Positive): 90.6%\n- P(Neutral): 7.5%\n- P(Negative): 1.9%\n\n**Interpretation**: Highly positive audience reception!\n\n---\n\n### LLM Qualitative Analysis\n\nKEY POINT:\nThe overall reaction to the NMIXX song and music video is overwhelmingly positive, with viewers praising the group's unique sound, emotional lyrics, and captivating visuals.\n\nDETAILED SUMMARY:\nThe majority of viewers (around 85%) are thrilled with the song and music video, praising NMIXX for their growth and unique style. Many commenters (around 60%) highlight the emotional lyrics, vocal delivery, and nostalgic vibe of the song, which they believe will resonate with listeners. Some viewers (around 10%) appreciate the music video's captivating visuals and choreography, while others (around 5%) mention the song's ability to evoke various emotions, from sadness to happiness. Notable minority views include a few commenters who express concerns about the song's potential to appeal to a broader audience, but these views are relatively rare.\n\nSENTIMENT BREAKDOWN:\nPositive: 85%  Negative: 5%  Neutral: 10%\n\n---\n\n## Top Comments\n\n1. **@@하-d7k** (58 likes): 이건 열심히 달려온 모든게 준비된 엔믹스들에게 온 너무 소중한 기회임 안 뜬다면… 케이팝 시장에 문제가 있는 건데 앞으로 홍보만 잘 돌리면 될 것 같은데 제발 힘을 내 제와피 !!...\n\n2. **@@mikzzza-k7o** (141 likes): i have this unexplainable feeling that this song will be a hit, the biggest so far in the entire nmi...\n\n3. **@@Belle_vie** (33 likes): 와 이번에는 수록곡뿐만 아니라 타이틀도 너무 잘 꼽았다 진짜… 트렌디하면서도 뭔가 애틋 아련하면서도 벅차고 느낌 너무 좋은데....\n\n4. **@@mAsHuMaRoPanda** (132 likes): Wait! People! Seriously! Please pay attention to lyrics! Their vocal delivery! Like this is the most...\n\n5. **@@rynnieeefairy** (320 likes): this song feels so upbeat and nostalgic!! and like many are saying, their sound/color is so unique, ...\n\n---\n\n## Technical Notes\n\n- This report was automatically generated using LLM-based multilingual analysis\n- Token Efficiency: Dynamic token allocation based on input length\n- Quality Gate: Automatic validation and regeneration for quality assurance\n- Input content processed in original language(s) without translation layer\n- Output language fixed to English for consistency\n\n---\n\n*Generated by YouTube Report Generator - Phase 2 Full Pipeline v2.3*\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "REPORT 2/3\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# YouTube Video Report\n\n**Generated**: 2025-12-13 01:03:29\n**Model**: meta-llama/Llama-3.1-8B-Instruct\n**Pipeline Version**: 2.3\n\n---\n\n## Video Information\n\n- **Title**: How well do I know ROBLOX | ALBERTGUESSR\n- **Channel**: Flamingo\n- **Category (ML Model)**: Entertainment \n- **Category (LLM Validated)**: Gaming\n- **Published**: 2025-10-13T03:13:19Z\n- **Duration**: PT27M10S seconds\n- **Video ID**: `RGbDW-hyxxc`\n- **URL**: https://www.youtube.com/watch?v=RGbDW-hyxxc\n\n### Detected Languages\n\n- **Video content**: English\n- **Comments**: English (16), German (3), Id (1)\n- **Report language**: English\n\n---\n\n## Engagement Metrics\n\n| Metric | Value |\n|--------|-------|\n| Views | 349,586 |\n| Likes | 23,507 |\n| Comments | 2,703 |\n| Engagement Rate | 7.50% |\n| Like Rate | 6.72% |\n| Comment Rate | 0.77% |\n\n---\n\n## Video Summary\n\nKEY POINT:\nIn this entertaining video, AlbertGUESSR plays Roblox GeoGuessr, where he is teleported into various Roblox games to test his knowledge and guessing skills. He shares a list of games, categorized by difficulty levels, for viewers to explore.\n\nDETAILED SUMMARY:\nAlbertGUESSR embarks on an exciting adventure through Roblox GeoGuessr, a game that challenges his knowledge of various Roblox games. He is transported into different games, including some that are no longer available on Roblox due to updates, and attempts to guess the correct game based on his surroundings. The games are categorized into four difficulty levels: easy, medium, hard, and impossible modes, providing a variety of challenges for AlbertGUESSR to tackle. Throughout the video, viewers can access links to the games featured, allowing them to explore the games for themselves.\n\n---\n\n## Audience Reaction Summary\n\n**Comments Analyzed**: 20 / 2703 (0.7%)\n\n### ML Model Sentiment Analysis\n\n**Distribution:**\n- Positive: 6 (30.0%)\n- Neutral: 12 (60.0%)\n- Negative: 2 (10.0%)\n\n**Model Confidence (Average):**\n- P(Positive): 31.7%\n- P(Neutral): 59.2%\n- P(Negative): 9.1%\n\n**Interpretation**: Mixed audience sentiment with balanced reactions.\n\n---\n\n### LLM Qualitative Analysis\n\nKEY POINT:\nThe overall reaction to the video is overwhelmingly positive, with viewers excited to see Kaden return and nostalgic for the content from the past.\n\nDETAILED SUMMARY:\nThe majority opinion is clear: viewers are thrilled to see Kaden back, with comments like \"KADEN IS BACK??!!\" and \"We love to see Kaden back\" showcasing their enthusiasm. Many viewers are also appreciative of the content creator's efforts, with comments like \"love when kaden helps out small creators like flamingo <3\" indicating a sense of gratitude. Some viewers express nostalgia for the old days, with comments like \"I miss all the old collabs Albert would do\" and \"WE NEED DANI, JANDEL, KADEN, DENIS, TEMPRIST, MILES BACK LIKE THE OLDS DAYYSS\" highlighting the longing for past collaborations. However, a minority of viewers express sadness and disappointment, particularly regarding the game's shutdown, with comments like \"5:21 It's unfortunate to see that it basically got abandoned after the game was shut down.\" There is no notable code-switching in the comments.\n\nSENTIMENT BREAKDOWN:\nPositive: 85%  Negative: 10%  Neutral: 5%\n\n---\n\n## Top Comments\n\n1. **@@ilikecats382** (2283 likes): Yes we love to see Kaden back...\n\n2. **@@ItsjustmeKayla** (637 likes): love when kaden helps out small creators like flamingo <3...\n\n3. **@@zhyyblox** (322 likes): WE NEED DANI, JANDEL, KADEN, DENIS, TEMPRIST, MILES BACK LIKE THE OLDS DAYYSS...\n\n4. **@@LucieeMotlová** (568 likes): 5:21  It's unfortunate to see that it basically got abandoned after the game was shut down....\n\n5. **@@Loveforsara** (697 likes): 0:10 KADEN IS BACK??!!! OMG OMGG...\n\n---\n\n## Technical Notes\n\n- This report was automatically generated using LLM-based multilingual analysis\n- Token Efficiency: Dynamic token allocation based on input length\n- Quality Gate: Automatic validation and regeneration for quality assurance\n- Input content processed in original language(s) without translation layer\n- Output language fixed to English for consistency\n\n---\n\n*Generated by YouTube Report Generator - Phase 2 Full Pipeline v2.3*\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "REPORT 3/3\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# YouTube Video Report\n\n**Generated**: 2025-12-13 01:04:00\n**Model**: meta-llama/Llama-3.1-8B-Instruct\n**Pipeline Version**: 2.3\n\n---\n\n## Video Information\n\n- **Title**: 劇場版『チェンソーマン レゼ篇』オープニングムービー 　主題歌：米津玄師「IRIS OUT」“Chainsaw Man – The Movie: Reze Arc” – Opening Movie\n- **Channel**: Kenshi Yonezu  米津玄師\n- **Category (ML Model)**: Entertainment \n- **Category (LLM Validated)**: Entertainment\n- **Published**: 2025-10-07T10:59:56Z\n- **Duration**: PT2M31S seconds\n- **Video ID**: `ux3QETpLcPs`\n- **URL**: https://www.youtube.com/watch?v=ux3QETpLcPs\n\n### Detected Languages\n\n- **Video content**: Japanese\n- **Comments**: Japanese (19), English (1)\n- **Report language**: English\n\n---\n\n## Engagement Metrics\n\n| Metric | Value |\n|--------|-------|\n| Views | 9,096,175 |\n| Likes | 416,328 |\n| Comments | 14,691 |\n| Engagement Rate | 4.74% |\n| Like Rate | 4.58% |\n| Comment Rate | 0.16% |\n\n---\n\n## Video Summary\n\nKEY POINT:\nThe video is the opening movie for the Japanese anime film \"Chainsaw Man – The Movie: Reze Arc,\" featuring the theme song \"IRIS OUT\" by Kenshi Yonezu.\n\nDETAILED SUMMARY:\nThe video introduces the upcoming anime film, which is an adaptation of the popular manga series \"Chainsaw Man\" by Tatsuki Fujimoto. The story follows Denji, a young devil hunter, who meets a girl named Reze and becomes involved in a world of blood battles between humans and devils. The film promises to bring an extravagant and thrilling experience, with a blend of love, desire, and action. The video also highlights the voice cast and the production team behind the film, including MAPPA, the studio behind other notable anime series. The trailer showcases the movie's action-packed sequences and hints at the complex relationships between the characters.\n\n---\n\n## Audience Reaction Summary\n\n**Comments Analyzed**: 20 / 14691 (0.1%)\n\n### ML Model Sentiment Analysis\n\n**Distribution:**\n- Positive: 15 (75.0%)\n- Neutral: 4 (20.0%)\n- Negative: 1 (5.0%)\n\n**Model Confidence (Average):**\n- P(Positive): 64.5%\n- P(Neutral): 30.5%\n- P(Negative): 5.1%\n\n**Interpretation**: Highly positive audience reception!\n\n---\n\n### LLM Qualitative Analysis\n\nKEY POINT:\nViewers are overwhelmingly enthusiastic about the opening sequence of the movie, praising its emotional impact, beautiful animation, and the way it sets the tone for the story.\n\nDETAILED SUMMARY:\nThe majority of viewers (around 90%) are extremely positive about the opening sequence, with many commenting on its emotional impact and how it effectively captures the essence of the story. They appreciate how the sequence seamlessly integrates the opening and ending themes, making the whole experience feel cohesive and engaging. Many viewers are also fond of the character interactions, particularly the relationship between Akira, Denji, and Power, and the way the animation brings out the emotions and personalities of each character. Some viewers (around 5%) have noticed the attention to detail in the animation, such as the way the characters' expressions and movements are designed to be realistic and endearing. A few viewers (around 5%) also appreciate the use of different camera angles and perspectives, such as the bird's-eye view shots.\n\nSENTIMENT BREAKDOWN:\nPositive: 90%  Negative: 5%  Neutral: 5%\n\n---\n\n## Top Comments\n\n1. **@@YAMIGMISAMA** (29539 likes): 映画館でこのムービーと一緒に大音量で曲が流れた時の幸福感エグかった...\n\n2. **@@summer-xf2zo** (21043 likes): レゼ編はマジで、OPで「始まるぞ！！」って感じて、EDで「終わった......。」って感じられる最高の作品。...\n\n3. **@@syu-rikka7965** (4349 likes): OPとして独立してるんじゃなくて、その中で確実に話が進んでるし、登場人物全員にしっかりフォーカスを置いてたりしてるのがもう完全に完成しきってるんだって、もう感動です。...\n\n4. **@@harucha6280** (736 likes): ワガママな妹と、世話を焼いてる兄2人みたいな関係性の早川家マジで好き...\n\n5. **@@漢梅トレイン** (18128 likes): 1:05 ここのポチタダンスまじで可愛すぎる...\n\n---\n\n## Technical Notes\n\n- This report was automatically generated using LLM-based multilingual analysis\n- Token Efficiency: Dynamic token allocation based on input length\n- Quality Gate: Automatic validation and regeneration for quality assurance\n- Input content processed in original language(s) without translation layer\n- Output language fixed to English for consistency\n\n---\n\n*Generated by YouTube Report Generator - Phase 2 Full Pipeline v2.3*\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Display all reports (optional)\n",
        "for i, report in enumerate(reports, 1):\n",
        "    print(f\"\\n{'=' * 80}\")\n",
        "    print(f\"REPORT {i}/{len(reports)}\")\n",
        "    print(\"=\" * 80)\n",
        "    display(Markdown(report))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "base_dir = Path(\"/content/drive/MyDrive/25_sch/ML/reports_batch\")\n",
        "base_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def extract_video_id(report_md: str) -> str:\n",
        "    m = re.search(r\"Video ID.*?`([A-Za-z0-9_\\-]+)`\", report_md)\n",
        "    return m.group(1) if m else \"unknown\"\n",
        "\n",
        "def extract_title(report_md: str) -> str:\n",
        "    # looks for: - **Title**: ...\n",
        "    m = re.search(r\"- \\*\\*Title\\*\\*: (.+)\", report_md)\n",
        "    if not m:\n",
        "        return \"untitled\"\n",
        "    title = m.group(1).strip()\n",
        "    title = re.sub(r\"[^\\w\\-]+\", \"_\", title)\n",
        "    title = re.sub(r\"_+\", \"_\", title).strip(\"_\")\n",
        "    return title[:50] or \"untitled\"\n",
        "\n",
        "def save_all_reports(reports, prefix: str = \"youtube_report\"):\n",
        "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    for i, report_md in enumerate(reports, 1):\n",
        "        video_id = extract_video_id(report_md)\n",
        "        title_slug = extract_title(report_md)\n",
        "        filename = f\"{prefix}_{i:02d}_{ts}_{video_id}_{title_slug}.md\"\n",
        "        path = base_dir / filename\n",
        "\n",
        "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(report_md)\n",
        "\n",
        "        print(f\"Saved REPORT {i}/{len(reports)} → {path}\")\n",
        "\n",
        "# example\n",
        "save_all_reports(reports, prefix=\"yt_report\")"
      ],
      "metadata": {
        "id": "aY5xpaIbWRpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "youtube_api_section"
      },
      "source": [
        "## 4. YouTube API Integration (On-The-Fly Application)\n",
        "\n",
        "Generate reports directly from YouTube URLs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "youtube_api_client",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2319f5d3-cb26-42d3-a4c8-eadd78342ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YouTube API integration loaded\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import isodate\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "\n",
        "\n",
        "class YouTubeAPIClient:\n",
        "    \"\"\"YouTube API client for fetching video data\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str):\n",
        "        self.youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "    def extract_video_id(self, url: str) -> Optional[str]:\n",
        "        \"\"\"Extract video ID from YouTube URL\"\"\"\n",
        "        patterns = [\n",
        "            r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*',\n",
        "            r'(?:embed\\/|v\\/|youtu.be\\/)([0-9A-Za-z_-]{11})'\n",
        "        ]\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, url)\n",
        "            if match:\n",
        "                return match.group(1)\n",
        "        return None\n",
        "\n",
        "    def get_video_info(self, video_id: str) -> Optional[Dict]:\n",
        "        \"\"\"Fetch video information\"\"\"\n",
        "        try:\n",
        "            request = self.youtube.videos().list(\n",
        "                part='snippet,statistics,contentDetails',\n",
        "                id=video_id\n",
        "            )\n",
        "            response = request.execute()\n",
        "\n",
        "            if not response['items']:\n",
        "                return None\n",
        "\n",
        "            item = response['items'][0]\n",
        "            snippet = item['snippet']\n",
        "            statistics = item['statistics']\n",
        "            content_details = item['contentDetails']\n",
        "\n",
        "            duration = isodate.parse_duration(content_details['duration']).total_seconds()\n",
        "\n",
        "            return {\n",
        "                'video_info': {\n",
        "                    'video_id': video_id,\n",
        "                    'title': snippet['title'],\n",
        "                    'description': snippet['description'],\n",
        "                    'channel_title': snippet['channelTitle'],\n",
        "                    'published_at': snippet['publishedAt'],\n",
        "                    'category_id': snippet['categoryId'],\n",
        "                    'view_count': int(statistics.get('viewCount', 0)),\n",
        "                    'like_count': int(statistics.get('likeCount', 0)),\n",
        "                    'comment_count': int(statistics.get('commentCount', 0)),\n",
        "                    'duration': int(duration)\n",
        "                },\n",
        "                'comments': []\n",
        "            }\n",
        "\n",
        "        except HttpError as e:\n",
        "            print(f\"API Error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_comments(self, video_id: str, max_results: int = 100) -> List[Dict]:\n",
        "        \"\"\"Fetch video comments\"\"\"\n",
        "        try:\n",
        "            comments = []\n",
        "            request = self.youtube.commentThreads().list(\n",
        "                part='snippet',\n",
        "                videoId=video_id,\n",
        "                maxResults=min(max_results, 100),\n",
        "                order='relevance'\n",
        "            )\n",
        "\n",
        "            while request and len(comments) < max_results:\n",
        "                response = request.execute()\n",
        "\n",
        "                for item in response['items']:\n",
        "                    comment = item['snippet']['topLevelComment']['snippet']\n",
        "                    comments.append({\n",
        "                        'author': comment['authorDisplayName'],\n",
        "                        'text': comment['textDisplay'],\n",
        "                        'like_count': comment['likeCount'],\n",
        "                        'published_at': comment['publishedAt']\n",
        "                    })\n",
        "\n",
        "                if 'nextPageToken' in response and len(comments) < max_results:\n",
        "                    request = self.youtube.commentThreads().list(\n",
        "                        part='snippet',\n",
        "                        videoId=video_id,\n",
        "                        pageToken=response['nextPageToken'],\n",
        "                        maxResults=min(max_results - len(comments), 100),\n",
        "                        order='relevance'\n",
        "                    )\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "            return comments\n",
        "\n",
        "        except HttpError as e:\n",
        "            print(f\"Comments API Error: {e}\")\n",
        "            return []\n",
        "\n",
        "\n",
        "def generate_report_from_url(video_url: str, api_key: str,\n",
        "                              config: Optional['PipelineConfig'] = None,\n",
        "                              model_manager: Optional['ModelManager'] = None,\n",
        "                              force_reload: bool = False) -> str:\n",
        "    \"\"\"\n",
        "    Generate report from YouTube URL.\n",
        "\n",
        "    Args:\n",
        "        video_url: YouTube video URL\n",
        "        api_key: YouTube API key\n",
        "        config: Pipeline configuration (None for default)\n",
        "        model_manager: Existing model manager (None to auto-create)\n",
        "        force_reload: Force reload model if True\n",
        "\n",
        "    Returns:\n",
        "        Generated report string\n",
        "    \"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"GENERATING REPORT FROM URL\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    if config is None:\n",
        "        config = PipelineConfig()\n",
        "\n",
        "    api_client = YouTubeAPIClient(api_key)\n",
        "\n",
        "    # Extract video ID\n",
        "    video_id = api_client.extract_video_id(video_url)\n",
        "    if not video_id:\n",
        "        raise ValueError(\"Invalid YouTube URL\")\n",
        "\n",
        "    print(f\"Video ID: {video_id}\")\n",
        "\n",
        "    # Fetch video info\n",
        "    print(\"  Fetching video information...\")\n",
        "    video_data = api_client.get_video_info(video_id)\n",
        "    if not video_data:\n",
        "        raise ValueError(\"Could not fetch video information\")\n",
        "\n",
        "    print(f\"  Video: {video_data['video_info']['title'][:50]}...\")\n",
        "\n",
        "    # Fetch comments\n",
        "    print(f\"  Fetching comments (max: {config.max_comments_to_process})...\")\n",
        "    comments = api_client.get_comments(video_id, config.max_comments_to_process)\n",
        "    video_data['comments'] = comments\n",
        "    print(f\"  Collected {len(comments)} comments\\n\")\n",
        "\n",
        "    # Get or create model manager\n",
        "    if model_manager is None:\n",
        "        model_manager = get_or_create_model_manager(config, force_reload)\n",
        "    else:\n",
        "        print(\"Using provided model manager\\n\")\n",
        "\n",
        "    # Generate report\n",
        "    report_gen = ReportGenerator(config, model_manager)\n",
        "    report = report_gen.generate_full_report(video_data)\n",
        "\n",
        "    print(f\"\\n{'=' * 80}\")\n",
        "    print(\"REPORT COMPLETED\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Print efficiency reports\n",
        "    print(model_manager.get_token_efficiency_report())\n",
        "    print(report_gen.quality_gate.get_quality_report())\n",
        "\n",
        "    return report\n",
        "\n",
        "\n",
        "print(\"YouTube API integration loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "youtube_api_usage"
      },
      "source": [
        "### 4.1 Generate Report from URL\n",
        "\n",
        "Set your YouTube API key and run to generate a report from any YouTube video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "youtube_api_example",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ebfdb33-a615-4408-89dd-7a1679aa29df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "GENERATING REPORT FROM URL\n",
            "================================================================================\n",
            "Video ID: dQw4w9WgXcQ\n",
            "  Fetching video information...\n",
            "  Video: Rick Astley - Never Gonna Give You Up (Official Vi...\n",
            "  Fetching comments (max: 100)...\n",
            "  Collected 100 comments\n",
            "\n",
            "Reusing existing model: meta-llama/Llama-3.1-8B-Instruct\n",
            "\n",
            "Processing: Rick Astley - Never Gonna Give You Up (Official Vi...\n",
            "  Generating video summary...\n",
            "    [Input language: English]\n",
            "      [Input: 675 tokens, Max output: 384]\n",
            "      [Output: 193 tokens]\n",
            "    [Output language: English]\n",
            "\n",
            "  Analyzing sentiment with ML model...\n",
            "    ML Sentiment: Pos 17.0% | Neu 59.0% | Neg 24.0%\n",
            "  Generating reaction summary...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [Comment languages: {'English': 96, 'Dutch': 2, 'Cy': 1, 'Afrikaans': 1}]\n",
            "      [Input: 2463 tokens, Max output: 512]\n",
            "      [Output: 236 tokens]\n",
            "    [Output language: English]\n",
            "  Calculating metrics...\n",
            "  Formatting report...\n",
            "  ML Model Prediction: Music\n",
            "  Validating category with LLM...\n",
            "      [Input: 343 tokens, Max output: 256]\n",
            "      [Output: 6 tokens]\n",
            "    Category 10 validated\n",
            "  LLM Validated: Music\n",
            "  Done!\n",
            "\n",
            "================================================================================\n",
            "REPORT COMPLETED\n",
            "================================================================================\n",
            "\n",
            "╔══════════════════════════════════════════════════════════╗\n",
            "║              TOKEN EFFICIENCY REPORT                     ║\n",
            "╠══════════════════════════════════════════════════════════╣\n",
            "║ Total Calls:               12                         ║\n",
            "║ Total Input Tokens:      9852                         ║\n",
            "║ Total Output Tokens:     1633                         ║\n",
            "║ Tokens Saved:            2176                         ║\n",
            "║ Avg Tokens/Call:        957.1                         ║\n",
            "║ Efficiency Gain:        18.9%                         ║\n",
            "╚══════════════════════════════════════════════════════════╝\n",
            "\n",
            "\n",
            "╔══════════════════════════════════════════════════════════╗\n",
            "║              QUALITY GATE REPORT                         ║\n",
            "╠══════════════════════════════════════════════════════════╣\n",
            "║ Total Validations:          2                         ║\n",
            "║ Passed First Time:          2 (100.0%)              ║\n",
            "║ Regenerated:                0 (  0.0%)              ║\n",
            "║ Failed Final:               0                         ║\n",
            "╚══════════════════════════════════════════════════════════╝\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# YouTube Video Report\n\n**Generated**: 2025-12-13 01:06:34\n**Model**: meta-llama/Llama-3.1-8B-Instruct\n**Pipeline Version**: 2.3\n\n---\n\n## Video Information\n\n- **Title**: Rick Astley - Never Gonna Give You Up (Official Video) (4K Remaster)\n- **Channel**: Rick Astley\n- **Category (ML Model)**: Music \n- **Category (LLM Validated)**: Music\n- **Published**: 2009-10-25T06:57:33Z\n- **Duration**: 214 seconds\n- **Video ID**: `dQw4w9WgXcQ`\n- **URL**: https://www.youtube.com/watch?v=dQw4w9WgXcQ\n\n### Detected Languages\n\n- **Video content**: English\n- **Comments**: English (96), Dutch (2), Cy (1), Afrikaans (1)\n- **Report language**: English\n\n---\n\n## Engagement Metrics\n\n| Metric | Value |\n|--------|-------|\n| Views | 1,721,716,692 |\n| Likes | 18,675,159 |\n| Comments | 2,408,242 |\n| Engagement Rate | 1.22% |\n| Like Rate | 1.08% |\n| Comment Rate | 0.14% |\n\n---\n\n## Video Summary\n\nKEY POINT:\nThis video is the official 4K remastered version of Rick Astley's iconic 1987 hit single \"Never Gonna Give You Up,\" which was a global chart-topper and a defining song of the era.\n\nDETAILED SUMMARY:\nThe video features the song's memorable lyrics and Rick Astley's catchy vocals, showcasing the timeless romance and devotion theme. Released in July 1987, \"Never Gonna Give You Up\" was a massive success, topping the charts in 25 countries and winning the Brit Award for Best single in 1988. The song was written and produced by the legendary songwriting and production trio Stock Aitken and Waterman for Rick Astley's debut album \"Whenever You Need Somebody,\" which went on to sell over 15 million copies worldwide. The music video, directed by Simon West, has become a classic of the era and has surpassed 1 billion views on YouTube since its upload.\n\n---\n\n## Audience Reaction Summary\n\n**Comments Analyzed**: 100 / 2408242 (0.0%)\n\n### ML Model Sentiment Analysis\n\n**Distribution:**\n- Positive: 17 (17.0%)\n- Neutral: 59 (59.0%)\n- Negative: 24 (24.0%)\n\n**Model Confidence (Average):**\n- P(Positive): 17.7%\n- P(Neutral): 57.0%\n- P(Negative): 25.3%\n\n**Interpretation**: Mixed audience sentiment with balanced reactions.\n\n---\n\n### LLM Qualitative Analysis\n\nKEY POINT:\nThe audience reaction to the YouTube video is overwhelmingly positive, with viewers expressing their love for the song \"Never Gonna Give You Up\" by Rick Astley, as well as their amusement and nostalgia for the \"Rickrolling\" meme.\n\nDETAILED SUMMARY:\nThe majority of viewers are in high spirits, sharing their experiences of being \"rickrolled\" and joking about the meme's persistence and widespread impact. Many commenters express their admiration for the song, with some even suggesting it as the national anthem of the internet. Some viewers share humorous anecdotes about getting rickrolled in various situations, such as school, work, or even by AI-generated content. Notable minority views include a few commenters who are less enthusiastic, either because they didn't understand the joke or because they felt tricked. A small number of commenters also express a mix of nostalgia and melancholy, reminiscing about the good old days of the internet. Language patterns show a mix of informal and playful language, with some commenters using emojis and humorously exaggerated expressions.\n\nSENTIMENT BREAKDOWN:\nPositive: 85%  Negative: 5%  Neutral: 10%\n\n---\n\n## Top Comments\n\n1. **@@YouTube** (146373 likes): can confirm: he never gave us up...\n\n2. **@@JetpackGamer456** (417474 likes): Ok let’s be honest here<br>Rick rolling is the one meme that will never die...\n\n3. **@@SilentMemer** (124554 likes): Nobody can fool me anymore with this, I now remember every letter and number of the link...\n\n4. **@@CinematicCaptures** (353478 likes): I didn&#39;t get rickrolled today, I just really enjoy this song...\n\n5. **@@MrC37** (5 likes): I don&#39;t care, this song SLAPS...\n\n---\n\n## Technical Notes\n\n- This report was automatically generated using LLM-based multilingual analysis\n- Token Efficiency: Dynamic token allocation based on input length\n- Quality Gate: Automatic validation and regeneration for quality assurance\n- Input content processed in original language(s) without translation layer\n- Output language fixed to English for consistency\n\n---\n\n*Generated by YouTube Report Generator - Phase 2 Full Pipeline v2.3*\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Set your YouTube API key (get from https://console.developers.google.com)\n",
        "YOUR_YOUTUBE_API_KEY = \"[REDACTED]\"\n",
        "\n",
        "# Example usage\n",
        "report = generate_report_from_url(\n",
        "    \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\",\n",
        "    YOUR_YOUTUBE_API_KEY\n",
        ")\n",
        "display(Markdown(report))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "# Base directory for saving reports\n",
        "base_dir = Path(\"/content/drive/MyDrive/25_sch/ML/reports\")\n",
        "base_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def slugify(text: str, max_len: int = 50) -> str:\n",
        "    text = re.sub(r\"[^\\w\\-]+\", \"_\", text)\n",
        "    text = re.sub(r\"_+\", \"_\", text).strip(\"_\")\n",
        "    return text[:max_len] or \"report\"\n",
        "\n",
        "def extract_video_id(report_md: str) -> str:\n",
        "    # looks for a line like: - **Video ID**: `EmeW6li6bbo`\n",
        "    m = re.search(r\"Video ID.*?`([A-Za-z0-9_\\-]+)`\", report_md)\n",
        "    return m.group(1) if m else \"unknown\"\n",
        "\n",
        "def save_single_report(report_md: str, prefix: str = \"report\"):\n",
        "    video_id = extract_video_id(report_md)\n",
        "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"{prefix}_{ts}_{video_id}.md\"\n",
        "    path = base_dir / filename\n",
        "\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(report_md)\n",
        "\n",
        "    print(f\"Saved report to: {path}\")\n",
        "\n",
        "# example\n",
        "save_single_report(report, prefix=\"youtube_report\")\n"
      ],
      "metadata": {
        "id": "gndaK7S-WYhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b1RdGyJNGi-"
      },
      "source": [
        "## 5. Cleanup (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x52qvKfINGi-"
      },
      "outputs": [],
      "source": [
        "# Release model from memory when done\n",
        "# cleanup_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary_section"
      },
      "source": [
        "## 6. Pipeline Summary\n",
        "\n",
        "### Features\n",
        "\n",
        "**Token Efficiency:**\n",
        "- Dynamic token allocation based on input length\n",
        "- Three modes: conservative, adaptive (default), aggressive\n",
        "- Typical 20-40% token savings\n",
        "\n",
        "**Quality Gate:**\n",
        "- Automatic validation of generated summaries\n",
        "- 5 quality checks: length, diversity, relevance, structure, error detection\n",
        "- Auto-regeneration with conservative temperature on failure\n",
        "\n",
        "**Model Integration:**\n",
        "- Category prediction (BERT + TF-IDF)\n",
        "- LLM category validation\n",
        "- Sentiment analysis (BERT)\n",
        "\n",
        "**Report Content:**\n",
        "- Video information and metadata\n",
        "- Engagement metrics\n",
        "- Two-part summary (KEY POINT + DETAILED SUMMARY)\n",
        "- ML sentiment analysis results\n",
        "- LLM qualitative analysis\n",
        "- Top comments\n",
        "\n",
        "### Configuration Reference\n",
        "\n",
        "```python\n",
        "# Token efficiency\n",
        "config.enable_dynamic_tokens = True\n",
        "config.token_efficiency_mode = \"adaptive\"  # conservative/adaptive/aggressive\n",
        "\n",
        "# Quality gate\n",
        "config.enable_quality_gate = True\n",
        "config.min_summary_length = 100\n",
        "config.min_keyword_diversity = 10\n",
        "config.max_regeneration_attempts = 2\n",
        "\n",
        "# Model integration\n",
        "config.use_category_model = True\n",
        "config.use_sentiment_model = True\n",
        "config.enable_llm_category_correction = True\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a5865f2c30954078bd5f15b8991cf28c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ce5177ff25742569d975cf55b6d5071",
              "IPY_MODEL_24a475a8d9b24f5b82c362b1f30be614",
              "IPY_MODEL_322fcb48e549422b8cb28be0be829cc1"
            ],
            "layout": "IPY_MODEL_f6b7d789e5f34ab981d21076d361b7ed"
          }
        },
        "1ce5177ff25742569d975cf55b6d5071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bed3025cc54d432b849622b044e6f610",
            "placeholder": "​",
            "style": "IPY_MODEL_4705922ef99d43168c314e7b7971d455",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "24a475a8d9b24f5b82c362b1f30be614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aabdbab6c4c40bc8c18586d5af042a5",
            "max": 55351,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3beebc4de5f41bfbb6a3dc674c373a0",
            "value": 55351
          }
        },
        "322fcb48e549422b8cb28be0be829cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_469be542154f40afa4a97a979e6a43b2",
            "placeholder": "​",
            "style": "IPY_MODEL_723345f5bd094741b1f5f08d4172d5a9",
            "value": " 55.4k/55.4k [00:00&lt;00:00, 6.30MB/s]"
          }
        },
        "f6b7d789e5f34ab981d21076d361b7ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bed3025cc54d432b849622b044e6f610": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4705922ef99d43168c314e7b7971d455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8aabdbab6c4c40bc8c18586d5af042a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3beebc4de5f41bfbb6a3dc674c373a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "469be542154f40afa4a97a979e6a43b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "723345f5bd094741b1f5f08d4172d5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2ff6bbf97c447eeb47d0daafa48f310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4fbd5db1119146d09d4c376ade67db93",
              "IPY_MODEL_22a2036531024bb5ab237ea0f3028d98",
              "IPY_MODEL_d0d58d874d064bc18a91f64fbe9dc0f3"
            ],
            "layout": "IPY_MODEL_ef44f0ff40824373826997f853eddd0d"
          }
        },
        "4fbd5db1119146d09d4c376ade67db93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acdf772a0a0f468cb698c9131a79303e",
            "placeholder": "​",
            "style": "IPY_MODEL_1b35c8f5170c4988a065097f5d9d51aa",
            "value": "tokenizer.json: 100%"
          }
        },
        "22a2036531024bb5ab237ea0f3028d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96831706d99c4f5faf8c917790bac45e",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa59a29b453a40fdbbda523266df609c",
            "value": 9085657
          }
        },
        "d0d58d874d064bc18a91f64fbe9dc0f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81579cd60f934881bf4f6057cf5af1ef",
            "placeholder": "​",
            "style": "IPY_MODEL_4770c9609f314868806c8d7d8ed2d403",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 27.0MB/s]"
          }
        },
        "ef44f0ff40824373826997f853eddd0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acdf772a0a0f468cb698c9131a79303e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b35c8f5170c4988a065097f5d9d51aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96831706d99c4f5faf8c917790bac45e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa59a29b453a40fdbbda523266df609c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81579cd60f934881bf4f6057cf5af1ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4770c9609f314868806c8d7d8ed2d403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b0e4b62ec6e4546861b768f4f45c0bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ea9c48017c2424abf15ad9a1c5f717e",
              "IPY_MODEL_5e271df14c0c4535ba00ad69343d58b0",
              "IPY_MODEL_bc6137268db24fb694f78dbb5b76bd70"
            ],
            "layout": "IPY_MODEL_939cb135db9e4b6597d79adc84aacd35"
          }
        },
        "6ea9c48017c2424abf15ad9a1c5f717e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ec0aae9ff5044b78f9ed96d1e32cc4e",
            "placeholder": "​",
            "style": "IPY_MODEL_f23b8c5b00b44c19afde0e62ff98dc84",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "5e271df14c0c4535ba00ad69343d58b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca0315a0811141278fde25c28184de89",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6f01261beec4919b503a11b71edfb4d",
            "value": 296
          }
        },
        "bc6137268db24fb694f78dbb5b76bd70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4237a9dc610f4dbe845588834b97ed51",
            "placeholder": "​",
            "style": "IPY_MODEL_47599aa53f1443bfa9fd5c8d53ccaae1",
            "value": " 296/296 [00:00&lt;00:00, 43.1kB/s]"
          }
        },
        "939cb135db9e4b6597d79adc84aacd35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ec0aae9ff5044b78f9ed96d1e32cc4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f23b8c5b00b44c19afde0e62ff98dc84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca0315a0811141278fde25c28184de89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6f01261beec4919b503a11b71edfb4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4237a9dc610f4dbe845588834b97ed51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47599aa53f1443bfa9fd5c8d53ccaae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c9ef75a07c044178bf41dc86c4f5f51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1efa60f5c5ce4384b48b3f0cdec07812",
              "IPY_MODEL_8b0be080967847bd9db86d686b819820",
              "IPY_MODEL_1a2d276c098c43aa83045580213c9480"
            ],
            "layout": "IPY_MODEL_8bc97a2b5f8c471094596a1293ae5493"
          }
        },
        "1efa60f5c5ce4384b48b3f0cdec07812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82398331ef09463f99efb3668935c3f6",
            "placeholder": "​",
            "style": "IPY_MODEL_5ad59aef7d044d3ea8f0929c74179cf3",
            "value": "config.json: 100%"
          }
        },
        "8b0be080967847bd9db86d686b819820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86ae301a27a34969bad1ee300e195f7e",
            "max": 855,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2488c6d12094c078a6e427a604e435f",
            "value": 855
          }
        },
        "1a2d276c098c43aa83045580213c9480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f8982a16a194a17b7192bdbf8cfecc6",
            "placeholder": "​",
            "style": "IPY_MODEL_75c1db22131d47d1a3a52a4cc0d3adb0",
            "value": " 855/855 [00:00&lt;00:00, 124kB/s]"
          }
        },
        "8bc97a2b5f8c471094596a1293ae5493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82398331ef09463f99efb3668935c3f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ad59aef7d044d3ea8f0929c74179cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86ae301a27a34969bad1ee300e195f7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2488c6d12094c078a6e427a604e435f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f8982a16a194a17b7192bdbf8cfecc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c1db22131d47d1a3a52a4cc0d3adb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6be7b1198bcf4177a9bf3a626a8ac0b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34f2e3fb2710444ab433ee97a2786f76",
              "IPY_MODEL_37fc2f35cb594220b56ab657cde67dad",
              "IPY_MODEL_aa1ddd9f25fc45d1b71ad74e6b622808"
            ],
            "layout": "IPY_MODEL_9264099b911f498d8db7cbc310c58000"
          }
        },
        "34f2e3fb2710444ab433ee97a2786f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7b99df4aac24e3dbf8395aed0ca8da7",
            "placeholder": "​",
            "style": "IPY_MODEL_951dda4406884de98b2f8fcee0935b31",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "37fc2f35cb594220b56ab657cde67dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a5cfa2326324ee2a2e3458957d909ab",
            "max": 23950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b0c0aa72ca74546bc106b987f391cb0",
            "value": 23950
          }
        },
        "aa1ddd9f25fc45d1b71ad74e6b622808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d694044effd44de960ccfcd9a291d15",
            "placeholder": "​",
            "style": "IPY_MODEL_da48314e1c644fc9850c21b4b11578e3",
            "value": " 23.9k/23.9k [00:00&lt;00:00, 2.85MB/s]"
          }
        },
        "9264099b911f498d8db7cbc310c58000": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7b99df4aac24e3dbf8395aed0ca8da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "951dda4406884de98b2f8fcee0935b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a5cfa2326324ee2a2e3458957d909ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b0c0aa72ca74546bc106b987f391cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d694044effd44de960ccfcd9a291d15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da48314e1c644fc9850c21b4b11578e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3656fc763cf24d039830e49487c55df8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52abae1a1e204489a8438ea24274ae3c",
              "IPY_MODEL_52de9d66e39b475fa163e61ea7cb4150",
              "IPY_MODEL_0a69de2f4dd74076b6baa9fa56e78a1f"
            ],
            "layout": "IPY_MODEL_c0831b7820344eff8165a7ca35f8f85c"
          }
        },
        "52abae1a1e204489a8438ea24274ae3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91d40f62e5bd417eb62f3798e6ad0d26",
            "placeholder": "​",
            "style": "IPY_MODEL_e1bb5ec2d8454f9bbd2482acd136b953",
            "value": "Fetching 4 files: 100%"
          }
        },
        "52de9d66e39b475fa163e61ea7cb4150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_656fb74c226a4a968b2a46670b80b082",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ea582815f4b430ab9350f95dcdded05",
            "value": 4
          }
        },
        "0a69de2f4dd74076b6baa9fa56e78a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5486d91c97424bd58f424b2dc1a5db9d",
            "placeholder": "​",
            "style": "IPY_MODEL_53814e2fe7ad4a55a5ea5177870231f6",
            "value": " 4/4 [00:54&lt;00:00, 22.96s/it]"
          }
        },
        "c0831b7820344eff8165a7ca35f8f85c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d40f62e5bd417eb62f3798e6ad0d26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1bb5ec2d8454f9bbd2482acd136b953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "656fb74c226a4a968b2a46670b80b082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ea582815f4b430ab9350f95dcdded05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5486d91c97424bd58f424b2dc1a5db9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53814e2fe7ad4a55a5ea5177870231f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e48c64ca72d54c36b793446859d34beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddb6d7c0bea542a38725261b76e60a02",
              "IPY_MODEL_a662c1282836449c854593afe53cacfb",
              "IPY_MODEL_597ae11b55274613a6d8e00a8605c17a"
            ],
            "layout": "IPY_MODEL_6d6e4cf882294ed3a5093e435eee9a99"
          }
        },
        "ddb6d7c0bea542a38725261b76e60a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2492a190798246b5a47a1e392f4cfdce",
            "placeholder": "​",
            "style": "IPY_MODEL_970c70d162184a93a499d5cc41ae3b0c",
            "value": "model-00002-of-00004.safetensors: 100%"
          }
        },
        "a662c1282836449c854593afe53cacfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fe4dae176a74a4798a9f1608324343f",
            "max": 4999802720,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b760a3723ae4044899440cc56db1297",
            "value": 4999802720
          }
        },
        "597ae11b55274613a6d8e00a8605c17a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1d746b3f01a4636b7799b4900366aea",
            "placeholder": "​",
            "style": "IPY_MODEL_0572eef7bc204d79bc76684e004a8446",
            "value": " 5.00G/5.00G [00:53&lt;00:00, 291MB/s]"
          }
        },
        "6d6e4cf882294ed3a5093e435eee9a99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2492a190798246b5a47a1e392f4cfdce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "970c70d162184a93a499d5cc41ae3b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fe4dae176a74a4798a9f1608324343f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b760a3723ae4044899440cc56db1297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1d746b3f01a4636b7799b4900366aea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0572eef7bc204d79bc76684e004a8446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd22bbbfd2c04950963c872d20ebce73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7a6750cb0da4558aa8a6d013bcb88c1",
              "IPY_MODEL_dc49d2d0688148a2b9480ea319947f76",
              "IPY_MODEL_e66ca8214c75478d8c1417c0d8ae0987"
            ],
            "layout": "IPY_MODEL_40699855419643d899013ed8d2fe65de"
          }
        },
        "f7a6750cb0da4558aa8a6d013bcb88c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_344eecd3046348bca04154612a295147",
            "placeholder": "​",
            "style": "IPY_MODEL_2648c9082cfa4e57a597ef184774f423",
            "value": "model-00001-of-00004.safetensors: 100%"
          }
        },
        "dc49d2d0688148a2b9480ea319947f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5a1ac299f2d4156a5aec999220df5af",
            "max": 4976698672,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84ffe3fdb0f34673b68b056b3f390014",
            "value": 4976698672
          }
        },
        "e66ca8214c75478d8c1417c0d8ae0987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ff4b467cba84e4ea05b881536f2162e",
            "placeholder": "​",
            "style": "IPY_MODEL_a8d090a61f6445c8b7b546389d95036b",
            "value": " 4.98G/4.98G [00:50&lt;00:00, 57.2MB/s]"
          }
        },
        "40699855419643d899013ed8d2fe65de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "344eecd3046348bca04154612a295147": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2648c9082cfa4e57a597ef184774f423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5a1ac299f2d4156a5aec999220df5af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84ffe3fdb0f34673b68b056b3f390014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ff4b467cba84e4ea05b881536f2162e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8d090a61f6445c8b7b546389d95036b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09280d1ca3e34a429c4ffc7528b7b49c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a442cfca7c0c4a4293c49f7d48777954",
              "IPY_MODEL_b1d1748a6a61477998b0fce0266678dd",
              "IPY_MODEL_393f57fa721b4646b7993ec84ed0e831"
            ],
            "layout": "IPY_MODEL_9a5f1db731b942d58c9a9c646733e89d"
          }
        },
        "a442cfca7c0c4a4293c49f7d48777954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e558611ff3747e69c7f0abf58463abe",
            "placeholder": "​",
            "style": "IPY_MODEL_49b8cb1d92794f528f903d6521fbe760",
            "value": "model-00004-of-00004.safetensors: 100%"
          }
        },
        "b1d1748a6a61477998b0fce0266678dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21f1d85913d0405cb75d35d851695f39",
            "max": 1168138808,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56c7ba4140d74214ad8b012f9ff6d0c2",
            "value": 1168138808
          }
        },
        "393f57fa721b4646b7993ec84ed0e831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4738d93b7f144375a8be8945552f6966",
            "placeholder": "​",
            "style": "IPY_MODEL_680a3a6352c8456c9dcad790c899fe28",
            "value": " 1.17G/1.17G [00:14&lt;00:00, 54.8MB/s]"
          }
        },
        "9a5f1db731b942d58c9a9c646733e89d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e558611ff3747e69c7f0abf58463abe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49b8cb1d92794f528f903d6521fbe760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21f1d85913d0405cb75d35d851695f39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56c7ba4140d74214ad8b012f9ff6d0c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4738d93b7f144375a8be8945552f6966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "680a3a6352c8456c9dcad790c899fe28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "622a6f8513b44535b32b61df51bf3d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe96feedc2ab4b2598253353b0014b45",
              "IPY_MODEL_529182bd5936473d936493f0af648c15",
              "IPY_MODEL_5fd1fe2e7e46472d974d5961469b4d1a"
            ],
            "layout": "IPY_MODEL_4a3272a7970646e58af4c7e5316d563d"
          }
        },
        "fe96feedc2ab4b2598253353b0014b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef36998b10674150ae5bd4988b95c8af",
            "placeholder": "​",
            "style": "IPY_MODEL_fbda7f9c2e824e949a85503ff2e1df37",
            "value": "model-00003-of-00004.safetensors: 100%"
          }
        },
        "529182bd5936473d936493f0af648c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f84c27d379e5456e9962ae66f1d14fc7",
            "max": 4915916176,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0486cbbf483d4f89bfce7ca8ec3834af",
            "value": 4915916176
          }
        },
        "5fd1fe2e7e46472d974d5961469b4d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a8d088df29f4749807d45e9f317c356",
            "placeholder": "​",
            "style": "IPY_MODEL_bb9396a99ee84ee686abf0a5ee79c7c7",
            "value": " 4.92G/4.92G [00:51&lt;00:00, 133MB/s]"
          }
        },
        "4a3272a7970646e58af4c7e5316d563d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef36998b10674150ae5bd4988b95c8af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbda7f9c2e824e949a85503ff2e1df37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f84c27d379e5456e9962ae66f1d14fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0486cbbf483d4f89bfce7ca8ec3834af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a8d088df29f4749807d45e9f317c356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb9396a99ee84ee686abf0a5ee79c7c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c68e7e8465a54f509960789b752ad634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9138cdc026743d685d03b42ce7f923d",
              "IPY_MODEL_0ad4d020ee134f4fafa0cb606462cd87",
              "IPY_MODEL_7f53ab6a05d04b05a4c1e059cebce311"
            ],
            "layout": "IPY_MODEL_75819672e8dd4a0ea2cc0e4e464743ce"
          }
        },
        "a9138cdc026743d685d03b42ce7f923d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8237dbd217e6453a8d2ab80e203269fc",
            "placeholder": "​",
            "style": "IPY_MODEL_65156932531c452b9088f1b0728434ca",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0ad4d020ee134f4fafa0cb606462cd87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fb342591e684ef1bbc7f26230b153c7",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_acea9fd4d22d4dd887938dee002868e3",
            "value": 4
          }
        },
        "7f53ab6a05d04b05a4c1e059cebce311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a386656758a41e1947d1ce087b237de",
            "placeholder": "​",
            "style": "IPY_MODEL_9b73564e9ae2447ebd88d0a95d8a917e",
            "value": " 4/4 [00:17&lt;00:00,  3.63s/it]"
          }
        },
        "75819672e8dd4a0ea2cc0e4e464743ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8237dbd217e6453a8d2ab80e203269fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65156932531c452b9088f1b0728434ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fb342591e684ef1bbc7f26230b153c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acea9fd4d22d4dd887938dee002868e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a386656758a41e1947d1ce087b237de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b73564e9ae2447ebd88d0a95d8a917e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a99fee6311d41a383a518715022b68a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca70217c6bda42d5abba743321009260",
              "IPY_MODEL_c9d1f7bb31a5452fb3aaa5c784e175ba",
              "IPY_MODEL_ae034a9a579c4fe6b92c3cf27451185d"
            ],
            "layout": "IPY_MODEL_8dadbb4255764d2ba7165ee8c1f7ae8c"
          }
        },
        "ca70217c6bda42d5abba743321009260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98f50ddb2d944afc9bc0691b9827caab",
            "placeholder": "​",
            "style": "IPY_MODEL_339561e0218a44cf8fd5c1a544874b76",
            "value": "generation_config.json: 100%"
          }
        },
        "c9d1f7bb31a5452fb3aaa5c784e175ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7811aed94ba24ea2b8d02e36ccf5aab8",
            "max": 184,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5c56d4f6bbd45479431ee322db80c43",
            "value": 184
          }
        },
        "ae034a9a579c4fe6b92c3cf27451185d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb348ce75b924394919023772e474bfa",
            "placeholder": "​",
            "style": "IPY_MODEL_286ffe532b084afa8db4383fbbf16704",
            "value": " 184/184 [00:00&lt;00:00, 26.2kB/s]"
          }
        },
        "8dadbb4255764d2ba7165ee8c1f7ae8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98f50ddb2d944afc9bc0691b9827caab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "339561e0218a44cf8fd5c1a544874b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7811aed94ba24ea2b8d02e36ccf5aab8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5c56d4f6bbd45479431ee322db80c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb348ce75b924394919023772e474bfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "286ffe532b084afa8db4383fbbf16704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}