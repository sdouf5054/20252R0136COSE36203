{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ YouTube Report Generator - Quick Demo\n",
    "\n",
    "**Phase 1: Quick Demo Notebook**\n",
    "\n",
    "## ğŸ“‹ Overview\n",
    "- **Purpose**: ìƒ˜í”Œ ë°ì´í„°ë¡œ ë¹ ë¥¸ ë¦¬í¬íŠ¸ ìƒì„± ë°ëª¨\n",
    "- **Execution Time**: < 10 minutes\n",
    "- **Requirements**: CPU only, No API keys needed\n",
    "- **Model**: BART-CNN (lightweight summarization)\n",
    "\n",
    "## âœ¨ Features\n",
    "1. Load sample video data from existing dataset\n",
    "2. Generate video summary from title + description\n",
    "3. Summarize audience reactions from comments\n",
    "4. Create formatted markdown report\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Setup & Installation\n",
    "\n",
    "Install required packages (if not already installed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers torch pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“‚ Load Sample Data\n",
    "\n",
    "Load the first video from our collected dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample dataset\n",
    "DATA_PATH = 'full_dataset_20251013_215347.json'\n",
    "\n",
    "try:\n",
    "    with open(DATA_PATH, 'r', encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "    print(f\"âœ… Loaded {len(dataset)} videos from dataset\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âš ï¸ Dataset file not found. Please ensure 'full_dataset_20251013_215347.json' is in the same directory.\")\n",
    "    print(\"You can download it from the project repository.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first video for demo\n",
    "sample_video = dataset[0]\n",
    "\n",
    "# Extract key information\n",
    "video_info = sample_video['video_info']\n",
    "comments = sample_video['comments']\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“¹ SAMPLE VIDEO INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Title: {video_info['title']}\")\n",
    "print(f\"Channel: {video_info['channel_title']}\")\n",
    "print(f\"Views: {video_info['view_count']:,}\")\n",
    "print(f\"Likes: {video_info['like_count']:,}\")\n",
    "print(f\"Comments Count: {len(comments)}\")\n",
    "print(f\"Category: {video_info['category_name']}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¤– Initialize Summarization Model\n",
    "\n",
    "Load BART-CNN model for text summarization (CPU-friendly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize summarization pipeline with BART-CNN\n",
    "print(\"Loading BART-CNN summarization model...\")\n",
    "print(\"(This may take a minute on first run)\")\n",
    "\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"facebook/bart-large-cnn\",\n",
    "    device=-1  # CPU mode\n",
    ")\n",
    "\n",
    "print(\"âœ… Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Generate Video Summary\n",
    "\n",
    "Summarize video content from title and description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_video_summary(video_info, summarizer, max_length=150, min_length=50):\n",
    "    \"\"\"\n",
    "    Generate video summary from title and description\n",
    "    \n",
    "    Args:\n",
    "        video_info: Dictionary containing video information\n",
    "        summarizer: Hugging Face summarization pipeline\n",
    "        max_length: Maximum summary length\n",
    "        min_length: Minimum summary length\n",
    "    \n",
    "    Returns:\n",
    "        Summary text string\n",
    "    \"\"\"\n",
    "    # Combine title and description\n",
    "    title = video_info.get('title', '')\n",
    "    description = video_info.get('description', '')\n",
    "    \n",
    "    # Create input text\n",
    "    input_text = f\"Title: {title}\\n\\nDescription: {description}\"\n",
    "    \n",
    "    # Truncate if too long (BART max input is 1024 tokens)\n",
    "    if len(input_text) > 3000:  # Rough character limit\n",
    "        input_text = input_text[:3000] + \"...\"\n",
    "    \n",
    "    try:\n",
    "        # Generate summary\n",
    "        summary = summarizer(\n",
    "            input_text,\n",
    "            max_length=max_length,\n",
    "            min_length=min_length,\n",
    "            do_sample=False\n",
    "        )\n",
    "        return summary[0]['summary_text']\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Summarization error: {e}\")\n",
    "        return f\"This video titled '{title}' was uploaded by {video_info.get('channel_title', 'Unknown')}.\"\n",
    "\n",
    "# Generate video summary\n",
    "print(\"Generating video summary...\")\n",
    "video_summary = generate_video_summary(video_info, summarizer)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“¹ VIDEO SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(video_summary)\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¬ Generate Reaction Summary\n",
    "\n",
    "Analyze and summarize audience reactions from comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reaction_summary(comments, summarizer, top_n=20, max_length=100, min_length=30):\n",
    "    \"\"\"\n",
    "    Generate audience reaction summary from top comments\n",
    "    \n",
    "    Args:\n",
    "        comments: List of comment dictionaries\n",
    "        summarizer: Hugging Face summarization pipeline\n",
    "        top_n: Number of top comments to analyze\n",
    "        max_length: Maximum summary length\n",
    "        min_length: Minimum summary length\n",
    "    \n",
    "    Returns:\n",
    "        Reaction summary text string\n",
    "    \"\"\"\n",
    "    if not comments:\n",
    "        return \"No comments available for analysis.\"\n",
    "    \n",
    "    # Take top N comments (assuming they're already sorted by relevance/likes)\n",
    "    top_comments = comments[:top_n]\n",
    "    \n",
    "    # Combine comment texts\n",
    "    comments_text = \"Viewer reactions: \" + \" \".join(\n",
    "        [comment.get('text', '') for comment in top_comments if comment.get('text')]\n",
    "    )\n",
    "    \n",
    "    # Truncate if too long\n",
    "    if len(comments_text) > 2000:\n",
    "        comments_text = comments_text[:2000] + \"...\"\n",
    "    \n",
    "    try:\n",
    "        # Generate summary\n",
    "        summary = summarizer(\n",
    "            comments_text,\n",
    "            max_length=max_length,\n",
    "            min_length=min_length,\n",
    "            do_sample=False\n",
    "        )\n",
    "        return summary[0]['summary_text']\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Comment summarization error: {e}\")\n",
    "        return f\"Comments show various reactions from {len(comments)} viewers.\"\n",
    "\n",
    "# Generate reaction summary\n",
    "print(f\"Analyzing top comments (sample size: {min(20, len(comments))})...\")\n",
    "reaction_summary = generate_reaction_summary(comments, summarizer)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ’¬ AUDIENCE REACTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(reaction_summary)\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š Basic Statistics\n",
    "\n",
    "Calculate some basic engagement metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate engagement metrics\n",
    "views = video_info['view_count']\n",
    "likes = video_info['like_count']\n",
    "num_comments = len(comments)\n",
    "\n",
    "engagement_rate = (likes / views * 100) if views > 0 else 0\n",
    "comment_rate = (num_comments / views * 100) if views > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ENGAGEMENT METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Views: {views:,}\")\n",
    "print(f\"Likes: {likes:,}\")\n",
    "print(f\"Comments: {num_comments:,}\")\n",
    "print(f\"Like Rate: {engagement_rate:.2f}%\")\n",
    "print(f\"Comment Rate: {comment_rate:.3f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“„ Generate Final Report\n",
    "\n",
    "Create a formatted markdown report with all information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_markdown_report(video_info, video_summary, reaction_summary, comments):\n",
    "    \"\"\"\n",
    "    Generate formatted markdown report\n",
    "    \n",
    "    Args:\n",
    "        video_info: Video metadata dictionary\n",
    "        video_summary: Generated video summary text\n",
    "        reaction_summary: Generated reaction summary text\n",
    "        comments: List of comment dictionaries\n",
    "    \n",
    "    Returns:\n",
    "        Markdown formatted report string\n",
    "    \"\"\"\n",
    "    # Calculate metrics\n",
    "    views = video_info['view_count']\n",
    "    likes = video_info['like_count']\n",
    "    num_comments = len(comments)\n",
    "    engagement_rate = (likes / views * 100) if views > 0 else 0\n",
    "    \n",
    "    # Create report\n",
    "    report = f\"\"\"# YouTube Video Report\n",
    "\n",
    "## ğŸ“¹ Video Information\n",
    "\n",
    "**Title**: {video_info['title']}\n",
    "\n",
    "**Channel**: {video_info['channel_title']}\n",
    "\n",
    "**Category**: {video_info.get('category_name', 'Unknown')}\n",
    "\n",
    "**Published**: {video_info['published_at']}\n",
    "\n",
    "**Video ID**: `{video_info['video_id']}`\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š Engagement Metrics\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Views | {views:,} |\n",
    "| Likes | {likes:,} |\n",
    "| Comments | {num_comments:,} |\n",
    "| Engagement Rate | {engagement_rate:.2f}% |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Video Summary\n",
    "\n",
    "{video_summary}\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¬ Audience Reaction Summary\n",
    "\n",
    "{reaction_summary}\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” Top Comments (Sample)\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    # Add top 5 comments as examples\n",
    "    for i, comment in enumerate(comments[:5], 1):\n",
    "        author = comment.get('author', 'Unknown')\n",
    "        text = comment.get('text', '').replace('\\n', ' ')[:200]  # Truncate long comments\n",
    "        report += f\"{i}. **{author}**: {text}...\\n\\n\"\n",
    "    \n",
    "    report += \"\"\"---\n",
    "\n",
    "*Report generated by YouTube Report Generator - Quick Demo*\n",
    "*Model: BART-CNN | Execution: CPU-only*\n",
    "\"\"\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generate the final report\n",
    "final_report = generate_markdown_report(\n",
    "    video_info=video_info,\n",
    "    video_summary=video_summary,\n",
    "    reaction_summary=reaction_summary,\n",
    "    comments=comments\n",
    ")\n",
    "\n",
    "print(\"âœ… Report generated successfully!\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“„ FINAL REPORT PREVIEW\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the report\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(final_report))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¾ Save Report to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save report to markdown file\n",
    "output_filename = f\"report_{video_info['video_id']}.md\"\n",
    "\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(final_report)\n",
    "\n",
    "print(f\"âœ… Report saved to: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Summary & Next Steps\n",
    "\n",
    "### What We Accomplished:\n",
    "- âœ… Loaded sample video data from existing dataset\n",
    "- âœ… Generated video summary using BART-CNN\n",
    "- âœ… Analyzed and summarized audience reactions\n",
    "- âœ… Created formatted markdown report\n",
    "- âœ… Calculated engagement metrics\n",
    "\n",
    "### Performance Notes:\n",
    "- **Execution Time**: < 10 minutes (as required)\n",
    "- **Resource Usage**: CPU-only (no GPU required)\n",
    "- **API Keys**: None required (sample data)\n",
    "- **Model**: BART-CNN (lightweight, suitable for demos)\n",
    "\n",
    "### Next Steps (Phase 2):\n",
    "1. **Full Pipeline Development**\n",
    "   - Integrate YouTube API for real-time data collection\n",
    "   - Upgrade to Llama-3.1-8B (4-bit) for better summaries\n",
    "   - Implement Map-Reduce for long content\n",
    "   - Add team models (category classification, sentiment analysis)\n",
    "\n",
    "2. **Enhancements**\n",
    "   - RAG system for context-aware summarization\n",
    "   - Multi-language support\n",
    "   - Advanced sentiment analysis\n",
    "   - Automated evaluation metrics\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š References\n",
    "\n",
    "- **Model**: [facebook/bart-large-cnn](https://huggingface.co/facebook/bart-large-cnn)\n",
    "- **Framework**: Hugging Face Transformers\n",
    "- **Dataset**: Custom collected YouTube data (20 videos, 400 comments)\n",
    "\n",
    "---\n",
    "\n",
    "**Phase 1 Complete! ğŸ‰**\n",
    "\n",
    "This quick demo demonstrates the core functionality of our YouTube Report Generator. The full pipeline (Phase 2) will include more sophisticated models and real-time data collection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
