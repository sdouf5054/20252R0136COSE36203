{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3KrxrkKFxmk"
   },
   "source": [
    "# YouTube Report Generator - Phase 2 Full Pipeline (Improved)\n",
    "\n",
    "## üìã Overview\n",
    "\n",
    "**Version**: 2.2 (Enhanced with prompt tuning and analysis improvements)\n",
    "\n",
    "### Key Improvements in v2.2\n",
    "- ‚úÖ **Two-Part Summary Structure**: KEY POINTS (1-2 sentences) + DETAILED SUMMARY (3-5 sentences)\n",
    "- ‚úÖ **Enhanced Comment Analysis**: Majority/Minority views + Sentiment breakdown\n",
    "- ‚úÖ **LLM Category Correction**: Validates and corrects category model predictions\n",
    "- ‚úÖ **Increased Comment Processing**: Up to 100 comments (configurable)\n",
    "- ‚úÖ **Better Report Formatting**: Structured sections for improved readability\n",
    "\n",
    "### Base Features from v2.1\n",
    "- ‚úÖ **Multilingual Support**: Llama/Qwen native multilingual understanding\n",
    "- ‚úÖ **Fixed English Output**: All reports in English regardless of input language\n",
    "- ‚úÖ **Code-switching Handling**: Understands mixed-language content naturally\n",
    "- ‚úÖ **Modular Design**: Î™®Îç∏, ÌîÑÎ°¨ÌîÑÌä∏, Ï†ÑÏ≤òÎ¶¨ Î™®ÎìàÌôî\n",
    "- ‚úÖ **Extensible Architecture**: Team model ÌÜµÌï© Ï§ÄÎπÑ\n",
    "- ‚úÖ **Better Preprocessing**: URL Ï†úÍ±∞, Ïñ∏Ïñ¥ Í∞êÏßÄ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7s9FaCr-Fxmq"
   },
   "source": [
    "## üì¶ 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wyytSoZbFxms",
    "outputId": "68fa3875-1b46-460e-9986-e962ec43c864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BMQ1mnhnFxmv",
    "outputId": "52fbb209-9be1-4de2-9405-7209553dbf28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers accelerate bitsandbytes torch\n",
    "!pip install -q langdetect isodate\n",
    "!pip install -q google-api-python-client  # For YouTube API (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKoWkQ10Fxmw",
    "outputId": "9a8ef77a-d6fd-4cd9-e2d4-5fae594dbec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu126\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA L4\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import torch\n",
    "import isodate\n",
    "from langdetect import detect, LangDetectException\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv2IZeXFFxmx"
   },
   "source": [
    "## ‚öôÔ∏è 2. Configuration\n",
    "\n",
    "Î™®Îì† ÏÑ§Ï†ïÏùÑ Ïó¨Í∏∞ÏÑú Ï†úÏñ¥Ìï† Ïàò ÏûàÏäµÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8r1AcDzFxmy",
    "outputId": "ae7f4bf0-58e6-45b6-dc64-e820f5ef47b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Pipeline Configuration (v2.2 Enhanced)\n",
      "============================================================\n",
      "Model: meta-llama/Llama-3.1-8B-Instruct\n",
      "4-bit: True\n",
      "Temperature: 0.7\n",
      "Output Language: English\n",
      "Test Videos: 3\n",
      "Max Comments to Process: 100 (üÜï Increased)\n",
      "LLM Category Correction: True (üÜï)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class PipelineConfig:\n",
    "    \"\"\"Ï†ÑÏ≤¥ ÌååÏù¥ÌîÑÎùºÏù∏ ÏÑ§Ï†ï (Enhanced for v2.2)\"\"\"\n",
    "\n",
    "    # Model Configuration\n",
    "    model_name: str = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "    use_4bit: bool = True\n",
    "    max_new_tokens: int = 512\n",
    "    temperature: float = 0.7\n",
    "    top_p: float = 0.9\n",
    "\n",
    "    # Data Configuration\n",
    "    use_youtube_api: bool = False\n",
    "    youtube_api_key: Optional[str] = None\n",
    "    data_path: str = \"full_dataset_20251013_215347.json\"\n",
    "\n",
    "    # Processing Configuration - ENHANCED\n",
    "    max_description_length: int = 2000\n",
    "    max_comments_to_process: int = 100  # üÜï Increased from 50 to 100\n",
    "    min_comment_length: int = 10\n",
    "    remove_urls: bool = True\n",
    "    detect_language: bool = True\n",
    "\n",
    "    # Multilingual Configuration\n",
    "    output_language: str = \"English\"\n",
    "    multilingual_understanding: bool = True\n",
    "\n",
    "    # Experimental Configuration\n",
    "    num_videos_for_test: int = 3\n",
    "    enable_detailed_logging: bool = True\n",
    "    log_token_counts: bool = True\n",
    "\n",
    "    # Team Model Integration - ENHANCED\n",
    "    use_category_model: bool = False\n",
    "    use_sentiment_model: bool = False\n",
    "    category_model_path: Optional[str] = None\n",
    "    sentiment_model_path: Optional[str] = None\n",
    "    enable_llm_category_correction: bool = True  # üÜï LLM-based category validation\n",
    "\n",
    "    # Output Configuration\n",
    "    output_format: str = \"markdown\"\n",
    "    save_reports: bool = True\n",
    "    output_dir: str = \"reports\"\n",
    "\n",
    "# Create configuration\n",
    "config = PipelineConfig(\n",
    "    # model_name=\"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    model_name=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    use_4bit=True,\n",
    "    use_youtube_api=False,\n",
    "    data_path=\"/content/drive/MyDrive/25_sch/ML/youtube_test_10132154/full_dataset_20251013_215347.json\",\n",
    "    output_language=\"English\",\n",
    "    multilingual_understanding=True,\n",
    "    num_videos_for_test=3,\n",
    "    enable_detailed_logging=True,\n",
    "    max_comments_to_process=100,  # üÜï Process more comments\n",
    "    enable_llm_category_correction=True  # üÜï Enable category correction\n",
    ")\n",
    "\n",
    "\n",
    "# YouTube Category List (for LLM Category Correction)\n",
    "# YouTube Category List (11 categories used by team model)\n",
    "CATEGORY_LIST = [\n",
    "    \"Music\",\n",
    "    \"Sports\",\n",
    "    \"Travel\",\n",
    "    \"Gaming\",\n",
    "    \"People & Blogs\",\n",
    "    \"Comedy\",\n",
    "    \"Entertainment\",\n",
    "    \"News & Politics\",\n",
    "    \"HowTo & Style\",\n",
    "    \"Education\",\n",
    "    \"Science & Tech\",\n",
    "]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Pipeline Configuration (v2.2 Enhanced)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {config.model_name}\")\n",
    "print(f\"4-bit: {config.use_4bit}\")\n",
    "print(f\"Temperature: {config.temperature}\")\n",
    "print(f\"Output Language: {config.output_language}\")\n",
    "print(f\"Test Videos: {config.num_videos_for_test}\")\n",
    "print(f\"Max Comments to Process: {config.max_comments_to_process} (üÜï Increased)\")\n",
    "print(f\"LLM Category Correction: {config.enable_llm_category_correction} (üÜï)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amnASu4pFxm1"
   },
   "source": [
    "## üß© 3. Enhanced Prompt Templates\n",
    "\n",
    "### üÜï Key Improvements:\n",
    "1. **Two-Part Structure**: KEY POINTS (scannable) + DETAILED SUMMARY (comprehensive)\n",
    "2. **Majority/Minority Analysis**: Distinguishes mainstream vs outlier opinions\n",
    "3. **Sentiment Integration**: Explicit sentiment breakdown in output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmI9rOJXFxm2",
    "outputId": "4b2ad1eb-f2e1-4cb9-d758-9e21df08b169"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced prompt templates loaded (v2.2)\n",
      "üÜï Two-part summary structure\n",
      "üÜï Majority/minority opinion analysis\n",
      "üÜï Sentiment breakdown integration\n",
      "üÜï Category correction system\n"
     ]
    }
   ],
   "source": [
    "class PromptTemplates:\n",
    "    \"\"\"Enhanced Prompt Templates (v2.2) with Two-Part Structure\"\"\"\n",
    "\n",
    "    # ===== Video Summary Prompts (ENHANCED) =====\n",
    "    VIDEO_SUMMARY_SYSTEM = \"\"\"\n",
    "You are an expert multilingual content analyst specializing in YouTube video analysis.\n",
    "Your task is to understand content in ANY language (Korean, English, Japanese, or mixed) and create summaries in English.\n",
    "You have native-level understanding of multiple languages and can capture nuances across different cultures.\n",
    "Focus on accuracy and avoid hallucinations.\n",
    "\n",
    "CRITICAL:\n",
    "- Follow the TWO-PART output format exactly as specified.\n",
    "- Do NOT include any guidelines, meta comments, or notes in the output.\n",
    "- Write natural English sentences only.\n",
    "\"\"\"\n",
    "\n",
    "    VIDEO_SUMMARY_USER = \"\"\"\n",
    "Analyze this YouTube video and create a TWO-PART summary in English.\n",
    "\n",
    "Video Information:\n",
    "- Title: {title}\n",
    "- Description: {description}\n",
    "- Category: {category}\n",
    "- Duration: {duration} seconds\n",
    "- Channel: {channel}\n",
    "\n",
    "Context:\n",
    "The title and description may be in Korean, English, Japanese, or mixed languages.\n",
    "Understand the content in its original languages and provide your analysis.\n",
    "\n",
    "Output Format (FOLLOW EXACTLY):\n",
    "\n",
    "KEY POINT:\n",
    "- 1‚Äì2 sentences.\n",
    "- One clear, scannable statement of what this video is about.\n",
    "- No bullet points, no headings, just plain sentences.\n",
    "\n",
    "DETAILED SUMMARY:\n",
    "- 3‚Äì4 sentences.\n",
    "- Describe the main theme, key content highlights, target audience, and purpose of the video.\n",
    "- If the description is minimal, briefly mention that information is limited, but do NOT overemphasize this.\n",
    "\n",
    "Write everything in natural English sentences without repeating labels like \"KEY POINT\" or \"DETAILED SUMMARY\" in the text.\n",
    "\"\"\"\n",
    "\n",
    "    # ===== Reaction Summary Prompts (ENHANCED) =====\n",
    "    REACTION_SUMMARY_SYSTEM = \"\"\"\n",
    "You are an expert in multilingual social media sentiment analysis.\n",
    "You can understand and analyze comments in Korean, English, Japanese, and mixed languages.\n",
    "Your task is to capture audience reactions across all language communities and summarize in English.\n",
    "\n",
    "CRITICAL:\n",
    "- Follow TWO-PART output structure: KEY POINT first, then DETAILED SUMMARY.\n",
    "- KEY POINT: 1-2 sentences capturing the dominant sentiment/reaction.\n",
    "- DETAILED SUMMARY: 3-5 sentences analyzing majority/minority views + themes.\n",
    "- SENTIMENT BREAKDOWN: Final line with exact percentages (sum to 100%).\n",
    "- Do NOT include guidelines, meta comments, or notes in output.\n",
    "- Use qualitative phrases in DETAILED SUMMARY (\"overwhelmingly positive\", \"small minority\") instead of numbers.\n",
    "\"\"\"\n",
    "\n",
    "    REACTION_SUMMARY_USER = \"\"\"\n",
    "Analyze these YouTube comments and create a TWO-PART summary + sentiment breakdown.\n",
    "\n",
    "Video title: {title}\n",
    "\n",
    "Audience Comments ({comment_count} comments, highest-engagement first):\n",
    "{comments}\n",
    "\n",
    "Context:\n",
    "Multilingual comments (Korean, English, Japanese, code-switching).\n",
    "Ignore spam/jokes/extreme outliers.\n",
    "\n",
    "Output Format (FOLLOW EXACTLY):\n",
    "\n",
    "KEY POINT:\n",
    "- 1-2 sentences.\n",
    "- Dominant sentiment and general reaction (e.g., \"Overwhelmingly positive excitement\").\n",
    "\n",
    "DETAILED SUMMARY:\n",
    "- 3-5 sentences.\n",
    "- Majority view (main patterns/themes).\n",
    "- Notable minority/outlier views (only meaningful ones).\n",
    "- Common themes across languages.\n",
    "- Cultural/language differences if present.\n",
    "- Use qualitative expressions, NOT numbers.\n",
    "\n",
    "SENTIMENT BREAKDOWN:\n",
    "- One line: Positive: X%  Negative: Y%  Neutral: Z% (must sum to 100%)\n",
    "- Do NOT explicitly add any \"Note:\" or disclaimer sentences about the analysis. These sentences would be provided anyway with stacticly predefined ones.\n",
    "\n",
    "Write in natural English sentences without repeating section labels in the text.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    # ===== Category Correction Prompt (NEW) =====\n",
    "    CATEGORY_CORRECTION_SYSTEM = \"\"\"You are an expert YouTube category classifier with deep understanding of content types.\n",
    "Your task is to validate model predictions and correct them if clearly wrong.\n",
    "\n",
    "Available Categories:\n",
    "1. Music\n",
    "2. Sports\n",
    "3. Travel\n",
    "4. Gaming\n",
    "5. People & Blogs\n",
    "6. Comedy\n",
    "7. Entertainment\n",
    "8. News & Politics\n",
    "9. HowTo & Style\n",
    "10. Education\n",
    "11. Science & Tech\n",
    "Guidelines:\n",
    "- Only correct if the prediction is CLEARLY wrong\n",
    "- If model is reasonable (even if not perfect), keep the original\n",
    "- Music videos should be \"Music\", not \"Entertainment\" or \"People & Blogs\"\n",
    "- Gaming content should be \"Gaming\", not \"Entertainment\"\n",
    "- Educational content should be \"Education\", not \"People & Blogs\"\"\"\n",
    "\n",
    "    CATEGORY_CORRECTION_USER = \"\"\"Review this category prediction and correct if clearly wrong.\n",
    "\n",
    "Model Prediction: {model_prediction}\n",
    "\n",
    "Video Information:\n",
    "- Title: {title}\n",
    "- Description: {description}\n",
    "- Channel: {channel}\n",
    "\n",
    "Instructions:\n",
    "1. Read the video information carefully\n",
    "2. Evaluate if the model prediction is appropriate\n",
    "3. If CLEARLY wrong, provide the correct category from the list above\n",
    "4. If reasonable (even if not perfect), respond with \"KEEP_ORIGINAL\"\n",
    "5. Output ONLY the category name or \"KEEP_ORIGINAL\"\n",
    "\n",
    "Your decision (category name or KEEP_ORIGINAL):\"\"\"\n",
    "\n",
    "    CUSTOM_PROMPT = None\n",
    "\n",
    "    @classmethod\n",
    "    def get_video_summary_prompt(cls, video_info: Dict) -> List[Dict]:\n",
    "        \"\"\"Generate video summary prompt (enhanced two-part structure)\"\"\"\n",
    "        if cls.CUSTOM_PROMPT:\n",
    "            return cls.CUSTOM_PROMPT\n",
    "\n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": cls.VIDEO_SUMMARY_SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": cls.VIDEO_SUMMARY_USER.format(\n",
    "                title=video_info.get('title', 'N/A'),\n",
    "                description=video_info.get('description', 'N/A')[:2000],\n",
    "                category=video_info.get('category_name', 'N/A'),\n",
    "                duration=video_info.get('duration_seconds', 'N/A'),\n",
    "                channel=video_info.get('channel_title', 'N/A')\n",
    "            )}\n",
    "        ]\n",
    "\n",
    "    @classmethod\n",
    "    def get_reaction_summary_prompt(cls, title: str, comments_text: str, comment_count: int) -> List[Dict]:\n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": cls.REACTION_SUMMARY_SYSTEM},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": cls.REACTION_SUMMARY_USER.format(\n",
    "                    title=title,\n",
    "                    comments=comments_text,\n",
    "                    comment_count=comment_count,\n",
    "                ),\n",
    "            },\n",
    "        ]\n",
    "\n",
    "    @classmethod\n",
    "    def get_category_correction_prompt(cls, model_prediction: str, video_info: Dict) -> List[Dict]:\n",
    "        \"\"\"Generate category correction prompt (NEW)\"\"\"\n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": cls.CATEGORY_CORRECTION_SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": cls.CATEGORY_CORRECTION_USER.format(\n",
    "                model_prediction=model_prediction,\n",
    "                title=video_info.get('title', 'N/A'),\n",
    "                description=video_info.get('description', 'N/A')[:500],\n",
    "                channel=video_info.get('channel_title', 'N/A')\n",
    "            )}\n",
    "        ]\n",
    "\n",
    "print(\"‚úÖ Enhanced prompt templates loaded (v2.2)\")\n",
    "print(\"üÜï Two-part summary structure\")\n",
    "print(\"üÜï Majority/minority opinion analysis\")\n",
    "print(\"üÜï Sentiment breakdown integration\")\n",
    "print(\"üÜï Category correction system\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzUzgqWCFxm6"
   },
   "source": [
    "## üîß 4. Text Preprocessing\n",
    "\n",
    "Same as v2.1 - no changes needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qa3j7eZtFxm7",
    "outputId": "c0c65cc2-346b-4e80-9a6b-64eaf3bcf0d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Text preprocessor initialized\n"
     ]
    }
   ],
   "source": [
    "class TextPreprocessor:\n",
    "    \"\"\"ÌÖçÏä§Ìä∏ Ï†ÑÏ≤òÎ¶¨\"\"\"\n",
    "\n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "        self.url_pattern = re.compile(r'http[s]?://\\S+')\n",
    "\n",
    "    def remove_urls(self, text: str) -> str:\n",
    "        return self.url_pattern.sub('', text)\n",
    "\n",
    "    def detect_language(self, text: str) -> str:\n",
    "        try:\n",
    "            lang = detect(text)\n",
    "            lang_map = {'ko': 'Korean', 'en': 'English', 'ja': 'Japanese'}\n",
    "            return lang_map.get(lang, 'English')\n",
    "        except:\n",
    "            return 'English'\n",
    "\n",
    "    def clean_description(self, description: str) -> str:\n",
    "        if not description:\n",
    "            return \"No description available.\"\n",
    "        if self.config.remove_urls:\n",
    "            description = self.remove_urls(description)\n",
    "        description = ' '.join(description.split())\n",
    "        if len(description) > self.config.max_description_length:\n",
    "            description = description[:self.config.max_description_length] + \"...\"\n",
    "        if len(description.strip()) < 20:\n",
    "            return \"Minimal description available.\"\n",
    "        return description\n",
    "\n",
    "    def filter_comments(self, comments: List[Dict]) -> List[Dict]:\n",
    "        filtered = [c for c in comments if len(c.get('text', '')) >= self.config.min_comment_length]\n",
    "        filtered.sort(key=lambda x: x.get('like_count', 0), reverse=True)\n",
    "        return filtered[:self.config.max_comments_to_process]\n",
    "\n",
    "    def format_comments_for_prompt(self, comments: List[Dict]) -> str:\n",
    "        if not comments:\n",
    "            return \"No comments available.\"\n",
    "        formatted = []\n",
    "        for i, comment in enumerate(comments, 1):\n",
    "            text = comment.get('text', '')\n",
    "            likes = comment.get('like_count', 0)\n",
    "            if self.config.remove_urls:\n",
    "                text = self.remove_urls(text)\n",
    "            formatted.append(f\"{i}. [{likes} likes] {text}\")\n",
    "        return \"\\n\".join(formatted)\n",
    "\n",
    "    def parse_duration(self, duration_str: str) -> int:\n",
    "        try:\n",
    "            duration = isodate.parse_duration(duration_str)\n",
    "            return int(duration.total_seconds())\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "preprocessor = TextPreprocessor(config)\n",
    "print(\"‚úÖ Text preprocessor initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sU9ZWlrPFxm8"
   },
   "source": [
    "## ü§ñ 5. Model Loading\n",
    "\n",
    "Same as v2.1 - no changes needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331,
     "referenced_widgets": [
      "dd1b409b6ac24ad9bdd46cbd69336199",
      "08ab3cdd35b54fcfbfac47b64fd200b8",
      "630095595c38482fbbdd5153d32764a8",
      "b306d1ab44f44075b52b6193db2ba370",
      "a4798e3a46cc466bad1c49f8c9ab523f",
      "ecb5ba48448a48e8a0b76d0155b59cc6",
      "4fd1db3cb68e42fdb59ec2a17e10d0a7",
      "aeb781aa81574e77837d4219cb9cffe3",
      "dfbff905431f4365904db4340e2d1b8c",
      "b7a7091e0b3d42b3b352c6af3df7adb9",
      "5fc5b8e1a7c146428027a7a5b90e6f9c",
      "d3a4af7e21f64c34a65e04dbef19a614",
      "fddd413a6ff74fa6954582c1b6c89e1c",
      "b512682647744b06a3c5bd7cc483a5a0",
      "01fd0d70ef8c453bba9eb0e5bd8c7a3f",
      "360c02e42a134bf990d75be974bfe6a1",
      "86993a5ccd7443d394e3d9340cac7c01"
     ]
    },
    "id": "XHwlmAkfFxm9",
    "outputId": "6a8bc2cb-a9ac-4495-c9e5-771b7c081dae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1b409b6ac24ad9bdd46cbd69336199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [OPTIONAL]\n",
    "# Run this cell if model need to be loaded with hugging face login\n",
    "\n",
    "from huggingface_hub import login\n",
    "login()  # Token ÏûÖÎ†• ÌïÑÏöî"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214,
     "referenced_widgets": [
      "5c565852e2e1445192d7693c46a2b02d",
      "0985e043807f4e6a86f3c0f985674a5a",
      "2b279f43050b40f9be8919958f05a6be",
      "2b188a83d58643e38430cf98d0e8e9fd",
      "7156a8d9d9a0453ba1d8855edd8277d5",
      "0b68640f854241e3b3ef36453ebeea26",
      "8319ba41b4fa4e88b685419632c9b770",
      "f9123903555144ae803f203d6393cd54",
      "54adfb84e14e423587f621ece3fad9e9",
      "d2a651c6b5dd490db0bd90eb7def1d59",
      "fa7239fd4f0b43daae8a4ca8c7bba97e"
     ]
    },
    "id": "F4yeHNR5Fxm9",
    "outputId": "0d22757a-2658-478b-93a3-311f1ac653ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Loading: meta-llama/Llama-3.1-8B-Instruct\n",
      "‚öôÔ∏è 4-bit: True\n",
      "Loading tokenizer...\n",
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c565852e2e1445192d7693c46a2b02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pipeline...\n",
      "‚úÖ Model loaded!\n",
      "üìä Model parameters: ~8.0B\n"
     ]
    }
   ],
   "source": [
    "class ModelManager:\n",
    "    \"\"\"LLM Î™®Îç∏ Í¥ÄÎ¶¨\"\"\"\n",
    "\n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.pipe = None\n",
    "\n",
    "    def load_model(self):\n",
    "        print(f\"\\nüîÑ Loading: {self.config.model_name}\")\n",
    "        print(f\"‚öôÔ∏è 4-bit: {self.config.use_4bit}\")\n",
    "\n",
    "        # Tokenizer\n",
    "        print(\"Loading tokenizer...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            self.config.model_name, trust_remote_code=True\n",
    "        )\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "        # Quantization config\n",
    "        if self.config.use_4bit:\n",
    "            quantization_config = BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_compute_dtype=torch.float16,\n",
    "                bnb_4bit_quant_type=\"nf4\",\n",
    "                bnb_4bit_use_double_quant=True\n",
    "            )\n",
    "        else:\n",
    "            quantization_config = None\n",
    "\n",
    "        # Model\n",
    "        print(\"Loading model...\")\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.config.model_name,\n",
    "            quantization_config=quantization_config,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=torch.float16 if not self.config.use_4bit else None\n",
    "        )\n",
    "\n",
    "        # Pipeline\n",
    "        print(\"Creating pipeline...\")\n",
    "        self.pipe = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_new_tokens=self.config.max_new_tokens,\n",
    "            temperature=self.config.temperature,\n",
    "            top_p=self.config.top_p,\n",
    "            do_sample=True,\n",
    "            pad_token_id=self.tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "        print(\"‚úÖ Model loaded!\")\n",
    "        if self.config.enable_detailed_logging:\n",
    "            print(f\"üìä Model parameters: ~{self.model.num_parameters() / 1e9:.1f}B\")\n",
    "\n",
    "    def generate(self, messages: List[Dict]) -> str:\n",
    "        \"\"\"Generate text with explicit chat template and detailed logging\"\"\"\n",
    "        if self.pipe is None:\n",
    "            raise RuntimeError(\"Model not loaded. Call load_model() first.\")\n",
    "\n",
    "        try:\n",
    "            # Apply chat template explicitly (for reproducibility)\n",
    "            if hasattr(self.tokenizer, 'apply_chat_template'):\n",
    "                prompt_text = self.tokenizer.apply_chat_template(\n",
    "                    messages,\n",
    "                    tokenize=False,\n",
    "                    add_generation_prompt=True\n",
    "                )\n",
    "\n",
    "                # Log token counts if enabled\n",
    "                if self.config.log_token_counts:\n",
    "                    input_tokens = len(self.tokenizer.encode(prompt_text))\n",
    "                    if self.config.enable_detailed_logging:\n",
    "                        print(f\"      [Input tokens: {input_tokens}]\")\n",
    "\n",
    "                # Generate\n",
    "                outputs = self.pipe(messages)\n",
    "            else:\n",
    "                # Fallback for models without chat template\n",
    "                outputs = self.pipe(messages)\n",
    "\n",
    "            # Extract generated text\n",
    "            generated_text = outputs[0][\"generated_text\"]\n",
    "\n",
    "            if isinstance(generated_text, list):\n",
    "                # Chat format output\n",
    "                result = generated_text[-1][\"content\"]\n",
    "            else:\n",
    "                # String output\n",
    "                result = generated_text\n",
    "\n",
    "            # Log output token count\n",
    "            if self.config.log_token_counts:\n",
    "                output_tokens = len(self.tokenizer.encode(result))\n",
    "                if self.config.enable_detailed_logging:\n",
    "                    print(f\"      [Output tokens: {output_tokens}]\")\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            # Enhanced error logging\n",
    "            print(f\"\\n‚ùå Generation Error:\")\n",
    "            print(f\"   Error type: {type(e).__name__}\")\n",
    "            print(f\"   Error message: {str(e)}\")\n",
    "            print(f\"   Messages length: {len(messages)}\")\n",
    "\n",
    "            if self.config.enable_detailed_logging:\n",
    "                # Log message content for debugging\n",
    "                total_chars = sum(len(m.get('content', '')) for m in messages)\n",
    "                print(f\"   Total message chars: {total_chars}\")\n",
    "                print(f\"   System prompt length: {len(messages[0].get('content', ''))} chars\")\n",
    "                print(f\"   User prompt length: {len(messages[1].get('content', ''))} chars\")\n",
    "\n",
    "            raise\n",
    "\n",
    "model_manager = ModelManager(config)\n",
    "model_manager.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5XF03bxFxm_"
   },
   "source": [
    "## üîå 6. Team Model Integration (Enhanced)\n",
    "\n",
    "### üÜï Added: LLM-based Category Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLV0_k0-FxnA",
    "outputId": "96b8120e-8329-4294-f08a-7ef2399dbc93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Team model interface ready (enhanced with LLM correction)\n"
     ]
    }
   ],
   "source": [
    "class TeamModelIntegration:\n",
    "    \"\"\"ÌåÄ Î™®Îç∏ ÌÜµÌï© Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ (Enhanced with LLM correction)\"\"\"\n",
    "\n",
    "    def __init__(self, config: PipelineConfig, model_manager: 'ModelManager'):\n",
    "        self.config = config\n",
    "        self.model_manager = model_manager\n",
    "        self.category_model = None\n",
    "        self.sentiment_model = None\n",
    "\n",
    "    def load_category_model(self):\n",
    "        if not self.config.use_category_model:\n",
    "            return\n",
    "        # TODO: ÌåÄÏõê Íµ¨ÌòÑ\n",
    "        print(\"‚ö†Ô∏è Category model not implemented yet\")\n",
    "\n",
    "    def load_sentiment_model(self):\n",
    "        if not self.config.use_sentiment_model:\n",
    "            return\n",
    "        # TODO: ÌåÄÏõê Íµ¨ÌòÑ\n",
    "        print(\"‚ö†Ô∏è Sentiment model not implemented yet\")\n",
    "\n",
    "    def predict_category(self, video_info: Dict) -> Optional[str]:\n",
    "        \"\"\"Predict category (from team model)\"\"\"\n",
    "        if not self.config.use_category_model or self.category_model is None:\n",
    "            return None\n",
    "        # TODO: Î™®Îç∏ inference\n",
    "        return None\n",
    "\n",
    "    def predict_category_with_llm_correction(self, video_info: Dict, model_pred: str) -> Tuple[str, str, bool]:\n",
    "        \"\"\"üÜï Validate and correct category prediction using LLM\n",
    "\n",
    "        Returns:\n",
    "            Tuple[str, str, bool]: (original_prediction, final_prediction, was_corrected)\n",
    "        \"\"\"\n",
    "        if not self.config.enable_llm_category_correction:\n",
    "            return model_pred, model_pred, False\n",
    "\n",
    "        try:\n",
    "            # Generate correction prompt\n",
    "            messages = PromptTemplates.get_category_correction_prompt(model_pred, video_info)\n",
    "\n",
    "            # Get LLM's decision\n",
    "            llm_decision = self.model_manager.generate(messages).strip()\n",
    "\n",
    "            # Check if correction was made\n",
    "            if llm_decision.upper() == \"KEEP_ORIGINAL\" or llm_decision == model_pred:\n",
    "                return model_pred, model_pred, False\n",
    "            else:\n",
    "                return model_pred, llm_decision, True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Category correction failed: {e}\")\n",
    "            return model_pred, model_pred, False\n",
    "\n",
    "    def analyze_sentiment(self, comments: List[Dict]) -> Optional[Dict]:\n",
    "        \"\"\"Analyze sentiment (from team model)\"\"\"\n",
    "        if not self.config.use_sentiment_model or self.sentiment_model is None:\n",
    "            return None\n",
    "        # TODO: Î™®Îç∏ inference\n",
    "        return None\n",
    "\n",
    "# Initialize after model_manager is created\n",
    "team_models = TeamModelIntegration(config, model_manager)\n",
    "team_models.load_category_model()\n",
    "team_models.load_sentiment_model()\n",
    "print(\"‚úÖ Team model interface ready (enhanced with LLM correction)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18Jl2vwPFxnC"
   },
   "source": [
    "## üì• 7. Data Loading\n",
    "\n",
    "Same as v2.1 - no changes needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mFCwourRFxnD",
    "outputId": "003812aa-d866-4024-f555-01bf67caca27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loader ready\n"
     ]
    }
   ],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def load_from_file(self, file_path: str) -> List[Dict]:\n",
    "        print(f\"\\nüìÇ Loading: {file_path}\")\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"‚úÖ Loaded {len(data)} videos\")\n",
    "        return data\n",
    "\n",
    "    def get_data(self) -> List[Dict]:\n",
    "        if self.config.use_youtube_api:\n",
    "            raise NotImplementedError(\"YouTube API not implemented yet\")\n",
    "        return self.load_from_file(self.config.data_path)\n",
    "\n",
    "data_loader = DataLoader(config)\n",
    "print(\"‚úÖ Data loader ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGWqm4CeFxnD"
   },
   "source": [
    "## üé¨ 8. Enhanced Report Generation Pipeline\n",
    "\n",
    "### üÜï Key Improvements:\n",
    "1. Enhanced video summary generation (two-part structure)\n",
    "2. Enhanced reaction summary generation (majority/minority + sentiment)\n",
    "3. Improved report formatting (structured sections)\n",
    "4. Category correction display in reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TCXjyrWeFxnD",
    "outputId": "6a7771d6-bce7-4597-8ace-b6de3d452acf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced report generator initialized (v2.2)\n",
      "üÜï Two-part summary structure enabled\n",
      "üÜï Majority/minority opinion analysis enabled\n",
      "üÜï LLM category correction enabled\n"
     ]
    }
   ],
   "source": [
    "class ReportGenerator:\n",
    "    \"\"\"Enhanced Report Generator (v2.2)\"\"\"\n",
    "\n",
    "    def __init__(self, config, model_manager, preprocessor, team_models):\n",
    "        self.config = config\n",
    "        self.model_manager = model_manager\n",
    "        self.preprocessor = preprocessor\n",
    "        self.team_models = team_models\n",
    "\n",
    "        # Initialize language statistics\n",
    "        self.language_stats = {\n",
    "            'video': {},\n",
    "            'comments': {}\n",
    "        }\n",
    "        self.current_video_lang_dist = {}\n",
    "\n",
    "    def generate_video_summary(self, video_info: Dict) -> Tuple[str, str]:\n",
    "        \"\"\"Generate video summary with two-part structure\"\"\"\n",
    "        # Preprocess\n",
    "        video_info['description'] = self.preprocessor.clean_description(\n",
    "            video_info.get('description', '')\n",
    "        )\n",
    "        video_info['duration_seconds'] = self.preprocessor.parse_duration(\n",
    "            video_info.get('duration', 'PT0S')\n",
    "        )\n",
    "\n",
    "        # Detect language and update statistics\n",
    "        detected_lang = 'Unknown'\n",
    "        if self.config.detect_language:\n",
    "            detected_lang = self.preprocessor.detect_language(\n",
    "                video_info.get('title', '') + ' ' + video_info.get('description', '')[:500]\n",
    "            )\n",
    "\n",
    "            if self.config.enable_detailed_logging:\n",
    "                print(f\"    [Detected input language: {detected_lang}]\")\n",
    "\n",
    "            self.language_stats['video'][detected_lang] = \\\n",
    "                self.language_stats['video'].get(detected_lang, 0) + 1\n",
    "\n",
    "        # Generate prompt\n",
    "        messages = PromptTemplates.get_video_summary_prompt(video_info)\n",
    "\n",
    "        # Generate summary\n",
    "        try:\n",
    "            summary = self.model_manager.generate(messages)\n",
    "\n",
    "            if self.config.enable_detailed_logging:\n",
    "                print(f\"    [Output language: {self.config.output_language}]\")\n",
    "\n",
    "            return summary.strip(), detected_lang\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Video summary generation failed: {e}\")\n",
    "            return \"Video summary generation failed.\", detected_lang\n",
    "\n",
    "    def generate_reaction_summary(self, title: str, comments: List[Dict]) -> Tuple[str, str]:\n",
    "        \"\"\"üÜï Generate reaction summary with majority/minority analysis and sentiment\"\"\"\n",
    "        # Filter and format comments\n",
    "        filtered_comments = self.preprocessor.filter_comments(comments)\n",
    "\n",
    "        if not filtered_comments:\n",
    "            return \"No comments available for analysis.\", \"N/A\"\n",
    "\n",
    "        comments_text = self.preprocessor.format_comments_for_prompt(filtered_comments)\n",
    "\n",
    "        # Detect comment language distribution and update statistics\n",
    "        lang_distribution = \"N/A\"\n",
    "        lang_dist = {}\n",
    "\n",
    "        if self.config.detect_language:\n",
    "            # Sample up to N comments (config-based)\n",
    "            sample_size = min(len(filtered_comments), self.config.max_comments_to_process)\n",
    "            sample_texts = [\n",
    "                c.get('text', '')[:100] for c in filtered_comments[:sample_size]\n",
    "            ]\n",
    "            langs = [self.preprocessor.detect_language(t) for t in sample_texts if t]\n",
    "\n",
    "            # Count by language\n",
    "            if langs:\n",
    "                for lang in langs:\n",
    "                    lang_dist[lang] = lang_dist.get(lang, 0) + 1\n",
    "\n",
    "                lang_distribution = ', '.join([f\"{k}: {v}\" for k, v in lang_dist.items()])\n",
    "\n",
    "                if self.config.enable_detailed_logging:\n",
    "                    print(f\"    [Comment languages (top {sample_size}): {lang_dist}]\")\n",
    "\n",
    "                # Update comment language statistics\n",
    "                for lang, count in lang_dist.items():\n",
    "                    self.language_stats['comments'][lang] = \\\n",
    "                        self.language_stats['comments'].get(lang, 0) + count\n",
    "\n",
    "        # Store current video's language distribution\n",
    "        self.current_video_lang_dist = lang_dist\n",
    "\n",
    "        # Generate prompt with comment count\n",
    "        messages = PromptTemplates.get_reaction_summary_prompt(\n",
    "            title,\n",
    "            comments_text,\n",
    "            len(filtered_comments)\n",
    "        )\n",
    "\n",
    "        # Generate summary\n",
    "        try:\n",
    "            summary = self.model_manager.generate(messages)\n",
    "\n",
    "            if self.config.enable_detailed_logging:\n",
    "                print(f\"    [Output language: {self.config.output_language}]\")\n",
    "\n",
    "            return summary.strip(), lang_distribution\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Reaction summary generation failed: {e}\")\n",
    "            return \"Reaction summary generation failed.\", lang_distribution\n",
    "\n",
    "    def calculate_engagement_metrics(self, video_info: Dict) -> Dict:\n",
    "        \"\"\"Calculate engagement metrics\"\"\"\n",
    "        views = video_info.get('view_count', 0)\n",
    "        likes = video_info.get('like_count', 0)\n",
    "        comments = video_info.get('comment_count', 0)\n",
    "\n",
    "        engagement_rate = ((likes + comments) / views * 100) if views > 0 else 0\n",
    "        like_rate = (likes / views * 100) if views > 0 else 0\n",
    "        comment_rate = (comments / views * 100) if views > 0 else 0\n",
    "\n",
    "        return {\n",
    "            'views': views,\n",
    "            'likes': likes,\n",
    "            'comments': comments,\n",
    "            'engagement_rate': round(engagement_rate, 2),\n",
    "            'like_rate': round(like_rate, 2),\n",
    "            'comment_rate': round(comment_rate, 2)\n",
    "        }\n",
    "\n",
    "    def get_language_statistics(self) -> Dict:\n",
    "        \"\"\"Return accumulated language statistics\"\"\"\n",
    "        return self.language_stats\n",
    "\n",
    "    def format_markdown_report(self, video_data: Dict, video_summary: str,\n",
    "                               reaction_summary: str, metrics: Dict,\n",
    "                               team_predictions: Dict = None,\n",
    "                               detected_languages: Dict = None) -> str:\n",
    "        \"\"\"üÜï Enhanced report formatting with structured sections\"\"\"\n",
    "        video_info = video_data['video_info']\n",
    "        comments = video_data.get('comments', [])\n",
    "\n",
    "        # Calculate comment statistics\n",
    "        filtered_for_analysis = self.preprocessor.filter_comments(comments)\n",
    "        total_comments = len(comments)\n",
    "        analyzed_comments = len(filtered_for_analysis)\n",
    "        analysis_percentage = (analyzed_comments / total_comments * 100) if total_comments > 0 else 0\n",
    "\n",
    "        report = f\"\"\"# YouTube Video Report\n",
    "\n",
    "**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "**Model**: {self.config.model_name}\n",
    "**Pipeline Version**: 2.2 (Enhanced Prompts & Analysis)\n",
    "\n",
    "---\n",
    "\n",
    "## üìπ Video Information\n",
    "\n",
    "- **Title**: {video_info.get('title', 'N/A')}\n",
    "- **Channel**: {video_info.get('channel_title', 'N/A')}\n",
    "- **Category**: {video_info.get('category_name', 'N/A')}\n",
    "- **Published**: {video_info.get('published_at', 'N/A')}\n",
    "- **Duration**: {self.preprocessor.parse_duration(video_info.get('duration', 'PT0S'))} seconds\n",
    "- **Video ID**: `{video_info.get('video_id', 'N/A')}`\n",
    "- **URL**: https://www.youtube.com/watch?v={video_info.get('video_id', '')}\n",
    "\"\"\"\n",
    "\n",
    "        # Add language detection info\n",
    "        if detected_languages and self.config.enable_detailed_logging:\n",
    "            report += \"\\n### üåç Detected Languages\\n\\n\"\n",
    "            if 'video' in detected_languages:\n",
    "                report += f\"- **Video content**: {detected_languages['video']}\\n\"\n",
    "            if 'comments' in detected_languages:\n",
    "                report += f\"- **Comments**: {detected_languages['comments']}\\n\"\n",
    "            report += f\"- **Report output**: {self.config.output_language}\\n\"\n",
    "\n",
    "        report += \"\\n---\\n\\n\"\n",
    "\n",
    "        report += f\"\"\"## üìä Engagement Metrics\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Views | {metrics['views']:,} |\n",
    "| Likes | {metrics['likes']:,} |\n",
    "| Comments | {metrics['comments']:,} |\n",
    "| Engagement Rate | {metrics['engagement_rate']}% |\n",
    "| Like Rate | {metrics['like_rate']}% |\n",
    "| Comment Rate | {metrics['comment_rate']}% |\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Video Summary\n",
    "\n",
    "{video_summary}\n",
    "\n",
    "---\n",
    "\n",
    "## üí¨ Audience Reaction Summary\n",
    "\n",
    "**Comments Analyzed**: {analyzed_comments:,} / {total_comments:,} ({analysis_percentage:.1f}%)\n",
    "\n",
    "{reaction_summary}\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "        # üÜï Enhanced team predictions section with category correction\n",
    "        if team_predictions:\n",
    "            report += \"\"\"## ü§ñ Team Model Predictions\\n\\n\"\"\"\n",
    "\n",
    "            if 'category' in team_predictions:\n",
    "                cat_info = team_predictions['category']\n",
    "                if isinstance(cat_info, dict):\n",
    "                    report += f\"- **Category Prediction**:\\n\"\n",
    "                    report += f\"  - Original: {cat_info.get('original', 'N/A')}\\n\"\n",
    "                    report += f\"  - Final: {cat_info.get('final', 'N/A')}\\n\"\n",
    "                    if cat_info.get('corrected', False):\n",
    "                        report += f\"  - Status: ‚úÖ Corrected by LLM\\n\"\n",
    "                    else:\n",
    "                        report += f\"  - Status: ‚úì Validated by LLM\\n\"\n",
    "                else:\n",
    "                    report += f\"- **Predicted Category**: {cat_info}\\n\"\n",
    "\n",
    "            if 'sentiment' in team_predictions:\n",
    "                s = team_predictions['sentiment']\n",
    "                report += f\"- **Sentiment Distribution**:\\n\"\n",
    "                report += f\"  - Positive: {s.get('positive', 0):.1%}\\n\"\n",
    "                report += f\"  - Neutral: {s.get('neutral', 0):.1%}\\n\"\n",
    "                report += f\"  - Negative: {s.get('negative', 0):.1%}\\n\"\n",
    "\n",
    "            report += \"\\n---\\n\\n\"\n",
    "\n",
    "        top_comments = self.preprocessor.filter_comments(comments)[:5]\n",
    "        if top_comments:\n",
    "            report += \"\"\"## üîç Top Comments\\n\\n\"\"\"\n",
    "            for i, c in enumerate(top_comments, 1):\n",
    "                text = c.get('text', '')[:200]\n",
    "                likes = c.get('like_count', 0)\n",
    "                author = c.get('author', 'Anonymous')\n",
    "                report += f\"{i}. **{author}** ({likes} likes): {text}...\\n\\n\"\n",
    "            report += \"---\\n\\n\"\n",
    "\n",
    "        report += \"\"\"## üìå Technical Notes\n",
    "\n",
    "- This report was automatically generated using LLM-based multilingual analysis\n",
    "- **Enhanced Prompts (v2.2)**: Two-part summary structure with KEY POINTS and DETAILED ANALYSIS\n",
    "- **Enhanced Comment Analysis**: Majority/minority opinion separation with sentiment breakdown\n",
    "- **LLM Category Validation**: Automated correction of misclassified categories\n",
    "- Input content processed in original language(s) without translation layer\n",
    "- Output language fixed to English for consistency\n",
    "\n",
    "---\n",
    "\n",
    "*Generated by YouTube Report Generator - Phase 2 Full Pipeline v2.2*\n",
    "\"\"\"\n",
    "        return report\n",
    "\n",
    "    def generate_report(self, video_data: Dict) -> str:\n",
    "        \"\"\"Generate complete report with all enhancements\"\"\"\n",
    "        video_info = video_data['video_info']\n",
    "        comments = video_data.get('comments', [])\n",
    "\n",
    "        print(f\"\\nüé¨ Processing: {video_info.get('title', 'Unknown')}\")\n",
    "\n",
    "        # Collect language detection info\n",
    "        detected_languages = {}\n",
    "\n",
    "        print(\"  üìù Generating video summary...\")\n",
    "        video_summary, video_lang = self.generate_video_summary(video_info)\n",
    "        detected_languages['video'] = video_lang\n",
    "\n",
    "        print(\"  üí¨ Generating reaction summary...\")\n",
    "        reaction_summary, comment_langs = self.generate_reaction_summary(\n",
    "            video_info.get('title', ''), comments\n",
    "        )\n",
    "        detected_languages['comments'] = comment_langs\n",
    "\n",
    "        print(\"  üìä Calculating metrics...\")\n",
    "        metrics = self.calculate_engagement_metrics(video_info)\n",
    "\n",
    "        # Team model predictions with category correction\n",
    "        team_predictions = {}\n",
    "\n",
    "        if self.config.use_category_model:\n",
    "            pred = self.team_models.predict_category(video_info)\n",
    "            if pred:\n",
    "                # üÜï Apply LLM correction if enabled\n",
    "                if self.config.enable_llm_category_correction:\n",
    "                    print(\"  üîç Validating category with LLM...\")\n",
    "                    original, final, corrected = self.team_models.predict_category_with_llm_correction(\n",
    "                        video_info, pred\n",
    "                    )\n",
    "                    team_predictions['category'] = {\n",
    "                        'original': original,\n",
    "                        'final': final,\n",
    "                        'corrected': corrected\n",
    "                    }\n",
    "                    if corrected:\n",
    "                        print(f\"    [Category corrected: {original} ‚Üí {final}]\")\n",
    "                else:\n",
    "                    team_predictions['category'] = pred\n",
    "\n",
    "        if self.config.use_sentiment_model:\n",
    "            sent = self.team_models.analyze_sentiment(comments)\n",
    "            if sent:\n",
    "                team_predictions['sentiment'] = sent\n",
    "\n",
    "        print(\"  üìÑ Formatting report...\")\n",
    "        report = self.format_markdown_report(\n",
    "            video_data, video_summary, reaction_summary,\n",
    "            metrics,\n",
    "            team_predictions if team_predictions else None,\n",
    "            detected_languages\n",
    "        )\n",
    "\n",
    "        print(\"  ‚úÖ Done!\")\n",
    "        return report\n",
    "\n",
    "# Initialize report generator\n",
    "report_generator = ReportGenerator(config, model_manager, preprocessor, team_models)\n",
    "print(\"‚úÖ Enhanced report generator initialized (v2.2)\")\n",
    "print(\"üÜï Two-part summary structure enabled\")\n",
    "print(\"üÜï Majority/minority opinion analysis enabled\")\n",
    "print(\"üÜï LLM category correction enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxuyKFKKFxnE"
   },
   "source": [
    "## üöÄ 9. Run Enhanced Pipeline\n",
    "\n",
    "### What's New:\n",
    "- Processing up to 100 comments per video (configurable)\n",
    "- Two-part structured summaries\n",
    "- Majority/minority opinion separation\n",
    "- LLM-validated categories (if team model enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nAJhsFbsFxnE",
    "outputId": "6d4d3094-31d8-423c-d9fe-75eae4c3a20a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Loading: /content/drive/MyDrive/25_sch/ML/youtube_test_10132154/full_dataset_20251013_215347.json\n",
      "‚úÖ Loaded 20 videos\n",
      "\n",
      "üéØ Processing 3 videos...\n",
      "   (Pipeline v2.2 with enhanced prompts and analysis)\n",
      "   (Processing up to 100 comments per video)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Video 1/3\n",
      "============================================================\n",
      "\n",
      "üé¨ Processing: NMIXX(ÏóîÎØπÏä§) ‚ÄúBlue Valentine‚Äù M/V\n",
      "  üìù Generating video summary...\n",
      "    [Detected input language: English]\n",
      "      [Input tokens: 472]\n",
      "      [Output tokens: 122]\n",
      "    [Output language: English]\n",
      "  üí¨ Generating reaction summary...\n",
      "    [Comment languages (top 20): {'English': 8, 'Korean': 9, 'Japanese': 3}]\n",
      "      [Input tokens: 1787]\n",
      "      [Output tokens: 196]\n",
      "    [Output language: English]\n",
      "  üìä Calculating metrics...\n",
      "  üìÑ Formatting report...\n",
      "  ‚úÖ Done!\n",
      "\n",
      "============================================================\n",
      "Video 2/3\n",
      "============================================================\n",
      "\n",
      "üé¨ Processing: How well do I know ROBLOX | ALBERTGUESSR\n",
      "  üìù Generating video summary...\n",
      "    [Detected input language: English]\n",
      "      [Input tokens: 432]\n",
      "      [Output tokens: 160]\n",
      "    [Output language: English]\n",
      "  üí¨ Generating reaction summary...\n",
      "    [Comment languages (top 20): {'English': 20}]\n",
      "      [Input tokens: 902]\n",
      "      [Output tokens: 184]\n",
      "    [Output language: English]\n",
      "  üìä Calculating metrics...\n",
      "  üìÑ Formatting report...\n",
      "  ‚úÖ Done!\n",
      "\n",
      "============================================================\n",
      "Video 3/3\n",
      "============================================================\n",
      "\n",
      "üé¨ Processing: ÂäáÂ†¥Áâà„Äé„ÉÅ„Çß„É≥„ÇΩ„Éº„Éû„É≥ „É¨„ÇºÁØá„Äè„Ç™„Éº„Éó„Éã„É≥„Ç∞„É†„Éº„Éì„Éº „ÄÄ‰∏ªÈ°åÊ≠åÔºöÁ±≥Ê¥•ÁéÑÂ∏´„ÄåIRIS OUT„Äç‚ÄúChainsaw Man ‚Äì The Movie: Reze Arc‚Äù ‚Äì Opening Movie\n",
      "  üìù Generating video summary...\n",
      "    [Detected input language: Japanese]\n",
      "      [Input tokens: 1628]\n",
      "      [Output tokens: 167]\n",
      "    [Output language: English]\n",
      "  üí¨ Generating reaction summary...\n",
      "    [Comment languages (top 20): {'Japanese': 19, 'English': 1}]\n",
      "      [Input tokens: 1432]\n",
      "      [Output tokens: 192]\n",
      "    [Output language: English]\n",
      "  üìä Calculating metrics...\n",
      "  üìÑ Formatting report...\n",
      "  ‚úÖ Done!\n",
      "\n",
      "============================================================\n",
      "‚úÖ Completed 3/3 videos\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "dataset = data_loader.get_data()\n",
    "\n",
    "# Select videos using config\n",
    "videos_to_process = dataset[:config.num_videos_for_test]\n",
    "\n",
    "print(f\"\\nüéØ Processing {len(videos_to_process)} videos...\")\n",
    "print(f\"   (Pipeline v2.2 with enhanced prompts and analysis)\")\n",
    "print(f\"   (Processing up to {config.max_comments_to_process} comments per video)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate reports\n",
    "reports = []\n",
    "\n",
    "for i, video_data in enumerate(videos_to_process, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Video {i}/{len(videos_to_process)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    try:\n",
    "        report = report_generator.generate_report(video_data)\n",
    "        reports.append({\n",
    "            'video_id': video_data['video_info']['video_id'],\n",
    "            'report': report\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úÖ Completed {len(reports)}/{len(videos_to_process)} videos\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17f5e3RlFxnF"
   },
   "source": [
    "## üìä 10. Display Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EkTmA3RLFxnF",
    "outputId": "3012bd99-6424-4f31-af04-0c180ccb6496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "REPORT 1/3 - Video ID: EmeW6li6bbo\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# YouTube Video Report\n",
       "\n",
       "**Generated**: 2025-12-11 12:22:08\n",
       "**Model**: meta-llama/Llama-3.1-8B-Instruct\n",
       "**Pipeline Version**: 2.2 (Enhanced Prompts & Analysis)\n",
       "\n",
       "---\n",
       "\n",
       "## üìπ Video Information\n",
       "\n",
       "- **Title**: NMIXX(ÏóîÎØπÏä§) ‚ÄúBlue Valentine‚Äù M/V\n",
       "- **Channel**: JYP Entertainment\n",
       "- **Category**: Music\n",
       "- **Published**: 2025-10-13T09:00:02Z\n",
       "- **Duration**: 195 seconds\n",
       "- **Video ID**: `EmeW6li6bbo`\n",
       "- **URL**: https://www.youtube.com/watch?v=EmeW6li6bbo\n",
       "\n",
       "### üåç Detected Languages\n",
       "\n",
       "- **Video content**: English\n",
       "- **Comments**: English: 8, Korean: 9, Japanese: 3\n",
       "- **Report output**: English\n",
       "\n",
       "---\n",
       "\n",
       "## üìä Engagement Metrics\n",
       "\n",
       "| Metric | Value |\n",
       "|--------|-------|\n",
       "| Views | 1,295,943 |\n",
       "| Likes | 66,047 |\n",
       "| Comments | 6,284 |\n",
       "| Engagement Rate | 5.58% |\n",
       "| Like Rate | 5.1% |\n",
       "| Comment Rate | 0.48% |\n",
       "\n",
       "---\n",
       "\n",
       "## üìù Video Summary\n",
       "\n",
       "KEY POINT:\n",
       "The music video for NMIXX's song \"Blue Valentine\" showcases the group's energetic and emotive performance.\n",
       "\n",
       "DETAILED SUMMARY:\n",
       "NMIXX's \"Blue Valentine\" music video primarily focuses on the group's dynamic performance, with a mix of dark and vibrant visuals. The video seems to explore themes of love and relationships, with the group members conveying a range of emotions. Targeting K-pop fans, the video is likely intended to promote the song and the group's upcoming activities. Unfortunately, the description does not provide further context, so some aspects of the video remain unclear.\n",
       "\n",
       "---\n",
       "\n",
       "## üí¨ Audience Reaction Summary\n",
       "\n",
       "**Comments Analyzed**: 20 / 20 (100.0%)\n",
       "\n",
       "KEY POINT:\n",
       "The audience reaction to NMIXX's \"Blue Valentine\" music video is overwhelmingly positive excitement, with fans praising the group's unique concept, music quality, and emotional delivery.\n",
       "\n",
       "DETAILED SUMMARY:\n",
       "The majority of comments express deep admiration for NMIXX's growth and uniqueness, with many fans highlighting the song's nostalgic and dreamy vibe. The emotional delivery of the lyrics and the vocal performances are also widely praised, with some fans even considering this song a highlight of their career. A small minority of comments, mostly in Japanese, focus on the song's catchy melody and NMIXX's stylish vocals. There are also a few comments that appreciate the song's themes of universal love and its avoidance of being consumed by the idol industry. Cultural and language differences are not prominent in this analysis, as the fans' reactions are largely uniform across languages.\n",
       "\n",
       "SENTIMENT BREAKDOWN:\n",
       "Positive: 95%  Negative: 2%  Neutral: 3%\n",
       "\n",
       "Note: This sentiment analysis is based on the top 20 high‚Äëengagement comments and may not fully represent the entire audience.\n",
       "\n",
       "---\n",
       "## üîç Top Comments\n",
       "\n",
       "1. **@kyujified** (806 likes): I get really emotional thinking about how far NMIXX have come. From their debut with O.O, when so many people misunderstood their concept and doubted them, to now, where everyone finally sees their ta...\n",
       "\n",
       "2. **@nothing-mt7kv** (691 likes): ÏôÄ ÏßÑÏã¨ Î™®Îì† Î©¥ÏóêÏÑú Î†àÏ†ÑÎìúÎã§ ÎÖ∏Îûò ÌÄÑÎ¶¨Ìã∞ Î≥¥Ïª¨ Ïª®ÏÖâ ÏóîÎØπÏä§ÎäêÎÇå ÎåÄÏ§ëÏÑ± ÎÆ§ÎπÑ ÏïàÎ¨¥ ÎπÑÏ£ºÏñº Ï†ÑÎ∂Ä ÏôÑÎ≤ΩÌïòÎã§ ÏßÑÏßú ÎÑàÎ¨¥ Ï¢ãÎã§„Ö†„Ö†...\n",
       "\n",
       "3. **@alejandromoreno1111** (599 likes): Congratulations to NMIXX for being the only group to have Lily, Haewon, Bae, Sullyoon, Jiwoo and Kyujin as its members. Total privilege...\n",
       "\n",
       "4. **@Laenyu** (391 likes): ÏÑ†Í≥µÍ∞ú Í≥°Î∂ÄÌÑ∞ ÎÖ∏ÎûòÍ∞Ä ÏßÑÌñâÎêòÎ©¥ÏÑú Í∞ÄÏä¥Ïóê Î≤ÖÏ∞∏Í≥º Í∞êÎèôÏù¥ ÎäêÍª¥Ï°åÏóàÍ≥† Î∏îÎ£® Î∞úÎ†åÌÉÄÏù∏Ïù¥ Í∑∏ Í∏∞Î∂ÑÏùÑ Îòê Îã§Ïãú ÎäêÎÅºÍ≤å Ìï¥Ï§¨Ïùå\n",
       "ÏßÑÏ†ï ÎÖ∏ÎûòÎ•º ÏÇ¨ÎûëÌïòÍ≥† Ï¶êÍ∏∞Îäî ÏÇ¨ÎûåÎì§Ïù¥ Ï°¥Ïû¨ÌïúÎã§Î©¥ Ïù¥ ÎÖ∏ÎûòÎäî ÌïÑÌûà Ïú†ÌñâÌïúÎã§......\n",
       "\n",
       "5. **@rynnieeefairy** (320 likes): this song feels so upbeat and nostalgic!! and like many are saying, their sound/color is so unique, i'm so happy that they're always staying true to their uniqueness!! nmixx and nswer lets make this s...\n",
       "\n",
       "---\n",
       "\n",
       "## üìå Technical Notes\n",
       "\n",
       "- This report was automatically generated using LLM-based multilingual analysis\n",
       "- **Enhanced Prompts (v2.2)**: Two-part summary structure with KEY POINTS and DETAILED ANALYSIS\n",
       "- **Enhanced Comment Analysis**: Majority/minority opinion separation with sentiment breakdown\n",
       "- **LLM Category Validation**: Automated correction of misclassified categories\n",
       "- Input content processed in original language(s) without translation layer\n",
       "- Output language fixed to English for consistency\n",
       "\n",
       "---\n",
       "\n",
       "*Generated by YouTube Report Generator - Phase 2 Full Pipeline v2.2*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "REPORT 2/3 - Video ID: RGbDW-hyxxc\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# YouTube Video Report\n",
       "\n",
       "**Generated**: 2025-12-11 12:22:34\n",
       "**Model**: meta-llama/Llama-3.1-8B-Instruct\n",
       "**Pipeline Version**: 2.2 (Enhanced Prompts & Analysis)\n",
       "\n",
       "---\n",
       "\n",
       "## üìπ Video Information\n",
       "\n",
       "- **Title**: How well do I know ROBLOX | ALBERTGUESSR\n",
       "- **Channel**: Flamingo\n",
       "- **Category**: Gaming\n",
       "- **Published**: 2025-10-13T03:13:19Z\n",
       "- **Duration**: 1630 seconds\n",
       "- **Video ID**: `RGbDW-hyxxc`\n",
       "- **URL**: https://www.youtube.com/watch?v=RGbDW-hyxxc\n",
       "\n",
       "### üåç Detected Languages\n",
       "\n",
       "- **Video content**: English\n",
       "- **Comments**: English: 20\n",
       "- **Report output**: English\n",
       "\n",
       "---\n",
       "\n",
       "## üìä Engagement Metrics\n",
       "\n",
       "| Metric | Value |\n",
       "|--------|-------|\n",
       "| Views | 349,586 |\n",
       "| Likes | 23,507 |\n",
       "| Comments | 2,703 |\n",
       "| Engagement Rate | 7.5% |\n",
       "| Like Rate | 6.72% |\n",
       "| Comment Rate | 0.77% |\n",
       "\n",
       "---\n",
       "\n",
       "## üìù Video Summary\n",
       "\n",
       "KEY POINT:\n",
       "This YouTube video features a gameplay challenge where the host, AlbertGUESSR, tries to guess various Roblox games he is teleported into, with the goal of identifying as many games as possible within a set time limit.\n",
       "\n",
       "DETAILED SUMMARY:\n",
       "The video showcases a mix of easy, medium, hard, and impossible mode games, with links provided to the games in the description. AlbertGUESSR's knowledge of Roblox games is tested through a GeoGuessr-style gameplay experience, where he is randomly placed into different games. The target audience appears to be fans of Roblox and gaming enthusiasts, as the content is centered around guessing and identifying Roblox games. The purpose of the video seems to be entertainment and community engagement, with a dash of friendly competition.\n",
       "\n",
       "---\n",
       "\n",
       "## üí¨ Audience Reaction Summary\n",
       "\n",
       "**Comments Analyzed**: 20 / 20 (100.0%)\n",
       "\n",
       "KEY POINT:\n",
       "The audience is overwhelmingly excited and nostalgic for the ROBLOX series, particularly the return of Kaden.\n",
       "\n",
       "DETAILED SUMMARY:\n",
       "The majority of comments (over 90%) are positive, with viewers expressing their enthusiasm for the series and the return of Kaden. Many fans are thrilled to see their favorite YouTubers reunited and are sharing memories of the old collabs. A small minority of comments (around 5%) express disappointment or sadness about the series' past, but these views are largely drowned out by the excitement. Notably, some fans are also appreciative of Albert's efforts to support smaller creators, as seen in comments praising his collaborations with Flamingo. Overall, the comments showcase a strong sense of community and shared nostalgia among ROBLOX fans.\n",
       "\n",
       "SENTIMENT BREAKDOWN:\n",
       "Positive: 92%  Negative: 4%  Neutral: 4%\n",
       "\n",
       "Note: This sentiment analysis is based on the top 20 high‚Äëengagement comments and may not fully represent the entire audience.\n",
       "\n",
       "---\n",
       "## üîç Top Comments\n",
       "\n",
       "1. **@klippyyyy** (2430 likes): I want a divorce, Albert....\n",
       "\n",
       "2. **@ilikecats382** (2283 likes): Yes we love to see Kaden back...\n",
       "\n",
       "3. **@Emizsocool** (1325 likes): KADEN IS OUT OF PRISON, YAYYYYYYYY...\n",
       "\n",
       "4. **@aster-o5f** (919 likes): ANOTHER 30 MIN VID?? WE ARE BEING BLESSED \"THANK YOU ALBERT\" WE ALL SAY IN UNISON...\n",
       "\n",
       "5. **@Loveforsara** (697 likes): 0:10 KADEN IS BACK??!!! OMG OMGG...\n",
       "\n",
       "---\n",
       "\n",
       "## üìå Technical Notes\n",
       "\n",
       "- This report was automatically generated using LLM-based multilingual analysis\n",
       "- **Enhanced Prompts (v2.2)**: Two-part summary structure with KEY POINTS and DETAILED ANALYSIS\n",
       "- **Enhanced Comment Analysis**: Majority/minority opinion separation with sentiment breakdown\n",
       "- **LLM Category Validation**: Automated correction of misclassified categories\n",
       "- Input content processed in original language(s) without translation layer\n",
       "- Output language fixed to English for consistency\n",
       "\n",
       "---\n",
       "\n",
       "*Generated by YouTube Report Generator - Phase 2 Full Pipeline v2.2*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "REPORT 3/3 - Video ID: ux3QETpLcPs\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# YouTube Video Report\n",
       "\n",
       "**Generated**: 2025-12-11 12:23:02\n",
       "**Model**: meta-llama/Llama-3.1-8B-Instruct\n",
       "**Pipeline Version**: 2.2 (Enhanced Prompts & Analysis)\n",
       "\n",
       "---\n",
       "\n",
       "## üìπ Video Information\n",
       "\n",
       "- **Title**: ÂäáÂ†¥Áâà„Äé„ÉÅ„Çß„É≥„ÇΩ„Éº„Éû„É≥ „É¨„ÇºÁØá„Äè„Ç™„Éº„Éó„Éã„É≥„Ç∞„É†„Éº„Éì„Éº „ÄÄ‰∏ªÈ°åÊ≠åÔºöÁ±≥Ê¥•ÁéÑÂ∏´„ÄåIRIS OUT„Äç‚ÄúChainsaw Man ‚Äì The Movie: Reze Arc‚Äù ‚Äì Opening Movie\n",
       "- **Channel**: Kenshi Yonezu  Á±≥Ê¥•ÁéÑÂ∏´\n",
       "- **Category**: Music\n",
       "- **Published**: 2025-10-07T10:59:56Z\n",
       "- **Duration**: 151 seconds\n",
       "- **Video ID**: `ux3QETpLcPs`\n",
       "- **URL**: https://www.youtube.com/watch?v=ux3QETpLcPs\n",
       "\n",
       "### üåç Detected Languages\n",
       "\n",
       "- **Video content**: Japanese\n",
       "- **Comments**: Japanese: 19, English: 1\n",
       "- **Report output**: English\n",
       "\n",
       "---\n",
       "\n",
       "## üìä Engagement Metrics\n",
       "\n",
       "| Metric | Value |\n",
       "|--------|-------|\n",
       "| Views | 9,096,175 |\n",
       "| Likes | 416,328 |\n",
       "| Comments | 14,691 |\n",
       "| Engagement Rate | 4.74% |\n",
       "| Like Rate | 4.58% |\n",
       "| Comment Rate | 0.16% |\n",
       "\n",
       "---\n",
       "\n",
       "## üìù Video Summary\n",
       "\n",
       "KEY POINT:\n",
       "This video is the opening movie for the theatrical anime adaptation of the popular manga \"Chainsaw Man\" and features the theme song \"IRIS OUT\" by Kenshi Yonezu.\n",
       "\n",
       "DETAILED SUMMARY:\n",
       "The video showcases the main theme of the \"Chainsaw Man\" story, which revolves around the protagonist Denji, a young devil hunter who forms a close bond with a girl named Makima. As Denji's life changes after meeting Makima, the video highlights the story's blend of action, romance, and fantasy elements. The video is likely targeting fans of the original manga series and anime adaptation, as well as new viewers interested in the story's unique blend of genres. The main trailer features a mix of action-packed sequences and emotional moments, setting the tone for the upcoming theatrical anime.\n",
       "\n",
       "---\n",
       "\n",
       "## üí¨ Audience Reaction Summary\n",
       "\n",
       "**Comments Analyzed**: 20 / 20 (100.0%)\n",
       "\n",
       "KEY POINT:\n",
       "The audience reaction is overwhelmingly positive excitement, with fans praising the opening movie's engaging storyline, lovable characters, and impressive visuals.\n",
       "\n",
       "DETAILED SUMMARY:\n",
       "The majority of comments (over 90%) express admiration for the opening movie, highlighting its ability to capture the audience's attention and set the tone for a thrilling story. Fans appreciate the development of the main characters, particularly Denji and Akane, and their relationships with each other and other supporting characters. Many commenters also praise the animation, music, and overall production quality, comparing it to a \"must-watch\" experience. A small minority (around 5%) of comments express enthusiasm for the movie's free availability, but this is not a dominant theme. Notably, some commenters mention the opening's ability to evoke strong emotions, such as happiness and nostalgia.\n",
       "\n",
       "SENTIMENT BREAKDOWN:\n",
       "Positive: 95%  Negative: 2%  Neutral: 3%\n",
       "\n",
       "Note: This sentiment analysis is based on the top 20 high‚Äëengagement comments and may not fully represent the entire audience.\n",
       "\n",
       "---\n",
       "## üîç Top Comments\n",
       "\n",
       "1. **@YAMIGMISAMA** (29539 likes): Êò†ÁîªÈ§®„Åß„Åì„ÅÆ„É†„Éº„Éì„Éº„Å®‰∏ÄÁ∑í„Å´Â§ßÈü≥Èáè„ÅßÊõ≤„ÅåÊµÅ„Çå„ÅüÊôÇ„ÅÆÂπ∏Á¶èÊÑü„Ç®„Ç∞„Åã„Å£„Åü...\n",
       "\n",
       "2. **@summer-xf2zo** (21043 likes): „É¨„ÇºÁ∑®„ÅØ„Éû„Ç∏„Åß„ÄÅOP„Åß„ÄåÂßã„Åæ„Çã„ÅûÔºÅÔºÅ„Äç„Å£„Å¶ÊÑü„Åò„Å¶„ÄÅED„Åß„ÄåÁµÇ„Çè„Å£„Åü......„ÄÇ„Äç„Å£„Å¶ÊÑü„Åò„Çâ„Çå„ÇãÊúÄÈ´ò„ÅÆ‰ΩúÂìÅ„ÄÇ...\n",
       "\n",
       "3. **@Êº¢Ô©Ñ„Éà„É¨„Ç§„É≥** (18128 likes): 1:05 „Åì„Åì„ÅÆ„Éù„ÉÅ„Çø„ÉÄ„É≥„Çπ„Åæ„Åò„ÅßÂèØÊÑõ„Åô„Åé„Çã...\n",
       "\n",
       "4. **@„Å≤„Çç„ÅÆ„Çâ„Åî„Çì** (12483 likes): YouTube„ÅßËÅ¥„Åè„ÅÆ„ÇÇËâØ„ÅÑ„Åë„Å©„ÄÅÊò†ÁîªÈ§®„ÅßËÅ¥„ÅÑ„Åü„Å®„Åç„Åª„Çì„Å®„Å´È≥•ËÇå„Åü„Å£„Åü„ÄÇOPËÅ¥„ÅÑ„Åü„Å†„Åë„ÅßË¶ã„Å´Êù•„Å¶ËâØ„Åã„Å£„Åü„Å£„Å¶„Å™„Å£„Åü...\n",
       "\n",
       "5. **@„Éã„Ç≥„Å°-y6k** (9829 likes): 0:54 2:05„Éú„É≥„ÇÑ„Éê„É≥„Åå„Å™„ÅÑ„ÅÆ„Åæ„Å†ÁîüÊ¥ª„ÅÆ‰∏≠„Å´„É¨„Çº„Åå„ÅÑ„Å™„ÅÑÊÑü„ÅòÂ•Ω„Åç‚Ä¶...\n",
       "\n",
       "---\n",
       "\n",
       "## üìå Technical Notes\n",
       "\n",
       "- This report was automatically generated using LLM-based multilingual analysis\n",
       "- **Enhanced Prompts (v2.2)**: Two-part summary structure with KEY POINTS and DETAILED ANALYSIS\n",
       "- **Enhanced Comment Analysis**: Majority/minority opinion separation with sentiment breakdown\n",
       "- **LLM Category Validation**: Automated correction of misclassified categories\n",
       "- Input content processed in original language(s) without translation layer\n",
       "- Output language fixed to English for consistency\n",
       "\n",
       "---\n",
       "\n",
       "*Generated by YouTube Report Generator - Phase 2 Full Pipeline v2.2*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "for i, report_data in enumerate(reports, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"REPORT {i}/{len(reports)} - Video ID: {report_data['video_id']}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    display(Markdown(report_data['report']))\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22Sxu4s8FxnF"
   },
   "source": [
    "## üìà 11. Language Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9__ExqQFxnG",
    "outputId": "d16dd121-514f-4fb4-d6f1-cf9874b07104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Language Statistics (Enhanced Processing)\n",
      "============================================================\n",
      "\n",
      "üìπ Video Languages:\n",
      "  - English: 2 videos\n",
      "  - Japanese: 1 videos\n",
      "\n",
      "üí¨ Comment Languages (sampled from top comments):\n",
      "  - English: 29 comments\n",
      "  - Korean: 9 comments\n",
      "  - Japanese: 22 comments\n",
      "\n",
      "üéØ Processing Summary:\n",
      "  - Comments per video: up to 100\n",
      "  - Total videos processed: 3\n",
      "  - Output language: English (fixed)\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "stats = report_generator.get_language_statistics()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Language Statistics (Enhanced Processing)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìπ Video Languages:\")\n",
    "for lang, count in stats['video'].items():\n",
    "    print(f\"  - {lang}: {count} videos\")\n",
    "\n",
    "print(\"\\nüí¨ Comment Languages (sampled from top comments):\")\n",
    "for lang, count in stats['comments'].items():\n",
    "    print(f\"  - {lang}: {count} comments\")\n",
    "\n",
    "print(\"\\nüéØ Processing Summary:\")\n",
    "print(f\"  - Comments per video: up to {config.max_comments_to_process}\")\n",
    "print(f\"  - Total videos processed: {len(reports)}\")\n",
    "print(f\"  - Output language: {config.output_language} (fixed)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-CIry2JFxnG"
   },
   "source": [
    "## üíæ 12. Save Reports (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EgNjkYSDFxnG",
    "outputId": "d451154b-416b-4cc9-8e7d-f11c94672030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: reports/report_EmeW6li6bbo_v2.2.md\n",
      "‚úÖ Saved: reports/report_RGbDW-hyxxc_v2.2.md\n",
      "‚úÖ Saved: reports/report_ux3QETpLcPs_v2.2.md\n",
      "\n",
      "‚úÖ Summary saved: reports/summary_20251211_122541_v2.2.json\n",
      "\n",
      "üìÅ All reports saved to: /content/reports\n"
     ]
    }
   ],
   "source": [
    "if config.save_reports:\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "\n",
    "    # Create output directory\n",
    "    output_dir = Path(config.output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Save individual reports\n",
    "    for report_data in reports:\n",
    "        video_id = report_data['video_id']\n",
    "        filepath = output_dir / f\"report_{video_id}_v2.2.md\"\n",
    "\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(report_data['report'])\n",
    "\n",
    "        print(f\"‚úÖ Saved: {filepath}\")\n",
    "\n",
    "    # Save summary\n",
    "    summary_path = output_dir / f\"summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}_v2.2.json\"\n",
    "    summary_data = {\n",
    "        'pipeline_version': '2.2',\n",
    "        'model': config.model_name,\n",
    "        'videos_processed': len(reports),\n",
    "        'max_comments_per_video': config.max_comments_to_process,\n",
    "        'language_stats': stats,\n",
    "        'enhancements': [\n",
    "            'Two-part summary structure',\n",
    "            'Majority/minority opinion analysis',\n",
    "            'Sentiment breakdown integration',\n",
    "            'LLM category correction'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\n‚úÖ Summary saved: {summary_path}\")\n",
    "    print(f\"\\nüìÅ All reports saved to: {output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7D5iw5HwPcI2",
    "outputId": "87c1050f-432d-486f-fbe5-007e8af9a56c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ìè¥ÎçîÍ∞Ä /content/drive/MyDrive/25_sch/ML/results ÏúºÎ°ú Ïù¥ÎèôÎêòÏóàÏäµÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "source = '/content/reports_2512112125'\n",
    "target = '/content/drive/MyDrive/25_sch/ML/results'\n",
    "\n",
    "# ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ± (ÏóÜÏùÑ Í≤ΩÏö∞)\n",
    "os.makedirs(target, exist_ok=True)\n",
    "\n",
    "# Ìè¥Îçî Ïù¥Îèô\n",
    "shutil.move(source, target)\n",
    "print(f\"Ìè¥ÎçîÍ∞Ä {target} ÏúºÎ°ú Ïù¥ÎèôÎêòÏóàÏäµÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkwGj7d5ZET7"
   },
   "source": [
    "## üåü 13. Real-Time YouTube URL Report Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m5VpFzqRZD26",
    "outputId": "24fb220d-0344-4c57-b8fc-e18db4c30309"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù How to Use Real-Time Report Generator:\n",
      "\n",
      "1. Get YouTube Data API Key:\n",
      "   - Visit: https://console.developers.google.com\n",
      "   - Create project and enable YouTube Data API v3\n",
      "   - Create credentials (API Key)\n",
      "\n",
      "2. Set your API key:\n",
      "   YOUR_YOUTUBE_API_KEY = \"paste_your_api_key_here\"\n",
      "\n",
      "3. Generate report:\n",
      "   report = generate_report_from_url(\n",
      "       \"https://www.youtube.com/watch?v=VIDEO_ID\",\n",
      "       YOUR_YOUTUBE_API_KEY,\n",
      "       max_comments=100\n",
      "   )\n",
      "\n",
      "‚ö†Ô∏è  Note: YouTube API has daily quota limits (10,000 units/day)\n",
      "   Each report generation uses approximately 100-150 units\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import time\n",
    "\n",
    "def extract_video_id(url: str) -> str:\n",
    "    \"\"\"Extract video_id from YouTube URL\n",
    "\n",
    "    Supports formats:\n",
    "    - https://www.youtube.com/watch?v=VIDEO_ID\n",
    "    - https://youtu.be/VIDEO_ID\n",
    "    - https://www.youtube.com/embed/VIDEO_ID\n",
    "    \"\"\"\n",
    "    patterns = [\n",
    "        r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*',\n",
    "        r'(?:embed\\/)([0-9A-Za-z_-]{11})',\n",
    "        r'(?:\\/watch\\?v=)([0-9A-Za-z_-]{11})'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, url)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    raise ValueError(\"Invalid YouTube URL format\")\n",
    "\n",
    "def fetch_video_data(youtube, video_id: str, max_results=100) -> Dict:\n",
    "    \"\"\"Fetch video info and comments from YouTube API\n",
    "\n",
    "    Args:\n",
    "        youtube: YouTube API client\n",
    "        video_id: Video ID to fetch\n",
    "        max_results: Maximum number of comments to collect (default: 100)\n",
    "\n",
    "    Returns:\n",
    "        Dict with 'video_info' and 'comments' keys\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch video information\n",
    "        print(f\"  üìπ Fetching video information...\")\n",
    "        video_response = youtube.videos().list(\n",
    "            part='snippet,statistics,contentDetails',\n",
    "            id=video_id\n",
    "        ).execute()\n",
    "\n",
    "        if not video_response['items']:\n",
    "            raise ValueError(f\"Video not found: {video_id}\")\n",
    "\n",
    "        video_item = video_response['items'][0]\n",
    "        video_info = {\n",
    "            'video_id': video_id,\n",
    "            'title': video_item['snippet']['title'],\n",
    "            'channel_title': video_item['snippet']['channelTitle'],\n",
    "            'category_name': video_item['snippet'].get('categoryId', 'N/A'),\n",
    "            'published_at': video_item['snippet']['publishedAt'],\n",
    "            'description': video_item['snippet']['description'],\n",
    "            'view_count': int(video_item['statistics'].get('viewCount', 0)),\n",
    "            'like_count': int(video_item['statistics'].get('likeCount', 0)),\n",
    "            'comment_count': int(video_item['statistics'].get('commentCount', 0)),\n",
    "            'duration': video_item['contentDetails']['duration']\n",
    "        }\n",
    "        print(f\"  ‚úÖ Video: {video_info['title'][:50]}...\")\n",
    "\n",
    "        # Fetch comments (up to max_results)\n",
    "        comments = []\n",
    "        next_page_token = None\n",
    "\n",
    "        print(f\"  üí¨ Fetching comments (max: {max_results})...\")\n",
    "        while len(comments) < max_results:\n",
    "            comment_response = youtube.commentThreads().list(\n",
    "                part='snippet',\n",
    "                videoId=video_id,\n",
    "                maxResults=min(100, max_results - len(comments)),\n",
    "                pageToken=next_page_token\n",
    "            ).execute()\n",
    "\n",
    "            for item in comment_response['items']:\n",
    "                top_comment = item['snippet']['topLevelComment']['snippet']\n",
    "                comments.append({\n",
    "                    'text': top_comment['textDisplay'],\n",
    "                    'like_count': top_comment.get('likeCount', 0),\n",
    "                    'author': top_comment['authorDisplayName']\n",
    "                })\n",
    "\n",
    "            next_page_token = comment_response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break\n",
    "\n",
    "        video_data = {\n",
    "            'video_info': video_info,\n",
    "            'comments': comments[:max_results]\n",
    "        }\n",
    "\n",
    "        print(f\"  ‚úÖ Collected {len(comments)} comments\")\n",
    "        return video_data\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f\"  ‚ùå YouTube API error: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Data collection failed: {e}\")\n",
    "        raise\n",
    "\n",
    "def generate_report_from_url(youtube_url: str, youtube_api_key: str = None,\n",
    "                             max_comments: int = 100) -> Optional[str]:\n",
    "    \"\"\"Generate report from YouTube URL in real-time\n",
    "\n",
    "    Args:\n",
    "        youtube_url: YouTube video URL\n",
    "        youtube_api_key: YouTube Data API key (get from Google Cloud Console)\n",
    "        max_comments: Maximum comments to fetch (default: 100)\n",
    "\n",
    "    Returns:\n",
    "        Generated markdown report or None if failed\n",
    "\n",
    "    Example:\n",
    "        >>> report = generate_report_from_url(\n",
    "        ...     \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\",\n",
    "        ...     YOUR_API_KEY\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üöÄ Real-Time YouTube Report Generation\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Extract Video ID\n",
    "    try:\n",
    "        video_id = extract_video_id(youtube_url)\n",
    "        print(f\"üì∫ Video ID: {video_id}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Initialize YouTube API\n",
    "    if not youtube_api_key:\n",
    "        print(\"‚ö†Ô∏è  Warning: No API key provided\")\n",
    "        print(\"   Get your API key from: https://console.developers.google.com\")\n",
    "        return None\n",
    "\n",
    "    youtube = build('youtube', 'v3', developerKey=youtube_api_key)\n",
    "\n",
    "    try:\n",
    "        # Fetch data from YouTube\n",
    "        print(\"\\nüì• Fetching data from YouTube API...\")\n",
    "        video_data = fetch_video_data(youtube, video_id, max_comments)\n",
    "\n",
    "        # Generate report using existing pipeline\n",
    "        print(\"\\nüîÑ Generating report with LLM pipeline...\")\n",
    "        report = report_generator.generate_report(video_data)\n",
    "\n",
    "        # Display result\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"‚úÖ REPORT GENERATION COMPLETED\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        from IPython.display import display, Markdown\n",
    "        display(Markdown(report))\n",
    "\n",
    "        return report\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Report generation failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# ============================================================\n",
    "# Usage Instructions\n",
    "# ============================================================\n",
    "\n",
    "print(\"\"\"\n",
    "üìù How to Use Real-Time Report Generator:\n",
    "\n",
    "1. Get YouTube Data API Key:\n",
    "   - Visit: https://console.developers.google.com\n",
    "   - Create project and enable YouTube Data API v3\n",
    "   - Create credentials (API Key)\n",
    "\n",
    "2. Set your API key:\n",
    "   YOUR_YOUTUBE_API_KEY = \"paste_your_api_key_here\"\n",
    "\n",
    "3. Generate report:\n",
    "   report = generate_report_from_url(\n",
    "       \"https://www.youtube.com/watch?v=VIDEO_ID\",\n",
    "       YOUR_YOUTUBE_API_KEY,\n",
    "       max_comments=100\n",
    "   )\n",
    "\n",
    "‚ö†Ô∏è  Note: YouTube API has daily quota limits (10,000 units/day)\n",
    "   Each report generation uses approximately 100-150 units\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================\n",
    "# Example Usage (uncomment and add your API key to test)\n",
    "# ============================================================\n",
    "\n",
    "# YOUR_YOUTUBE_API_KEY = \"\"  # Add your API key here\n",
    "#\n",
    "# # Example: Generate report from URL\n",
    "# report = generate_report_from_url(\n",
    "#     \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\",\n",
    "#     YOUR_YOUTUBE_API_KEY,\n",
    "#     max_comments=100\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "uG395QqmZUPo"
   },
   "outputs": [],
   "source": [
    "def generate_report_from_url(youtube_url: str, youtube_api_key: str = None, max_comments=100):\n",
    "    \"\"\"URL ÏûÖÎ†• ‚Üí Ï¶âÏãú Report ÏÉùÏÑ±\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üöÄ Ïã§ÏãúÍ∞Ñ YouTube Report ÏÉùÏÑ±\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Video ID Ï∂îÏ∂ú\n",
    "    video_id = extract_video_id(youtube_url)\n",
    "    print(f\"üì∫ Video ID: {video_id}\")\n",
    "\n",
    "    # YouTube API Ï¥àÍ∏∞Ìôî\n",
    "    if not youtube_api_key:\n",
    "        print(\"‚ö†Ô∏è  API ÌÇ§ ÏóÜÏùå - Îç∞Î™® Îç∞Ïù¥ÌÑ∞Î°ú ÎåÄÏ≤¥\")\n",
    "        return \"YouTube API ÌÇ§Î•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî.\"\n",
    "\n",
    "    youtube = build('youtube', 'v3', developerKey=youtube_api_key)\n",
    "\n",
    "    try:\n",
    "        # Îç∞Ïù¥ÌÑ∞ ÏàòÏßë\n",
    "        video_data = fetch_video_data(youtube, video_id, max_comments)\n",
    "\n",
    "        # Í∏∞Ï°¥ ÌååÏù¥ÌîÑÎùºÏù∏ÏúºÎ°ú Report ÏÉùÏÑ±\n",
    "        report = report_generator.generate_report(video_data)\n",
    "\n",
    "        # Í≤∞Í≥º Ï∂úÎ†•\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"‚úÖ REPORT COMPLETED\")\n",
    "        print(\"=\" * 80)\n",
    "        from IPython.display import display, Markdown\n",
    "        display(Markdown(report))\n",
    "\n",
    "        return report\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Report ÏÉùÏÑ± Ïã§Ìå®: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ktuCEu2BZemv",
    "outputId": "a3c32727-02cc-49f5-a008-fc69a7832b7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üöÄ Ïã§ÏãúÍ∞Ñ YouTube Report ÏÉùÏÑ±\n",
      "================================================================================\n",
      "üì∫ Video ID: dQw4w9WgXcQ\n",
      "  üìπ Fetching video information...\n",
      "  ‚úÖ Video: Rick Astley - Never Gonna Give You Up (Official Vi...\n",
      "  üí¨ Fetching comments (max: 100)...\n",
      "  ‚úÖ Collected 100 comments\n",
      "\n",
      "üé¨ Processing: Rick Astley - Never Gonna Give You Up (Official Video) (4K Remaster)\n",
      "  üìù Generating video summary...\n",
      "    [Detected input language: English]\n",
      "      [Input tokens: 815]\n",
      "      [Output tokens: 147]\n",
      "    [Output language: English]\n",
      "  üí¨ Generating reaction summary...\n",
      "    [Comment languages (top 97): {'English': 97}]\n",
      "      [Input tokens: 2694]\n",
      "      [Output tokens: 220]\n",
      "    [Output language: English]\n",
      "  üìä Calculating metrics...\n",
      "  üìÑ Formatting report...\n",
      "  ‚úÖ Done!\n",
      "\n",
      "================================================================================\n",
      "‚úÖ REPORT COMPLETED\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# YouTube Video Report\n",
       "\n",
       "**Generated**: 2025-12-11 12:50:56\n",
       "**Model**: meta-llama/Llama-3.1-8B-Instruct\n",
       "**Pipeline Version**: 2.2 (Enhanced Prompts & Analysis)\n",
       "\n",
       "---\n",
       "\n",
       "## üìπ Video Information\n",
       "\n",
       "- **Title**: Rick Astley - Never Gonna Give You Up (Official Video) (4K Remaster)\n",
       "- **Channel**: Rick Astley\n",
       "- **Category**: 10\n",
       "- **Published**: 2009-10-25T06:57:33Z\n",
       "- **Duration**: 214 seconds\n",
       "- **Video ID**: `dQw4w9WgXcQ`\n",
       "- **URL**: https://www.youtube.com/watch?v=dQw4w9WgXcQ\n",
       "\n",
       "### üåç Detected Languages\n",
       "\n",
       "- **Video content**: English\n",
       "- **Comments**: English: 97\n",
       "- **Report output**: English\n",
       "\n",
       "---\n",
       "\n",
       "## üìä Engagement Metrics\n",
       "\n",
       "| Metric | Value |\n",
       "|--------|-------|\n",
       "| Views | 1,721,242,047 |\n",
       "| Likes | 18,672,714 |\n",
       "| Comments | 2,408,603 |\n",
       "| Engagement Rate | 1.22% |\n",
       "| Like Rate | 1.08% |\n",
       "| Comment Rate | 0.14% |\n",
       "\n",
       "---\n",
       "\n",
       "## üìù Video Summary\n",
       "\n",
       "KEY POINT:\n",
       "This official music video is a remastered version of Rick Astley's hit song \"Never Gonna Give You Up,\" released in 1987.\n",
       "\n",
       "DETAILED SUMMARY:\n",
       "The video showcases the catchy and upbeat tune, featuring Rick Astley singing and performing the song with his iconic style. The song, written and produced by Stock Aitken and Waterman, was a global success, topping the charts in 25 countries, including the US Billboard Hot 100. The video, directed by Simon West, has become a legendary piece, passing the 1 billion YouTube views milestone in 2021. The song's lyrics, which emphasize commitment and loyalty, have become a classic and are still widely popular today.\n",
       "\n",
       "---\n",
       "\n",
       "## üí¨ Audience Reaction Summary\n",
       "\n",
       "**Comments Analyzed**: 97 / 100 (97.0%)\n",
       "\n",
       "KEY POINT:\n",
       "Overwhelmingly positive excitement and nostalgia dominate the comments, as fans celebrate the iconic song and share their experiences of being \"Rickrolled.\"\n",
       "\n",
       "DETAILED SUMMARY:\n",
       "The majority of comments express enthusiasm and fondness for the song, with many users sharing their personal stories of being \"Rickrolled\" and how it made them laugh or smile. A notable minority of comments, mostly in English, express frustration or annoyance at being misled, but these are largely outweighed by the positive reactions. The comments also reveal a cultural phenomenon, with the term \"Rickroll\" becoming a shared experience and a symbol of internet culture. Language differences are minimal, with English comments making up the majority, but Korean and Japanese comments also express similar sentiments of nostalgia and excitement. Code-switching comments, such as those in Korean and English, demonstrate the fluidity of language in online communities.\n",
       "\n",
       "SENTIMENT BREAKDOWN:\n",
       "Positive: 85%  Negative: 10%  Neutral: 5%\n",
       "\n",
       "(Exact percentages might vary based on manual sentiment analysis, but this gives a general idea of the sentiment distribution.)\n",
       "\n",
       "---\n",
       "## üîç Top Comments\n",
       "\n",
       "1. **@YouTube** (145745 likes): can confirm: he never gave us up...\n",
       "\n",
       "2. **@Tr·∫ßnB·∫£oVinh-l6p** (8 likes): I don&#39;t play this song to get rickrolled, I play this song to enjoy it...\n",
       "\n",
       "3. **@Flutters1211** (5 likes): ‚ÄúAs long as the trolls never stop trolling, the Rick will never stop rolling.‚Äù<br>- cotter548...\n",
       "\n",
       "4. **@EviKrimson** (4 likes): Well this is not the link for free bitcoin...\n",
       "\n",
       "5. **@gaming777official-army** (3 likes): Anyone in 2026üëâüëà...\n",
       "\n",
       "---\n",
       "\n",
       "## üìå Technical Notes\n",
       "\n",
       "- This report was automatically generated using LLM-based multilingual analysis\n",
       "- **Enhanced Prompts (v2.2)**: Two-part summary structure with KEY POINTS and DETAILED ANALYSIS\n",
       "- **Enhanced Comment Analysis**: Majority/minority opinion separation with sentiment breakdown\n",
       "- **LLM Category Validation**: Automated correction of misclassified categories\n",
       "- Input content processed in original language(s) without translation layer\n",
       "- Output language fixed to English for consistency\n",
       "\n",
       "---\n",
       "\n",
       "*Generated by YouTube Report Generator - Phase 2 Full Pipeline v2.2*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================\n",
    "# ÏÇ¨Ïö©Î≤ï (API ÌÇ§ ÏûÖÎ†• ÌõÑ ÏÇ¨Ïö©)\n",
    "# ====================\n",
    "YOUR_YOUTUBE_API_KEY = \"\"  # https://console.developers.google.comÏóêÏÑú Î∞úÍ∏â\n",
    "\n",
    "# ÏÇ¨Ïö© ÏòàÏãú\n",
    "report = generate_report_from_url(\n",
    "    \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\",\n",
    "    YOUR_YOUTUBE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3OFe_BnFxnH"
   },
   "source": [
    "## üéì Summary of Improvements (v2.2)\n",
    "\n",
    "### 1Ô∏è‚É£ Summary Prompt Tuning\n",
    "- ‚úÖ **Two-Part Structure**: KEY POINT (1-2 sentences) + DETAILED SUMMARY (3-5 sentences)\n",
    "- ‚úÖ **Improved Scannability**: Users can quickly grasp main points\n",
    "- ‚úÖ **Better LLM Output Quality**: Structured format reduces verbosity\n",
    "\n",
    "### 2Ô∏è‚É£ Enhanced Comment Analysis\n",
    "- ‚úÖ **Increased Comment Processing**: 50 ‚Üí 100 comments (configurable)\n",
    "- ‚úÖ **Majority/Minority Separation**: Distinguishes 80%+ views from outliers\n",
    "- ‚úÖ **Sentiment Breakdown**: Explicit percentages (Positive/Negative/Neutral)\n",
    "- ‚úÖ **Outlier Filtering**: Ignores absurd comments (<5%)\n",
    "\n",
    "### 3Ô∏è‚É£ LLM Category Correction\n",
    "- ‚úÖ **Automated Validation**: LLM reviews model predictions\n",
    "- ‚úÖ **Correction Tracking**: Shows original ‚Üí final category if corrected\n",
    "- ‚úÖ **Configurable**: Can be enabled/disabled in config\n",
    "\n",
    "### 4Ô∏è‚É£ Report Format Improvements\n",
    "- ‚úÖ **Structured Sections**: Clear separation of KEY POINTS and DETAILED ANALYSIS\n",
    "- ‚úÖ **Enhanced Metrics**: Shows comments analyzed vs total\n",
    "- ‚úÖ **Category Status**: Displays validation/correction status\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Next Steps\n",
    "\n",
    "### Immediate Testing\n",
    "1. Run on test videos and evaluate quality improvements\n",
    "2. Compare v2.1 vs v2.2 outputs side-by-side\n",
    "3. Gather feedback on new two-part structure\n",
    "\n",
    "### Future Enhancements (Not Implemented)\n",
    "- Token efficiency optimization (dynamic `max_new_tokens`)\n",
    "- Quality gate with regeneration for poor summaries\n",
    "- Multi-GPU support for faster processing\n",
    "- Real-time monitoring with WandB/Prometheus\n",
    "\n",
    "---\n",
    "\n",
    "*Pipeline v2.2 - Enhanced Prompts & Analysis*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
