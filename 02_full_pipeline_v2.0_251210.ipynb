{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Overview\n",
    "\n",
    "Phase 1ì˜ ê°œì„  ë²„ì „ìœ¼ë¡œ, ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” ê°œì„ ì‚¬í•­ì„ í¬í•¨í•©ë‹ˆë‹¤:\n",
    "\n",
    "### Key Improvements\n",
    "- âœ… **Multilingual Support**: Llama-3.1-8B native multilingual understanding\n",
    "- âœ… **Fixed English Output**: All reports in English regardless of input language\n",
    "- âœ… **Code-switching Handling**: Understands mixed-language content naturally\n",
    "- âœ… **Modular Design**: ëª¨ë¸, í”„ë¡¬í”„íŠ¸, ì „ì²˜ë¦¬ ëª¨ë“ˆí™”\n",
    "- âœ… **Extensible Architecture**: Team model í†µí•© ì¤€ë¹„\n",
    "- âœ… **Better Preprocessing**: URL ì œê±°, ì–¸ì–´ ê°ì§€\n",
    "\n",
    "### Multilingual Processing\n",
    "- **Input**: Korean (í•œê¸€), English, Japanese (æ—¥æœ¬èª), Mixed languages\n",
    "- **Processing**: LLM native understanding (no translation layer)\n",
    "- **Output**: English (fixed)\n",
    "\n",
    "### Expected Quality\n",
    "- Korean input â†’ English output: **7-9/10**\n",
    "- English input â†’ English output: **8-9/10**\n",
    "- Mixed language input â†’ English output: **7-8/10**\n",
    "- Japanese input â†’ English output: **7-8/10**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers accelerate bitsandbytes torch\n",
    "!pip install -q langdetect isodate\n",
    "!pip install -q google-api-python-client  # For YouTube API (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import torch\n",
    "import isodate\n",
    "from langdetect import detect, LangDetectException\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ 2. Configuration\n",
    "\n",
    "ëª¨ë“  ì„¤ì •ì„ ì—¬ê¸°ì„œ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PipelineConfig:\n",
    "    \"\"\"ì „ì²´ íŒŒì´í”„ë¼ì¸ ì„¤ì •\"\"\"\n",
    "    \n",
    "    # Model Configuration\n",
    "    model_name: str = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "    use_4bit: bool = True\n",
    "    max_new_tokens: int = 512\n",
    "    temperature: float = 0.7\n",
    "    top_p: float = 0.9\n",
    "    \n",
    "    # Data Configuration\n",
    "    use_youtube_api: bool = False\n",
    "    youtube_api_key: Optional[str] = None\n",
    "    data_path: str = \"full_dataset_20251013_215347.json\"\n",
    "    \n",
    "    # Processing Configuration\n",
    "    max_description_length: int = 2000\n",
    "    max_comments_to_process: int = 50\n",
    "    min_comment_length: int = 10\n",
    "    remove_urls: bool = True\n",
    "    detect_language: bool = True\n",
    "    \n",
    "    # Multilingual Configuration\n",
    "    output_language: str = \"English\"\n",
    "    multilingual_understanding: bool = True\n",
    "    \n",
    "    # Experimental Configuration (NEW)\n",
    "    num_videos_for_test: int = 3  # Number of videos to process in test mode\n",
    "    enable_detailed_logging: bool = True  # Detailed logs for experiments\n",
    "    log_token_counts: bool = True  # Log token usage for analysis\n",
    "    \n",
    "    # Team Model Integration\n",
    "    use_category_model: bool = False\n",
    "    use_sentiment_model: bool = False\n",
    "    category_model_path: Optional[str] = None\n",
    "    sentiment_model_path: Optional[str] = None\n",
    "    \n",
    "    # Output Configuration\n",
    "    output_format: str = \"markdown\"\n",
    "    save_reports: bool = True\n",
    "    output_dir: str = \"reports\"\n",
    "\n",
    "# Create configuration\n",
    "config = PipelineConfig(\n",
    "    model_name=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    use_4bit=True,\n",
    "    use_youtube_api=False,\n",
    "    data_path=\"full_dataset_20251013_215347.json\",\n",
    "    output_language=\"English\",\n",
    "    multilingual_understanding=True,\n",
    "    num_videos_for_test=3,  # NEW: Configurable test size\n",
    "    enable_detailed_logging=True  # NEW: Enable detailed logs\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Pipeline Configuration\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {config.model_name}\")\n",
    "print(f\"4-bit: {config.use_4bit}\")\n",
    "print(f\"Temperature: {config.temperature}\")\n",
    "print(f\"Output Language: {config.output_language}\")\n",
    "print(f\"Multilingual Understanding: {config.multilingual_understanding}\")\n",
    "print(f\"Test Videos: {config.num_videos_for_test}\")\n",
    "print(f\"Detailed Logging: {config.enable_detailed_logging}\")\n",
    "print(f\"YouTube API: {config.use_youtube_api}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§© 3. Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptTemplates:\n",
    "    \"\"\"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê´€ë¦¬ (Multilingual Native)\"\"\"\n",
    "    \n",
    "    # ===== Video Summary Prompts =====\n",
    "    VIDEO_SUMMARY_SYSTEM = \"\"\"You are an expert multilingual content analyst specializing in YouTube video analysis.\n",
    "Your task is to understand content in ANY language (Korean, English, Japanese, or mixed) and create summaries in English.\n",
    "You have native-level understanding of multiple languages and can capture nuances across different cultures.\n",
    "Focus on accuracy and avoid hallucinations.\"\"\"\n",
    "    \n",
    "    VIDEO_SUMMARY_USER = \"\"\"Analyze this YouTube video and create a summary.\n",
    "\n",
    "Video Information:\n",
    "- Title: {title}\n",
    "- Description: {description}\n",
    "- Category: {category}\n",
    "- Duration: {duration} seconds\n",
    "- Channel: {channel}\n",
    "\n",
    "Context:\n",
    "The title and description may be in Korean (í•œê¸€), English, Japanese (æ—¥æœ¬èª), or mixed languages.\n",
    "Please understand the content in its original language(s) and provide your analysis.\n",
    "\n",
    "Instructions:\n",
    "1. Read and comprehend the content regardless of the language(s) used\n",
    "2. Understand cultural context and nuances in the original language\n",
    "3. Write a 3-5 sentence summary in ENGLISH\n",
    "4. Capture the key points, main theme, and purpose of the video\n",
    "5. Be accurate - do NOT make up information or misinterpret due to language barriers\n",
    "6. If description is minimal, acknowledge this limitation\n",
    "\n",
    "Summary (in English):\"\"\"\n",
    "    \n",
    "    # ===== Reaction Summary Prompts =====\n",
    "    REACTION_SUMMARY_SYSTEM = \"\"\"You are an expert in multilingual social media sentiment analysis.\n",
    "You can understand and analyze comments in Korean (í•œê¸€), English, Japanese (æ—¥æœ¬èª), and mixed languages.\n",
    "Your task is to capture audience reactions across all language communities and summarize in English.\"\"\"\n",
    "    \n",
    "    REACTION_SUMMARY_USER = \"\"\"Analyze these YouTube comments and summarize the audience reaction.\n",
    "\n",
    "Video: {title}\n",
    "\n",
    "Audience Comments:\n",
    "{comments}\n",
    "\n",
    "Context:\n",
    "These comments are from a multilingual audience and may include:\n",
    "- Korean (í•œê¸€) comments\n",
    "- English comments\n",
    "- Japanese (æ—¥æœ¬èª) comments\n",
    "- Mixed-language comments (e.g., \"ì´ ë…¸ë˜ ì§„ì§œ beautifulí•˜ë‹¤\" - Korean + English in one comment)\n",
    "- Code-switching between languages\n",
    "\n",
    "Your Task:\n",
    "Please analyze ALL comments by:\n",
    "1. Reading and understanding each comment in its original language(s)\n",
    "2. For mixed-language comments, understanding the complete meaning and emotional tone\n",
    "3. Identifying sentiment patterns (positive/negative/neutral) across all language groups\n",
    "4. Finding common themes and topics that appear across different languages\n",
    "5. Noting any cultural references or language-specific expressions\n",
    "\n",
    "Instructions:\n",
    "1. Comprehend ALL comments regardless of language\n",
    "2. Identify overall sentiment (positive, negative, or mixed)\n",
    "3. Highlight common themes that appear across language communities\n",
    "4. Mention notable reactions or insightful comments\n",
    "5. Write a 3-5 sentence summary in ENGLISH\n",
    "6. Be objective and balanced in capturing diverse reactions\n",
    "7. If different language communities show different reactions, mention this\n",
    "\n",
    "Audience Reaction Summary (in English):\"\"\"\n",
    "    \n",
    "    CUSTOM_PROMPT = None\n",
    "    \n",
    "    @classmethod\n",
    "    def get_video_summary_prompt(cls, video_info: Dict) -> List[Dict]:\n",
    "        \"\"\"Generate video summary prompt (language-agnostic)\"\"\"\n",
    "        if cls.CUSTOM_PROMPT:\n",
    "            return cls.CUSTOM_PROMPT\n",
    "        \n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": cls.VIDEO_SUMMARY_SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": cls.VIDEO_SUMMARY_USER.format(\n",
    "                title=video_info.get('title', 'N/A'),\n",
    "                description=video_info.get('description', 'N/A')[:2000],\n",
    "                category=video_info.get('category_name', 'N/A'),\n",
    "                duration=video_info.get('duration_seconds', 'N/A'),\n",
    "                channel=video_info.get('channel_title', 'N/A')\n",
    "            )}\n",
    "        ]\n",
    "    \n",
    "    @classmethod\n",
    "    def get_reaction_summary_prompt(cls, title: str, comments: str) -> List[Dict]:\n",
    "        \"\"\"Generate reaction summary prompt (language-agnostic)\"\"\"\n",
    "        if cls.CUSTOM_PROMPT:\n",
    "            return cls.CUSTOM_PROMPT\n",
    "        \n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": cls.REACTION_SUMMARY_SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": cls.REACTION_SUMMARY_USER.format(\n",
    "                title=title,\n",
    "                comments=comments\n",
    "            )}\n",
    "        ]\n",
    "\n",
    "print(\"âœ… Multilingual prompt templates loaded\")\n",
    "print(\"ğŸ“ Output language: English (fixed)\")\n",
    "print(\"ğŸŒ Input languages: Korean, English, Japanese, Mixed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸŒ Multilingual Processing Strategy\n",
    "\n",
    "**Approach**: LLM Native Multilingual Understanding\n",
    "\n",
    "**How it works:**\n",
    "1. **Input**: Content in ANY language (Korean, English, Japanese, Mixed)\n",
    "2. **Processing**: Llama-3.1-8B understands content in original language(s)\n",
    "3. **Output**: Summary always in English\n",
    "\n",
    "**Examples:**\n",
    "```\n",
    "Input:  \"NMIXX(ì—”ë¯¹ìŠ¤) 'Blue Valentine' M/V\"\n",
    "Output: \"This is NMIXX's music video for 'Blue Valentine'...\"\n",
    "\n",
    "Input:  \"ì´ ë…¸ë˜ ì§„ì§œ ì¢‹ë‹¤ I love it so much\"\n",
    "Output: \"Positive reaction praising the song...\"\n",
    "\n",
    "Input:  \"ã“ã®æ›²æœ€é«˜ï¼choreography ã‚‚ great\"\n",
    "Output: \"Enthusiastic praise for the song and choreography...\"\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- âœ… No translation layer needed\n",
    "- âœ… Preserves cultural context and nuances\n",
    "- âœ… Handles code-switching naturally\n",
    "- âœ… Fast and efficient (single LLM call)\n",
    "- âœ… Consistent English output for all reports\n",
    "\n",
    "**Language Detection:**\n",
    "- Still performed for logging/debugging\n",
    "- Helps monitor language distribution\n",
    "- Not used for prompt selection (English output always)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ 4. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    \"\"\"í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "        self.url_pattern = re.compile(r'http[s]?://\\S+')\n",
    "    \n",
    "    def remove_urls(self, text: str) -> str:\n",
    "        return self.url_pattern.sub('', text)\n",
    "    \n",
    "    def detect_language(self, text: str) -> str:\n",
    "        try:\n",
    "            lang = detect(text)\n",
    "            lang_map = {'ko': 'Korean', 'en': 'English', 'ja': 'Japanese'}\n",
    "            return lang_map.get(lang, 'English')\n",
    "        except:\n",
    "            return 'English'\n",
    "    \n",
    "    def clean_description(self, description: str) -> str:\n",
    "        if not description:\n",
    "            return \"No description available.\"\n",
    "        if self.config.remove_urls:\n",
    "            description = self.remove_urls(description)\n",
    "        description = ' '.join(description.split())\n",
    "        if len(description) > self.config.max_description_length:\n",
    "            description = description[:self.config.max_description_length] + \"...\"\n",
    "        if len(description.strip()) < 20:\n",
    "            return \"Minimal description available.\"\n",
    "        return description\n",
    "    \n",
    "    def filter_comments(self, comments: List[Dict]) -> List[Dict]:\n",
    "        filtered = [c for c in comments if len(c.get('text', '')) >= self.config.min_comment_length]\n",
    "        filtered.sort(key=lambda x: x.get('like_count', 0), reverse=True)\n",
    "        return filtered[:self.config.max_comments_to_process]\n",
    "    \n",
    "    def format_comments_for_prompt(self, comments: List[Dict]) -> str:\n",
    "        if not comments:\n",
    "            return \"No comments available.\"\n",
    "        formatted = []\n",
    "        for i, comment in enumerate(comments, 1):\n",
    "            text = comment.get('text', '')\n",
    "            likes = comment.get('like_count', 0)\n",
    "            if self.config.remove_urls:\n",
    "                text = self.remove_urls(text)\n",
    "            formatted.append(f\"{i}. [{likes} likes] {text}\")\n",
    "        return \"\\n\".join(formatted)\n",
    "    \n",
    "    def parse_duration(self, duration_str: str) -> int:\n",
    "        try:\n",
    "            duration = isodate.parse_duration(duration_str)\n",
    "            return int(duration.total_seconds())\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "preprocessor = TextPreprocessor(config)\n",
    "print(\"âœ… Text preprocessor initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– 5. Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManager:\n",
    "    \"\"\"LLM ëª¨ë¸ ê´€ë¦¬ (Enhanced with explicit chat template)\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.pipe = None\n",
    "    \n",
    "    def load_model(self):\n",
    "        print(f\"\\nğŸ”„ Loading: {self.config.model_name}\")\n",
    "        print(f\"âš™ï¸ 4-bit: {self.config.use_4bit}\")\n",
    "        \n",
    "        # Tokenizer\n",
    "        print(\"Loading tokenizer...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            self.config.model_name, trust_remote_code=True\n",
    "        )\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Quantization config\n",
    "        if self.config.use_4bit:\n",
    "            quantization_config = BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_compute_dtype=torch.float16,\n",
    "                bnb_4bit_quant_type=\"nf4\",\n",
    "                bnb_4bit_use_double_quant=True\n",
    "            )\n",
    "        else:\n",
    "            quantization_config = None\n",
    "        \n",
    "        # Model\n",
    "        print(\"Loading model...\")\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.config.model_name,\n",
    "            quantization_config=quantization_config,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=torch.float16 if not self.config.use_4bit else None\n",
    "        )\n",
    "        \n",
    "        # Pipeline\n",
    "        print(\"Creating pipeline...\")\n",
    "        self.pipe = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_new_tokens=self.config.max_new_tokens,\n",
    "            temperature=self.config.temperature,\n",
    "            top_p=self.config.top_p,\n",
    "            do_sample=True,\n",
    "            pad_token_id=self.tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… Model loaded!\")\n",
    "        if self.config.enable_detailed_logging:\n",
    "            print(f\"ğŸ“Š Model parameters: ~{self.model.num_parameters() / 1e9:.1f}B\")\n",
    "    \n",
    "    def generate(self, messages: List[Dict]) -> str:\n",
    "        \"\"\"Generate text with explicit chat template and detailed logging\"\"\"\n",
    "        if self.pipe is None:\n",
    "            raise RuntimeError(\"Model not loaded. Call load_model() first.\")\n",
    "        \n",
    "        try:\n",
    "            # Apply chat template explicitly (for reproducibility)\n",
    "            if hasattr(self.tokenizer, 'apply_chat_template'):\n",
    "                prompt_text = self.tokenizer.apply_chat_template(\n",
    "                    messages,\n",
    "                    tokenize=False,\n",
    "                    add_generation_prompt=True\n",
    "                )\n",
    "                \n",
    "                # Log token counts if enabled\n",
    "                if self.config.log_token_counts:\n",
    "                    input_tokens = len(self.tokenizer.encode(prompt_text))\n",
    "                    if self.config.enable_detailed_logging:\n",
    "                        print(f\"      [Input tokens: {input_tokens}]\")\n",
    "                \n",
    "                # Generate\n",
    "                outputs = self.pipe(messages)\n",
    "            else:\n",
    "                # Fallback for models without chat template\n",
    "                outputs = self.pipe(messages)\n",
    "            \n",
    "            # Extract generated text\n",
    "            generated_text = outputs[0][\"generated_text\"]\n",
    "            \n",
    "            if isinstance(generated_text, list):\n",
    "                # Chat format output\n",
    "                result = generated_text[-1][\"content\"]\n",
    "            else:\n",
    "                # String output\n",
    "                result = generated_text\n",
    "            \n",
    "            # Log output token count\n",
    "            if self.config.log_token_counts:\n",
    "                output_tokens = len(self.tokenizer.encode(result))\n",
    "                if self.config.enable_detailed_logging:\n",
    "                    print(f\"      [Output tokens: {output_tokens}]\")\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Enhanced error logging\n",
    "            print(f\"\\nâŒ Generation Error:\")\n",
    "            print(f\"   Error type: {type(e).__name__}\")\n",
    "            print(f\"   Error message: {str(e)}\")\n",
    "            print(f\"   Messages length: {len(messages)}\")\n",
    "            \n",
    "            if self.config.enable_detailed_logging:\n",
    "                # Log message content for debugging\n",
    "                total_chars = sum(len(m.get('content', '')) for m in messages)\n",
    "                print(f\"   Total message chars: {total_chars}\")\n",
    "                print(f\"   System prompt length: {len(messages[0].get('content', ''))} chars\")\n",
    "                print(f\"   User prompt length: {len(messages[1].get('content', ''))} chars\")\n",
    "            \n",
    "            raise\n",
    "\n",
    "model_manager = ModelManager(config)\n",
    "model_manager.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”Œ 6. Team Model Integration (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeamModelIntegration:\n",
    "    \"\"\"íŒ€ ëª¨ë¸ í†µí•© ì¸í„°í˜ì´ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "        self.category_model = None\n",
    "        self.sentiment_model = None\n",
    "    \n",
    "    def load_category_model(self):\n",
    "        if not self.config.use_category_model:\n",
    "            return\n",
    "        # TODO: íŒ€ì› êµ¬í˜„\n",
    "        print(\"âš ï¸ Category model not implemented yet\")\n",
    "    \n",
    "    def load_sentiment_model(self):\n",
    "        if not self.config.use_sentiment_model:\n",
    "            return\n",
    "        # TODO: íŒ€ì› êµ¬í˜„\n",
    "        print(\"âš ï¸ Sentiment model not implemented yet\")\n",
    "    \n",
    "    def predict_category(self, video_info: Dict) -> Optional[str]:\n",
    "        if not self.config.use_category_model or self.category_model is None:\n",
    "            return None\n",
    "        # TODO: ëª¨ë¸ inference\n",
    "        return None\n",
    "    \n",
    "    def analyze_sentiment(self, comments: List[Dict]) -> Optional[Dict]:\n",
    "        if not self.config.use_sentiment_model or self.sentiment_model is None:\n",
    "            return None\n",
    "        # TODO: ëª¨ë¸ inference\n",
    "        return None\n",
    "\n",
    "team_models = TeamModelIntegration(config)\n",
    "team_models.load_category_model()\n",
    "team_models.load_sentiment_model()\n",
    "print(\"âœ… Team model interface ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ 7. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def load_from_file(self, file_path: str) -> List[Dict]:\n",
    "        print(f\"\\nğŸ“‚ Loading: {file_path}\")\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"âœ… Loaded {len(data)} videos\")\n",
    "        return data\n",
    "    \n",
    "    def get_data(self) -> List[Dict]:\n",
    "        if self.config.use_youtube_api:\n",
    "            raise NotImplementedError(\"YouTube API not implemented yet\")\n",
    "        return self.load_from_file(self.config.data_path)\n",
    "\n",
    "data_loader = DataLoader(config)\n",
    "print(\"âœ… Data loader ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¬ 8. Report Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportGenerator:\n",
    "    \"\"\"Enhanced report generator with detailed logging\"\"\"\n",
    "    \n",
    "    def __init__(self, config, model_manager, preprocessor, team_models):\n",
    "        self.config = config\n",
    "        self.model_manager = model_manager\n",
    "        self.preprocessor = preprocessor\n",
    "        self.team_models = team_models\n",
    "    \n",
    "    def generate_video_summary(self, video_info: Dict) -> Tuple[str, str]:\n",
    "        \"\"\"Generate video summary (returns summary and detected language)\"\"\"\n",
    "        # Preprocess\n",
    "        video_info['description'] = self.preprocessor.clean_description(\n",
    "            video_info.get('description', '')\n",
    "        )\n",
    "        video_info['duration_seconds'] = self.preprocessor.parse_duration(\n",
    "            video_info.get('duration', 'PT0S')\n",
    "        )\n",
    "        \n",
    "        # Detect language for logging\n",
    "        detected_lang = 'Unknown'\n",
    "        if self.config.detect_language:\n",
    "            detected_lang = self.preprocessor.detect_language(\n",
    "                video_info.get('title', '') + ' ' + \n",
    "                video_info.get('description', '')[:500]\n",
    "            )\n",
    "            if self.config.enable_detailed_logging:\n",
    "                print(f\"    [Detected input language: {detected_lang}]\")\n",
    "        \n",
    "        # Generate prompt\n",
    "        messages = PromptTemplates.get_video_summary_prompt(video_info)\n",
    "        \n",
    "        # Generate summary\n",
    "        try:\n",
    "            summary = self.model_manager.generate(messages)\n",
    "            if self.config.enable_detailed_logging:\n",
    "                print(f\"    [Output language: {self.config.output_language}]\")\n",
    "            return summary.strip(), detected_lang\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Video summary error: {e}\")\n",
    "            return \"Summary generation failed.\", detected_lang\n",
    "    \n",
    "    def generate_reaction_summary(self, title: str, comments: List[Dict]) -> Tuple[str, str]:\n",
    "        \"\"\"Generate reaction summary (returns summary and language distribution)\"\"\"\n",
    "        # Filter and format comments\n",
    "        filtered_comments = self.preprocessor.filter_comments(comments)\n",
    "        \n",
    "        if not filtered_comments:\n",
    "            return \"No comments available.\", \"N/A\"\n",
    "        \n",
    "        comments_text = self.preprocessor.format_comments_for_prompt(filtered_comments)\n",
    "        \n",
    "        # Detect language distribution\n",
    "        lang_distribution = \"N/A\"\n",
    "        if self.config.detect_language:\n",
    "            sample_texts = [c.get('text', '')[:100] for c in filtered_comments[:10]]\n",
    "            langs = [self.preprocessor.detect_language(t) for t in sample_texts if t]\n",
    "            \n",
    "            if langs:\n",
    "                lang_dist = {}\n",
    "                for lang in langs:\n",
    "                    lang_dist[lang] = lang_dist.get(lang, 0) + 1\n",
    "                lang_distribution = ', '.join([f\"{k}: {v}\" for k, v in lang_dist.items()])\n",
    "                \n",
    "                if self.config.enable_detailed_logging:\n",
    "                    print(f\"    [Comment languages: {lang_dist}]\")\n",
    "        \n",
    "        # Generate prompt\n",
    "        messages = PromptTemplates.get_reaction_summary_prompt(title, comments_text)\n",
    "        \n",
    "        # Generate summary\n",
    "        try:\n",
    "            summary = self.model_manager.generate(messages)\n",
    "            if self.config.enable_detailed_logging:\n",
    "                print(f\"    [Output language: {self.config.output_language}]\")\n",
    "            return summary.strip(), lang_distribution\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Reaction summary error: {e}\")\n",
    "            return \"Reaction summary generation failed.\", lang_distribution\n",
    "    \n",
    "    def calculate_engagement_metrics(self, video_info: Dict) -> Dict:\n",
    "        \"\"\"Calculate engagement metrics\"\"\"\n",
    "        views = video_info.get('view_count', 0)\n",
    "        likes = video_info.get('like_count', 0)\n",
    "        comments = video_info.get('comment_count', 0)\n",
    "        \n",
    "        engagement_rate = ((likes + comments) / views * 100) if views > 0 else 0\n",
    "        like_rate = (likes / views * 100) if views > 0 else 0\n",
    "        comment_rate = (comments / views * 100) if views > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'views': views,\n",
    "            'likes': likes,\n",
    "            'comments': comments,\n",
    "            'engagement_rate': round(engagement_rate, 2),\n",
    "            'like_rate': round(like_rate, 2),\n",
    "            'comment_rate': round(comment_rate, 2)\n",
    "        }\n",
    "\n",
    "print(\"âœ… Report generator class defined (enhanced with language tracking)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_markdown_report(self, video_data: Dict, video_summary: str, \n",
    "                           reaction_summary: str, metrics: Dict,\n",
    "                           team_predictions: Dict = None,\n",
    "                           detected_languages: Dict = None) -> str:  # NEW parameter\n",
    "    \"\"\"Format markdown report with language detection info\"\"\"\n",
    "    video_info = video_data['video_info']\n",
    "    comments = video_data.get('comments', [])\n",
    "    \n",
    "    report = f\"\"\"# YouTube Video Report\n",
    "\n",
    "**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "**Model**: {self.config.model_name}\n",
    "**Pipeline Version**: 2.1 (Multilingual Native)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“¹ Video Information\n",
    "\n",
    "- **Title**: {video_info.get('title', 'N/A')}\n",
    "- **Channel**: {video_info.get('channel_title', 'N/A')}\n",
    "- **Category**: {video_info.get('category_name', 'N/A')}\n",
    "- **Published**: {video_info.get('published_at', 'N/A')}\n",
    "- **Duration**: {self.preprocessor.parse_duration(video_info.get('duration', 'PT0S'))} seconds\n",
    "- **Video ID**: `{video_info.get('video_id', 'N/A')}`\n",
    "- **URL**: https://www.youtube.com/watch?v={video_info.get('video_id', '')}\n",
    "\"\"\"\n",
    "    \n",
    "    # Add language detection info (NEW)\n",
    "    if detected_languages and self.config.enable_detailed_logging:\n",
    "        report += \"\\n### ğŸŒ Detected Languages\\n\\n\"\n",
    "        if 'video' in detected_languages:\n",
    "            report += f\"- **Video content**: {detected_languages['video']}\\n\"\n",
    "        if 'comments' in detected_languages:\n",
    "            report += f\"- **Comments**: {detected_languages['comments']}\\n\"\n",
    "        report += f\"- **Report output**: {self.config.output_language}\\n\"\n",
    "    \n",
    "    report += \"\\n---\\n\\n\"\n",
    "    \n",
    "    report += f\"\"\"## ğŸ“Š Engagement Metrics\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Views | {metrics['views']:,} |\n",
    "| Likes | {metrics['likes']:,} |\n",
    "| Comments | {metrics['comments']:,} |\n",
    "| Engagement Rate | {metrics['engagement_rate']}% |\n",
    "| Like Rate | {metrics['like_rate']}% |\n",
    "| Comment Rate | {metrics['comment_rate']}% |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Video Summary\n",
    "\n",
    "{video_summary}\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¬ Audience Reaction Summary\n",
    "\n",
    "{reaction_summary}\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "    \n",
    "    if team_predictions:\n",
    "        report += \"\"\"## ğŸ¤– Team Model Predictions\\n\\n\"\"\"\n",
    "        if 'category' in team_predictions:\n",
    "            report += f\"- **Predicted Category**: {team_predictions['category']}\\n\"\n",
    "        if 'sentiment' in team_predictions:\n",
    "            s = team_predictions['sentiment']\n",
    "            report += f\"- **Sentiment Distribution**:\\n\"\n",
    "            report += f\"  - Positive: {s.get('positive',0):.1%}\\n\"\n",
    "            report += f\"  - Neutral: {s.get('neutral',0):.1%}\\n\"\n",
    "            report += f\"  - Negative: {s.get('negative',0):.1%}\\n\"\n",
    "        report += \"\\n---\\n\\n\"\n",
    "    \n",
    "    top_comments = self.preprocessor.filter_comments(comments)[:5]\n",
    "    if top_comments:\n",
    "        report += \"\"\"## ğŸ” Top Comments\\n\\n\"\"\"\n",
    "        for i, c in enumerate(top_comments, 1):\n",
    "            text = c.get('text', '')[:200]\n",
    "            likes = c.get('like_count', 0)\n",
    "            author = c.get('author', 'Anonymous')\n",
    "            report += f\"{i}. **{author}** ({likes} likes): {text}...\\n\\n\"\n",
    "        report += \"---\\n\\n\"\n",
    "    \n",
    "    report += \"\"\"## ğŸ“Œ Technical Notes\n",
    "\n",
    "- This report was automatically generated using LLM-based multilingual analysis\n",
    "- Input content processed in original language(s) without translation layer\n",
    "- Summaries generated through native multilingual understanding\n",
    "- Output language fixed to English for consistency\n",
    "\n",
    "---\n",
    "\n",
    "*Generated by YouTube Report Generator - Phase 2 Full Pipeline*\n",
    "\"\"\"\n",
    "    return report\n",
    "\n",
    "# Add method to ReportGenerator class\n",
    "ReportGenerator.format_markdown_report = format_markdown_report\n",
    "print(\"âœ… Report formatting enhanced with language detection info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(self, video_data: Dict) -> str:\n",
    "    \"\"\"Generate complete report with enhanced logging\"\"\"\n",
    "    video_info = video_data['video_info']\n",
    "    comments = video_data.get('comments', [])\n",
    "    \n",
    "    print(f\"\\nğŸ¬ Processing: {video_info.get('title', 'Unknown')}\")\n",
    "    \n",
    "    # Collect language detection info\n",
    "    detected_languages = {}\n",
    "    \n",
    "    print(\"  ğŸ“ Generating video summary...\")\n",
    "    video_summary, video_lang = self.generate_video_summary(video_info)\n",
    "    detected_languages['video'] = video_lang\n",
    "    \n",
    "    print(\"  ğŸ’¬ Generating reaction summary...\")\n",
    "    reaction_summary, comment_langs = self.generate_reaction_summary(\n",
    "        video_info.get('title', ''), comments\n",
    "    )\n",
    "    detected_languages['comments'] = comment_langs\n",
    "    \n",
    "    print(\"  ğŸ“Š Calculating metrics...\")\n",
    "    metrics = self.calculate_engagement_metrics(video_info)\n",
    "    \n",
    "    # Team model predictions\n",
    "    team_predictions = {}\n",
    "    if self.config.use_category_model:\n",
    "        pred = self.team_models.predict_category(video_info)\n",
    "        if pred:\n",
    "            team_predictions['category'] = pred\n",
    "    \n",
    "    if self.config.use_sentiment_model:\n",
    "        sent = self.team_models.analyze_sentiment(comments)\n",
    "        if sent:\n",
    "            team_predictions['sentiment'] = sent\n",
    "    \n",
    "    print(\"  ğŸ“„ Formatting report...\")\n",
    "    report = self.format_markdown_report(\n",
    "        video_data, video_summary, reaction_summary,\n",
    "        metrics,\n",
    "        team_predictions if team_predictions else None,\n",
    "        detected_languages  # NEW: Pass language info\n",
    "    )\n",
    "    \n",
    "    print(\"  âœ… Done!\")\n",
    "    return report\n",
    "\n",
    "# Add method\n",
    "ReportGenerator.generate_report = generate_report\n",
    "\n",
    "# Initialize report generator\n",
    "report_generator = ReportGenerator(config, model_manager, preprocessor, team_models)\n",
    "print(\"âœ… Report generator initialized (enhanced)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ 9. Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dataset = data_loader.get_data()\n",
    "\n",
    "# Select videos using config (no hardcoding)\n",
    "videos_to_process = dataset[:config.num_videos_for_test]\n",
    "\n",
    "print(f\"\\nğŸ¯ Processing {len(videos_to_process)} videos...\")\n",
    "print(f\"   (Configured test size: {config.num_videos_for_test})\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate reports\n",
    "reports = []\n",
    "\n",
    "for i, video_data in enumerate(videos_to_process, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Video {i}/{len(videos_to_process)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        report = report_generator.generate_report(video_data)\n",
    "        reports.append({\n",
    "            'video_id': video_data['video_info']['video_id'],\n",
    "            'report': report\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"âœ… Completed {len(reports)}/{len(videos_to_process)} videos\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ 10. Save Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if config.save_reports:\n",
    "    os.makedirs(config.output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ Saving to: {config.output_dir}/\")\n",
    "    \n",
    "    for report_data in reports:\n",
    "        video_id = report_data['video_id']\n",
    "        report = report_data['report']\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"{config.output_dir}/report_{video_id}_{timestamp}.md\"\n",
    "        \n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        print(f\"  âœ… {filename}\")\n",
    "    \n",
    "    print(f\"\\nâœ… All reports saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š 11. Display Sample Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reports:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Sample Report (First Video)\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    print(reports[0]['report'])\n",
    "else:\n",
    "    print(\"âš ï¸ No reports generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ 12. Language Statistics Summary\n",
    "\n",
    "Track language distribution across processed videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display language statistics\n",
    "if reports:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Language Distribution Summary\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    lang_stats = report_generator.get_language_statistics()\n",
    "    \n",
    "    if 'video' in lang_stats:\n",
    "        print(\"\\nğŸ“¹ Video Metadata Languages:\")\n",
    "        for lang, count in sorted(lang_stats['video'].items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {lang}: {count} videos\")\n",
    "    \n",
    "    if 'comments' in lang_stats:\n",
    "        print(\"\\nğŸ’¬ Comment Languages (sample of top 10 per video):\")\n",
    "        for lang, count in sorted(lang_stats['comments'].items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {lang}: {count} occurrences\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\\nğŸ’¡ Insight: This shows the pipeline's multilingual processing capability\")\n",
    "    print(\"   All outputs are in English regardless of input language mix.\")\n",
    "else:\n",
    "    print(\"âš ï¸ No reports to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ 13. End-to-End Wrapper Function\n",
    "\n",
    "High-level function for easy pipeline usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_youtube_video(video_data: Dict, \n",
    "                          report_generator: ReportGenerator,\n",
    "                          save_report: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    End-to-end YouTube video analysis pipeline.\n",
    "    \n",
    "    Args:\n",
    "        video_data: Dict containing 'video_info' and 'comments'\n",
    "        report_generator: Initialized ReportGenerator instance\n",
    "        save_report: Whether to save markdown report to file\n",
    "    \n",
    "    Returns:\n",
    "        Dict with analysis results:\n",
    "        {\n",
    "            'video_id': str,\n",
    "            'title': str,\n",
    "            'input_language': str,\n",
    "            'output_language': str,\n",
    "            'video_summary': str,\n",
    "            'reaction_summary': str,\n",
    "            'engagement_metrics': Dict,\n",
    "            'comment_language_distribution': Dict,\n",
    "            'markdown_report': str,\n",
    "            'report_path': Optional[str]\n",
    "        }\n",
    "    \"\"\"\n",
    "    video_info = video_data['video_info']\n",
    "    video_id = video_info['video_id']\n",
    "    \n",
    "    print(f\"\\nğŸ¬ Analyzing: {video_info.get('title', 'Unknown')}\")\n",
    "    \n",
    "    # Generate report\n",
    "    report_text = report_generator.generate_report(video_data)\n",
    "    \n",
    "    # Extract components\n",
    "    video_summary = report_generator.generate_video_summary(video_info)\n",
    "    reaction_summary = report_generator.generate_reaction_summary(\n",
    "        video_info['title'], \n",
    "        video_data.get('comments', [])\n",
    "    )\n",
    "    metrics = report_generator.calculate_engagement_metrics(video_info)\n",
    "    \n",
    "    # Detect languages\n",
    "    input_lang = report_generator.preprocessor.detect_language(\n",
    "        video_info.get('title', '') + ' ' + video_info.get('description', '')[:200]\n",
    "    )\n",
    "    \n",
    "    # Save if requested\n",
    "    report_path = None\n",
    "    if save_report:\n",
    "        import os\n",
    "        os.makedirs('reports', exist_ok=True)\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        report_path = f\"reports/report_{video_id}_{timestamp}.md\"\n",
    "        with open(report_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(report_text)\n",
    "        print(f\"  âœ… Report saved: {report_path}\")\n",
    "    \n",
    "    # Return structured results\n",
    "    return {\n",
    "        'video_id': video_id,\n",
    "        'title': video_info.get('title', 'N/A'),\n",
    "        'input_language': input_lang,\n",
    "        'output_language': report_generator.config.output_language,\n",
    "        'video_summary': video_summary,\n",
    "        'reaction_summary': reaction_summary,\n",
    "        'engagement_metrics': metrics,\n",
    "        'comment_language_distribution': getattr(report_generator, 'current_video_lang_dist', {}),\n",
    "        'markdown_report': report_text,\n",
    "        'report_path': report_path\n",
    "    }\n",
    "\n",
    "print(\"âœ… End-to-end wrapper function defined\")\n",
    "print(\"\\nğŸ’¡ Usage example:\")\n",
    "print(\"   result = analyze_youtube_video(video_data, report_generator)\")\n",
    "print(\"   print(result['video_summary'])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Use wrapper function on first video\n",
    "if dataset:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Example: End-to-End Analysis\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = analyze_youtube_video(\n",
    "        dataset[0], \n",
    "        report_generator,\n",
    "        save_report=False  # Don't save to avoid duplication\n",
    "    )\n",
    "    \n",
    "    print(\"\\nğŸ“Š Analysis Result:\")\n",
    "    print(f\"  Video ID: {result['video_id']}\")\n",
    "    print(f\"  Title: {result['title']}\")\n",
    "    print(f\"  Input Language: {result['input_language']}\")\n",
    "    print(f\"  Output Language: {result['output_language']}\")\n",
    "    print(f\"  Engagement Rate: {result['engagement_metrics']['engagement_rate']}%\")\n",
    "    print(f\"  Comment Languages: {result['comment_language_distribution']}\")\n",
    "    print(f\"\\n  Summary Preview: {result['video_summary'][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ 14. Usage Tips & Best Practices\n",
    "\n",
    "### ğŸ”§ Configuration Best Practices\n",
    "\n",
    "```python\n",
    "# For research/experiments\n",
    "config = PipelineConfig(\n",
    "    num_videos_for_test=5,         # Process subset\n",
    "    log_token_counts=True,          # Track token usage\n",
    "    log_language_distribution=True, # Monitor language mix\n",
    "    temperature=0.7                 # Balanced creativity\n",
    ")\n",
    "\n",
    "# For production\n",
    "config = PipelineConfig(\n",
    "    num_videos_for_test=None,       # Process all\n",
    "    log_token_counts=False,         # Reduce logging\n",
    "    temperature=0.5                 # More deterministic\n",
    ")\n",
    "```\n",
    "\n",
    "### ğŸŒ Multilingual Processing\n",
    "\n",
    "**The pipeline automatically handles:**\n",
    "```python\n",
    "# Korean video â†’ English report\n",
    "Input:  Title: \"NMIXX(ì—”ë¯¹ìŠ¤) 'Blue Valentine' M/V\"\n",
    "        Comments: \"ì´ ë…¸ë˜ ì§„ì§œ ì¢‹ë‹¤\", \"ì™„ì „ ëŒ€ë°•\"\n",
    "Output: English summary with [Detected: Korean] in logs\n",
    "\n",
    "# Mixed language â†’ English report  \n",
    "Input:  Comments: \"ì´ ë…¸ë˜ beautifulí•˜ë‹¤\", \"choreography ì§„ì§œ amazing\"\n",
    "Output: English summary understanding code-switching\n",
    "        [Comment languages: {'Korean': 5, 'English': 3}]\n",
    "```\n",
    "\n",
    "### ğŸ“Š Monitoring & Debugging\n",
    "\n",
    "**Check logs for:**\n",
    "```\n",
    "ğŸ¬ Processing: NMIXX(ì—”ë¯¹ìŠ¤) \"Blue Valentine\" M/V\n",
    "  ğŸ“ Generating video summary...\n",
    "    [Detected input language: Korean]\n",
    "    [Input tokens: 450]\n",
    "    [Output tokens: 120]\n",
    "    [Generation ratio: 120/450 = 0.27x]\n",
    "    [Output language: English]\n",
    "  ğŸ’¬ Generating reaction summary...\n",
    "    [Comment languages (top 10): {'English': 7, 'Korean': 3}]\n",
    "    [Input tokens: 850]\n",
    "    [Output tokens: 150]\n",
    "    [Output language: English]\n",
    "```\n",
    "\n",
    "### ğŸ¯ Using the Wrapper Function\n",
    "\n",
    "```python\n",
    "# Simple usage\n",
    "result = analyze_youtube_video(video_data, report_generator)\n",
    "\n",
    "# Access structured results\n",
    "print(f\"Summary: {result['video_summary']}\")\n",
    "print(f\"Sentiment: {result['reaction_summary']}\")\n",
    "print(f\"Metrics: {result['engagement_metrics']}\")\n",
    "print(f\"Languages: {result['comment_language_distribution']}\")\n",
    "```\n",
    "\n",
    "### ğŸ”§ Experiment Design\n",
    "\n",
    "**Temperature Ablation:**\n",
    "```python\n",
    "for temp in [0.3, 0.5, 0.7, 0.9]:\n",
    "    config.temperature = temp\n",
    "    # Regenerate and compare outputs\n",
    "```\n",
    "\n",
    "**Language-specific Analysis:**\n",
    "```python\n",
    "# Filter dataset by language\n",
    "korean_videos = [v for v in dataset if detect_korean(v['video_info']['title'])]\n",
    "english_videos = [v for v in dataset if detect_english(v['video_info']['title'])]\n",
    "# Compare quality metrics\n",
    "```\n",
    "\n",
    "### ğŸ“ˆ Performance Expectations\n",
    "\n",
    "**Quality (with token logging):**\n",
    "- Korean input: **8-9/10**, ~400-600 input tokens, ~100-150 output tokens\n",
    "- English input: **8-9/10**, ~300-500 input tokens, ~100-150 output tokens\n",
    "- Mixed language: **7-8/10**, ~500-700 input tokens, ~120-180 output tokens\n",
    "\n",
    "**Speed (T4 GPU):**\n",
    "- Model loading: 3-5 min (first time)\n",
    "- Per video: 2-3 min\n",
    "- 10 videos: ~25-35 min\n",
    "\n",
    "### ğŸ› Troubleshooting\n",
    "\n",
    "**Issue: Generation fails**\n",
    "```\n",
    "Check logs:\n",
    "âŒ Generation failed for video_summary\n",
    "   Error: CUDA out of memory\n",
    "   Message count: 2\n",
    "   Total message length: 4500 chars\n",
    "\n",
    "Solution: Reduce max_description_length or use smaller model\n",
    "```\n",
    "\n",
    "**Issue: Poor quality for rare languages**\n",
    "```\n",
    "Add language to prompt:\n",
    "PromptTemplates.VIDEO_SUMMARY_SYSTEM += \n",
    "    \"You also understand Arabic, Hindi, Thai...\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Next Steps for Research\n",
    "\n",
    "1. **Prompt Ablation Study**\n",
    "   - Compare short vs long prompts\n",
    "   - With/without examples\n",
    "   - Measure quality vs token cost\n",
    "\n",
    "2. **Language-specific Evaluation**\n",
    "   - Human evaluation (5 videos Ã— 3 languages)\n",
    "   - Rate accuracy, fluency, completeness (1-5)\n",
    "   - Compare across language pairs\n",
    "\n",
    "3. **Integration with Classification Models**\n",
    "   - Add category classifier to TeamModelIntegration\n",
    "   - Add sentiment analyzer\n",
    "   - Compare LLM summaries vs model predictions\n",
    "\n",
    "4. **End-to-End System Evaluation**\n",
    "   - Process full dataset (20 videos)\n",
    "   - Generate language statistics report\n",
    "   - Analyze quality across different content types\n",
    "\n",
    "---\n",
    "\n",
    "âœ… **Phase 2 Complete: Multilingual LLM-based Summarization Pipeline**\n",
    "\n",
    "**Key Achievements:**\n",
    "- Native multilingual understanding (Ko/En/Ja/Mixed)\n",
    "- Fixed English output\n",
    "- Comprehensive logging and monitoring\n",
    "- End-to-end wrapper function\n",
    "- Language statistics tracking\n",
    "- Modular, extensible architecture\n",
    "\n",
    "**Ready for Phase 3:**\n",
    "- Team model integration (category/sentiment classification)\n",
    "- YouTube API integration (link â†’ report)\n",
    "- Evaluation framework (human study)\n",
    "- Production deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}